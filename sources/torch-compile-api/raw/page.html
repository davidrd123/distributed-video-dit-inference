
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>torch.compile &#8212; PyTorch 2.10 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=047068a3" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=949a1ff5" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/css/jit.css?v=8de1ea5d" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=8998eb7a"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=940804e7"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'generated/torch.compile';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.15.4';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://docs.pytorch.org/docs/pytorch-versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '2.10';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <script src="../_static/js/runllm-widget.js?v=54a6b3cb"></script>
    <link rel="canonical" href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Aliases in torch" href="../torch.aliases.html" />
    <link rel="prev" title="torch.cond" href="torch.cond.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->


<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="https://docs.pytorch.org/docs/stable/_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="docs">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', '2.10');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->

<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>

<body data-feedback-url="https://github.com/pytorch/pytorch" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                <span>Learn</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started/locally">
                  <span class=dropdown-title>Get Started</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
                  <span class="dropdown-title">Webinars</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Community</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
                  <span class="dropdown-title">Join the Ecosystem</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
                  <span class="dropdown-title">Community Hub</span>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
                  <span class="dropdown-title">Forums</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
                  <span class="dropdown-title">Contributor Awards</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
                  <span class="dropdown-title">Community Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
                  <span class="dropdown-title">PyTorch Ambassadors</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Projects</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
                  <span class="dropdown-title">vLLM</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
                  <span class="dropdown-title">DeepSpeed</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
                  <span class="dropdown-title">Host Your Project</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/ray/">
                  <span class="dropdown-title">RAY</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span> Docs</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/domains">
                  <span class="dropdown-title">Domains</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Blogs & News</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">Blog</span>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/announcements">
                  <span class="dropdown-title">Announcements</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
                  <span class="dropdown-title">Case Studies</span>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                </a>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>About</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/members">
                  <span class="dropdown-title">Members</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact">
                  <span class="dropdown-title">Contact</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/wp-content/uploads/2025/09/pytorch_brand_guide_091925a.pdf">
                  <span class="dropdown-title">Brand Guidelines</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown main-menu-button">
              <a href="https://pytorch.org/join" data-cta="join">
                JOIN
              </a>
            </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>Learn</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/get-started/locally">Get Started</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials">Tutorials</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
           </li>
           <li>
            <a href="https://pytorch.org/webinars/">Webinars</a>
          </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a>Community</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Landscape</a>
          </li>
          <li>
             <a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
           </li>
           <li>
             <a href="https://pytorch.org/community-hub/">Community Hub</a>
           </li>
           <li>
             <a href="https://discuss.pytorch.org/">Forums</a>
           </li>
           <li>
             <a href="https://pytorch.org/resources">Developer Resources</a>
           </li>
           <li>
             <a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
           </li>
           <li>
            <a href="https://pytorch.org/community-events/">Community Events</a>
          </li>
          <li>
            <a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
          </li>
       </ul>

         <li class="resources-mobile-menu-title">
           <a>Projects</a>
         </li>

         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
           </li>

           <li>
             <a href="https://pytorch.org/projects/vllm/">vLLM</a>
           </li>
           <li>
            <a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
          </li>
          <li>
             <a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
           </li>
         </ul>

         <li class="resources-mobile-menu-title">
           <a>Docs</a>
         </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/stable/index.html">PyTorch</a>
          </li>

          <li>
            <a href="https://pytorch.org/domains">Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>
          <li>
            <a href="https://pytorch.org/announcements">Announcements</a>
          </li>

          <li>
            <a href="https://pytorch.org/case-studies/">Case Studies</a>
          </li>
          <li>
            <a href="https://pytorch.org/events">Events</a>
          </li>
          <li>
             <a href="https://pytorch.org/newsletter">Newsletter</a>
           </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="https://pytorch.org/members">Members</a>
          </li>
          <li>
            <a href="https://pytorch.org/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="https://pytorch.org/tac">Technical Advisory Council</a>
         </li>
         <li>
             <a href="https://pytorch.org/credits">Cloud Credit Program</a>
          </li>
          <li>
             <a href="https://pytorch.org/staff">Staff</a>
          </li>
          <li>
             <a href="https://pytorch.org/contact">Contact</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Home</p>
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-external" href="https://pytorch.org/get-started/locally/">
    Install PyTorch
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../user_guide/index.html">
    User Guide
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../pytorch-api.html">
    Reference API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes.html">
    Developer Notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../community/index.html">
    Community
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://docs.pytorch.org/tutorials/">
    Tutorials
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="PyTorch Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyTorch Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-external" href="https://pytorch.org/get-started/locally/">
    Install PyTorch
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../user_guide/index.html">
    User Guide
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../pytorch-api.html">
    Reference API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes.html">
    Developer Notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../community/index.html">
    Community
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://docs.pytorch.org/tutorials/">
    Tutorials
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="PyTorch Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyTorch Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://docs.pytorch.org/cppdocs/">C++</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../torch.html">torch</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="torch.is_tensor.html">torch.is_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.is_storage.html">torch.is_storage</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.is_complex.html">torch.is_complex</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.is_conj.html">torch.is_conj</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.is_floating_point.html">torch.is_floating_point</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.is_nonzero.html">torch.is_nonzero</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.set_default_dtype.html">torch.set_default_dtype</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.get_default_dtype.html">torch.get_default_dtype</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.set_default_device.html">torch.set_default_device</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.get_default_device.html">torch.get_default_device</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.set_default_tensor_type.html">torch.set_default_tensor_type</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.numel.html">torch.numel</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.set_printoptions.html">torch.set_printoptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.set_flush_denormal.html">torch.set_flush_denormal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.tensor.html">torch.tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse_coo_tensor.html">torch.sparse_coo_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse_csr_tensor.html">torch.sparse_csr_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse_csc_tensor.html">torch.sparse_csc_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse_bsr_tensor.html">torch.sparse_bsr_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse_bsc_tensor.html">torch.sparse_bsc_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.asarray.html">torch.asarray</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.as_tensor.html">torch.as_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.as_strided.html">torch.as_strided</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.from_file.html">torch.from_file</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.from_numpy.html">torch.from_numpy</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.from_dlpack.html">torch.from_dlpack</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.frombuffer.html">torch.frombuffer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.zeros.html">torch.zeros</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.zeros_like.html">torch.zeros_like</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.ones.html">torch.ones</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.ones_like.html">torch.ones_like</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.arange.html">torch.arange</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.range.html">torch.range</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linspace.html">torch.linspace</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.logspace.html">torch.logspace</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.eye.html">torch.eye</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.empty.html">torch.empty</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.empty_like.html">torch.empty_like</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.empty_strided.html">torch.empty_strided</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.full.html">torch.full</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.full_like.html">torch.full_like</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.quantize_per_tensor.html">quantize_per_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.quantize_per_channel.html">quantize_per_channel</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.dequantize.html">dequantize</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.complex.html">torch.complex</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.polar.html">torch.polar</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.heaviside.html">torch.heaviside</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.adjoint.html">torch.adjoint</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.argwhere.html">torch.argwhere</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cat.html">torch.cat</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.concat.html">torch.concat</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.concatenate.html">torch.concatenate</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.conj.html">torch.conj</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.chunk.html">torch.chunk</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.dsplit.html">torch.dsplit</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.column_stack.html">torch.column_stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.dstack.html">torch.dstack</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.gather.html">torch.gather</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.hsplit.html">torch.hsplit</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.hstack.html">torch.hstack</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.index_add.html">torch.index_add</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.index_copy.html">torch.index_copy</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.index_reduce.html">torch.index_reduce</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.index_select.html">torch.index_select</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.masked_select.html">torch.masked_select</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.movedim.html">torch.movedim</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.moveaxis.html">torch.moveaxis</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.narrow.html">torch.narrow</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.narrow_copy.html">torch.narrow_copy</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nonzero.html">torch.nonzero</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.permute.html">torch.permute</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.reshape.html">torch.reshape</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.row_stack.html">torch.row_stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.select.html">torch.select</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.scatter.html">torch.scatter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.diagonal_scatter.html">torch.diagonal_scatter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.select_scatter.html">torch.select_scatter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.slice_scatter.html">torch.slice_scatter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.scatter_add.html">torch.scatter_add</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.scatter_reduce.html">torch.scatter_reduce</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.segment_reduce.html">torch.segment_reduce</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.split.html">torch.split</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.squeeze.html">torch.squeeze</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.stack.html">torch.stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.swapaxes.html">torch.swapaxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.swapdims.html">torch.swapdims</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.t.html">torch.t</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.take.html">torch.take</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.take_along_dim.html">torch.take_along_dim</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.tensor_split.html">torch.tensor_split</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.tile.html">torch.tile</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.transpose.html">torch.transpose</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.unbind.html">torch.unbind</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.unravel_index.html">torch.unravel_index</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.unsqueeze.html">torch.unsqueeze</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.vsplit.html">torch.vsplit</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.vstack.html">torch.vstack</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.where.html">torch.where</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Stream.html">Stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Event.html">Event</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Generator.html">Generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.seed.html">torch.seed</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.manual_seed.html">torch.manual_seed</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.initial_seed.html">torch.initial_seed</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.get_rng_state.html">torch.get_rng_state</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.set_rng_state.html">torch.set_rng_state</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bernoulli.html">torch.bernoulli</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.multinomial.html">torch.multinomial</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.normal.html">torch.normal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.poisson.html">torch.poisson</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.rand.html">torch.rand</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.rand_like.html">torch.rand_like</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.randint.html">torch.randint</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.randint_like.html">torch.randint_like</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.randn.html">torch.randn</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.randn_like.html">torch.randn_like</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.randperm.html">torch.randperm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.quasirandom.SobolEngine.html">SobolEngine</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.save.html">torch.save</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.load.html">torch.load</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.get_num_threads.html">torch.get_num_threads</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.set_num_threads.html">torch.set_num_threads</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.get_num_interop_threads.html">torch.get_num_interop_threads</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.set_num_interop_threads.html">torch.set_num_interop_threads</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.no_grad.html">no_grad</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.enable_grad.html">enable_grad</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.grad_mode.set_grad_enabled.html">set_grad_enabled</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.is_grad_enabled.html">torch.is_grad_enabled</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.grad_mode.inference_mode.html">inference_mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.is_inference_mode_enabled.html">torch.is_inference_mode_enabled</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.abs.html">torch.abs</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.absolute.html">torch.absolute</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.acos.html">torch.acos</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.arccos.html">torch.arccos</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.acosh.html">torch.acosh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.arccosh.html">torch.arccosh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.add.html">torch.add</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.addcdiv.html">torch.addcdiv</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.addcmul.html">torch.addcmul</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.angle.html">torch.angle</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.asin.html">torch.asin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.arcsin.html">torch.arcsin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.asinh.html">torch.asinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.arcsinh.html">torch.arcsinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.atan.html">torch.atan</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.arctan.html">torch.arctan</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.atanh.html">torch.atanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.arctanh.html">torch.arctanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.atan2.html">torch.atan2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.arctan2.html">torch.arctan2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bitwise_not.html">torch.bitwise_not</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bitwise_and.html">torch.bitwise_and</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bitwise_or.html">torch.bitwise_or</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bitwise_xor.html">torch.bitwise_xor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bitwise_left_shift.html">torch.bitwise_left_shift</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bitwise_right_shift.html">torch.bitwise_right_shift</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.ceil.html">torch.ceil</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.clamp.html">torch.clamp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.clip.html">torch.clip</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.conj_physical.html">torch.conj_physical</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.copysign.html">torch.copysign</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cos.html">torch.cos</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cosh.html">torch.cosh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.deg2rad.html">torch.deg2rad</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.div.html">torch.div</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.divide.html">torch.divide</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.digamma.html">torch.digamma</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.erf.html">torch.erf</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.erfc.html">torch.erfc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.erfinv.html">torch.erfinv</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.exp.html">torch.exp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.exp2.html">torch.exp2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.expm1.html">torch.expm1</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fake_quantize_per_channel_affine.html">torch.fake_quantize_per_channel_affine</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fake_quantize_per_tensor_affine.html">torch.fake_quantize_per_tensor_affine</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fix.html">torch.fix</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.float_power.html">torch.float_power</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.floor.html">torch.floor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.floor_divide.html">torch.floor_divide</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fmod.html">torch.fmod</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.frac.html">torch.frac</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.frexp.html">torch.frexp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.gradient.html">torch.gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.imag.html">torch.imag</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.ldexp.html">torch.ldexp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.lerp.html">torch.lerp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.lgamma.html">torch.lgamma</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.log.html">torch.log</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.log10.html">torch.log10</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.log1p.html">torch.log1p</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.log2.html">torch.log2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.logaddexp.html">torch.logaddexp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.logaddexp2.html">torch.logaddexp2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.logical_and.html">torch.logical_and</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.logical_not.html">torch.logical_not</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.logical_or.html">torch.logical_or</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.logical_xor.html">torch.logical_xor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.logit.html">torch.logit</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.hypot.html">torch.hypot</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.i0.html">torch.i0</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.igamma.html">torch.igamma</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.igammac.html">torch.igammac</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mul.html">torch.mul</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.multiply.html">torch.multiply</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mvlgamma.html">torch.mvlgamma</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nan_to_num.html">torch.nan_to_num</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.neg.html">torch.neg</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.negative.html">torch.negative</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nextafter.html">torch.nextafter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.polygamma.html">torch.polygamma</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.positive.html">torch.positive</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.pow.html">torch.pow</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.quantized_batch_norm.html">torch.quantized_batch_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.quantized_max_pool1d.html">torch.quantized_max_pool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.quantized_max_pool2d.html">torch.quantized_max_pool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.rad2deg.html">torch.rad2deg</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.real.html">torch.real</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.reciprocal.html">torch.reciprocal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.remainder.html">torch.remainder</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.round.html">torch.round</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.rsqrt.html">torch.rsqrt</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sigmoid.html">torch.sigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sign.html">torch.sign</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sgn.html">torch.sgn</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.signbit.html">torch.signbit</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sin.html">torch.sin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sinc.html">torch.sinc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sinh.html">torch.sinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.softmax.html">torch.softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sqrt.html">torch.sqrt</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.square.html">torch.square</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sub.html">torch.sub</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.subtract.html">torch.subtract</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.tan.html">torch.tan</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.tanh.html">torch.tanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.true_divide.html">torch.true_divide</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.trunc.html">torch.trunc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xlogy.html">torch.xlogy</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.argmax.html">torch.argmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.argmin.html">torch.argmin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.amax.html">torch.amax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.amin.html">torch.amin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.aminmax.html">torch.aminmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.all.html">torch.all</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.any.html">torch.any</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.max.html">torch.max</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.min.html">torch.min</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.dist.html">torch.dist</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.logsumexp.html">torch.logsumexp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mean.html">torch.mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nanmean.html">torch.nanmean</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.median.html">torch.median</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nanmedian.html">torch.nanmedian</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mode.html">torch.mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.norm.html">torch.norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nansum.html">torch.nansum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.prod.html">torch.prod</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.quantile.html">torch.quantile</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nanquantile.html">torch.nanquantile</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.std.html">torch.std</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.std_mean.html">torch.std_mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sum.html">torch.sum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.unique.html">torch.unique</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.unique_consecutive.html">torch.unique_consecutive</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.var.html">torch.var</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.var_mean.html">torch.var_mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.count_nonzero.html">torch.count_nonzero</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.hash_tensor.html">torch.hash_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.allclose.html">torch.allclose</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.argsort.html">torch.argsort</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.eq.html">torch.eq</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.equal.html">torch.equal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.ge.html">torch.ge</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.greater_equal.html">torch.greater_equal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.gt.html">torch.gt</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.greater.html">torch.greater</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.isclose.html">torch.isclose</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.isfinite.html">torch.isfinite</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.isin.html">torch.isin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.isinf.html">torch.isinf</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.isposinf.html">torch.isposinf</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.isneginf.html">torch.isneginf</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.isnan.html">torch.isnan</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.isreal.html">torch.isreal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.kthvalue.html">torch.kthvalue</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.le.html">torch.le</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.less_equal.html">torch.less_equal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.lt.html">torch.lt</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.less.html">torch.less</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.maximum.html">torch.maximum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.minimum.html">torch.minimum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fmax.html">torch.fmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fmin.html">torch.fmin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.ne.html">torch.ne</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.not_equal.html">torch.not_equal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sort.html">torch.sort</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.topk.html">torch.topk</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.msort.html">torch.msort</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.stft.html">torch.stft</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.istft.html">torch.istft</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bartlett_window.html">torch.bartlett_window</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.blackman_window.html">torch.blackman_window</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.hamming_window.html">torch.hamming_window</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.hann_window.html">torch.hann_window</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.kaiser_window.html">torch.kaiser_window</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.atleast_1d.html">torch.atleast_1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.atleast_2d.html">torch.atleast_2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.atleast_3d.html">torch.atleast_3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bincount.html">torch.bincount</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.block_diag.html">torch.block_diag</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.broadcast_tensors.html">torch.broadcast_tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.broadcast_to.html">torch.broadcast_to</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.broadcast_shapes.html">torch.broadcast_shapes</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bucketize.html">torch.bucketize</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cartesian_prod.html">torch.cartesian_prod</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cdist.html">torch.cdist</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.clone.html">torch.clone</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.combinations.html">torch.combinations</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.corrcoef.html">torch.corrcoef</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cov.html">torch.cov</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cross.html">torch.cross</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cummax.html">torch.cummax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cummin.html">torch.cummin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cumprod.html">torch.cumprod</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cumsum.html">torch.cumsum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.diag.html">torch.diag</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.diag_embed.html">torch.diag_embed</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.diagflat.html">torch.diagflat</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.diagonal.html">torch.diagonal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.diff.html">torch.diff</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.einsum.html">torch.einsum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.flatten.html">torch.flatten</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.flip.html">torch.flip</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fliplr.html">torch.fliplr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.flipud.html">torch.flipud</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.kron.html">torch.kron</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.rot90.html">torch.rot90</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.gcd.html">torch.gcd</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.histc.html">torch.histc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.histogram.html">torch.histogram</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.histogramdd.html">torch.histogramdd</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.meshgrid.html">torch.meshgrid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.lcm.html">torch.lcm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.logcumsumexp.html">torch.logcumsumexp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.ravel.html">torch.ravel</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.renorm.html">torch.renorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.repeat_interleave.html">torch.repeat_interleave</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.roll.html">torch.roll</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.searchsorted.html">torch.searchsorted</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.tensordot.html">torch.tensordot</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.trace.html">torch.trace</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.tril.html">torch.tril</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.tril_indices.html">torch.tril_indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.triu.html">torch.triu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.triu_indices.html">torch.triu_indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.unflatten.html">torch.unflatten</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.vander.html">torch.vander</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.view_as_real.html">torch.view_as_real</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.view_as_complex.html">torch.view_as_complex</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.resolve_conj.html">torch.resolve_conj</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.resolve_neg.html">torch.resolve_neg</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.addbmm.html">torch.addbmm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.addmm.html">torch.addmm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.addmv.html">torch.addmv</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.addr.html">torch.addr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.baddbmm.html">torch.baddbmm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bmm.html">torch.bmm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.chain_matmul.html">torch.chain_matmul</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cholesky.html">torch.cholesky</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cholesky_inverse.html">torch.cholesky_inverse</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cholesky_solve.html">torch.cholesky_solve</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.dot.html">torch.dot</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.geqrf.html">torch.geqrf</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.ger.html">torch.ger</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.inner.html">torch.inner</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.inverse.html">torch.inverse</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.det.html">torch.det</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.logdet.html">torch.logdet</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.slogdet.html">torch.slogdet</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.lu.html">torch.lu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.lu_solve.html">torch.lu_solve</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.lu_unpack.html">torch.lu_unpack</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.matmul.html">torch.matmul</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.matrix_power.html">torch.matrix_power</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.matrix_exp.html">torch.matrix_exp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mm.html">torch.mm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mv.html">torch.mv</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.orgqr.html">torch.orgqr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.ormqr.html">torch.ormqr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.outer.html">torch.outer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.pinverse.html">torch.pinverse</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.qr.html">torch.qr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.svd.html">torch.svd</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.svd_lowrank.html">torch.svd_lowrank</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.pca_lowrank.html">torch.pca_lowrank</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.lobpcg.html">torch.lobpcg</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.trapz.html">torch.trapz</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.trapezoid.html">torch.trapezoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cumulative_trapezoid.html">torch.cumulative_trapezoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.triangular_solve.html">torch.triangular_solve</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.vdot.html">torch.vdot</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_abs.html">torch._foreach_abs</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_abs_.html">torch._foreach_abs_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_acos.html">torch._foreach_acos</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_acos_.html">torch._foreach_acos_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_asin.html">torch._foreach_asin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_asin_.html">torch._foreach_asin_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_atan.html">torch._foreach_atan</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_atan_.html">torch._foreach_atan_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_ceil.html">torch._foreach_ceil</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_ceil_.html">torch._foreach_ceil_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_cos.html">torch._foreach_cos</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_cos_.html">torch._foreach_cos_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_cosh.html">torch._foreach_cosh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_cosh_.html">torch._foreach_cosh_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_erf.html">torch._foreach_erf</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_erf_.html">torch._foreach_erf_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_erfc.html">torch._foreach_erfc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_erfc_.html">torch._foreach_erfc_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_exp.html">torch._foreach_exp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_exp_.html">torch._foreach_exp_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_expm1.html">torch._foreach_expm1</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_expm1_.html">torch._foreach_expm1_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_floor.html">torch._foreach_floor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_floor_.html">torch._foreach_floor_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_log.html">torch._foreach_log</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_log_.html">torch._foreach_log_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_log10.html">torch._foreach_log10</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_log10_.html">torch._foreach_log10_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_log1p.html">torch._foreach_log1p</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_log1p_.html">torch._foreach_log1p_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_log2.html">torch._foreach_log2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_log2_.html">torch._foreach_log2_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_neg.html">torch._foreach_neg</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_neg_.html">torch._foreach_neg_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_tan.html">torch._foreach_tan</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_tan_.html">torch._foreach_tan_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_sin.html">torch._foreach_sin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_sin_.html">torch._foreach_sin_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_sinh.html">torch._foreach_sinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_sinh_.html">torch._foreach_sinh_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_round.html">torch._foreach_round</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_round_.html">torch._foreach_round_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_sqrt.html">torch._foreach_sqrt</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_sqrt_.html">torch._foreach_sqrt_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_lgamma.html">torch._foreach_lgamma</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_lgamma_.html">torch._foreach_lgamma_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_frac.html">torch._foreach_frac</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_frac_.html">torch._foreach_frac_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_reciprocal.html">torch._foreach_reciprocal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_reciprocal_.html">torch._foreach_reciprocal_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_sigmoid.html">torch._foreach_sigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_sigmoid_.html">torch._foreach_sigmoid_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_trunc.html">torch._foreach_trunc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_trunc_.html">torch._foreach_trunc_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._foreach_zero_.html">torch._foreach_zero_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiled_with_cxx11_abi.html">torch.compiled_with_cxx11_abi</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.result_type.html">torch.result_type</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.can_cast.html">torch.can_cast</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.promote_types.html">torch.promote_types</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.use_deterministic_algorithms.html">torch.use_deterministic_algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.are_deterministic_algorithms_enabled.html">torch.are_deterministic_algorithms_enabled</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.is_deterministic_algorithms_warn_only_enabled.html">torch.is_deterministic_algorithms_warn_only_enabled</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.set_deterministic_debug_mode.html">torch.set_deterministic_debug_mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.get_deterministic_debug_mode.html">torch.get_deterministic_debug_mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.set_float32_matmul_precision.html">torch.set_float32_matmul_precision</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.get_float32_matmul_precision.html">torch.get_float32_matmul_precision</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.set_warn_always.html">torch.set_warn_always</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.get_device_module.html">torch.get_device_module</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.is_warn_always_enabled.html">torch.is_warn_always_enabled</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.vmap.html">torch.vmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch._assert.html">torch._assert</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sym_float.html">torch.sym_float</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sym_fresh_size.html">torch.sym_fresh_size</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sym_int.html">torch.sym_int</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sym_max.html">torch.sym_max</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sym_min.html">torch.sym_min</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sym_not.html">torch.sym_not</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sym_ite.html">torch.sym_ite</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sym_sum.html">torch.sym_sum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cond.html">torch.cond</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">torch.compile</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../torch.aliases.html">Aliases in torch</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.align_tensors.html">torch.functional.align_tensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.atleast_1d.html">torch.functional.atleast_1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.atleast_2d.html">torch.functional.atleast_2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.atleast_3d.html">torch.functional.atleast_3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.block_diag.html">torch.functional.block_diag</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.broadcast_shapes.html">torch.functional.broadcast_shapes</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.broadcast_tensors.html">torch.functional.broadcast_tensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.cartesian_prod.html">torch.functional.cartesian_prod</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.cdist.html">torch.functional.cdist</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.chain_matmul.html">torch.functional.chain_matmul</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.einsum.html">torch.functional.einsum</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.lu.html">torch.functional.lu</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.meshgrid.html">torch.functional.meshgrid</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.norm.html">torch.functional.norm</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.split.html">torch.functional.split</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.stft.html">torch.functional.stft</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.tensordot.html">torch.functional.tensordot</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.unique.html">torch.functional.unique</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.unique_consecutive.html">torch.functional.unique_consecutive</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.functional.unravel_index.html">torch.functional.unravel_index</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nn.aliases.html">Aliases in torch.nn</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.container.Sequential.html">Sequential</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.container.ModuleList.html">ModuleList</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.container.ModuleDict.html">ModuleDict</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.container.ParameterList.html">ParameterList</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.container.ParameterDict.html">ParameterDict</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.conv.Conv1d.html">Conv1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.conv.Conv2d.html">Conv2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.conv.Conv3d.html">Conv3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.conv.ConvTranspose1d.html">ConvTranspose1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.conv.ConvTranspose2d.html">ConvTranspose2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.conv.ConvTranspose3d.html">ConvTranspose3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.conv.LazyConv1d.html">LazyConv1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.conv.LazyConv2d.html">LazyConv2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.conv.LazyConv3d.html">LazyConv3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.conv.LazyConvTranspose1d.html">LazyConvTranspose1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.conv.LazyConvTranspose2d.html">LazyConvTranspose2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.conv.LazyConvTranspose3d.html">LazyConvTranspose3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.fold.Unfold.html">Unfold</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.fold.Fold.html">Fold</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.MaxPool1d.html">MaxPool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.MaxPool2d.html">MaxPool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.MaxPool3d.html">MaxPool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.MaxUnpool1d.html">MaxUnpool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.MaxUnpool2d.html">MaxUnpool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.MaxUnpool3d.html">MaxUnpool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.AvgPool1d.html">AvgPool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.AvgPool2d.html">AvgPool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.AvgPool3d.html">AvgPool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.FractionalMaxPool2d.html">FractionalMaxPool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.FractionalMaxPool3d.html">FractionalMaxPool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.LPPool1d.html">LPPool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.LPPool2d.html">LPPool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.LPPool3d.html">LPPool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.AdaptiveMaxPool1d.html">AdaptiveMaxPool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.AdaptiveMaxPool2d.html">AdaptiveMaxPool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.AdaptiveMaxPool3d.html">AdaptiveMaxPool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.AdaptiveAvgPool1d.html">AdaptiveAvgPool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.AdaptiveAvgPool2d.html">AdaptiveAvgPool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pooling.AdaptiveAvgPool3d.html">AdaptiveAvgPool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.padding.ReflectionPad1d.html">ReflectionPad1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.padding.ReflectionPad2d.html">ReflectionPad2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.padding.ReflectionPad3d.html">ReflectionPad3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.padding.ReplicationPad1d.html">ReplicationPad1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.padding.ReplicationPad2d.html">ReplicationPad2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.padding.ReplicationPad3d.html">ReplicationPad3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.padding.ZeroPad1d.html">ZeroPad1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.padding.ZeroPad2d.html">ZeroPad2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.padding.ZeroPad3d.html">ZeroPad3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.padding.ConstantPad1d.html">ConstantPad1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.padding.ConstantPad2d.html">ConstantPad2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.padding.ConstantPad3d.html">ConstantPad3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.padding.CircularPad1d.html">CircularPad1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.padding.CircularPad2d.html">CircularPad2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.padding.CircularPad3d.html">CircularPad3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.ELU.html">ELU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.Hardshrink.html">Hardshrink</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.Hardsigmoid.html">Hardsigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.Hardtanh.html">Hardtanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.Hardswish.html">Hardswish</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.LeakyReLU.html">LeakyReLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.LogSigmoid.html">LogSigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.MultiheadAttention.html">MultiheadAttention</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.PReLU.html">PReLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.ReLU.html">ReLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.ReLU6.html">ReLU6</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.RReLU.html">RReLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.SELU.html">SELU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.CELU.html">CELU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.GELU.html">GELU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.Sigmoid.html">Sigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.SiLU.html">SiLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.Mish.html">Mish</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.Softplus.html">Softplus</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.Softshrink.html">Softshrink</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.Softsign.html">Softsign</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.Tanh.html">Tanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.Tanhshrink.html">Tanhshrink</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.Threshold.html">Threshold</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.GLU.html">GLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.Softmin.html">Softmin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.Softmax.html">Softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.Softmax2d.html">Softmax2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.activation.LogSoftmax.html">LogSoftmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.adaptive.AdaptiveLogSoftmaxWithLoss.html">AdaptiveLogSoftmaxWithLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.batchnorm.BatchNorm1d.html">BatchNorm1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.batchnorm.BatchNorm2d.html">BatchNorm2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.batchnorm.BatchNorm3d.html">BatchNorm3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.batchnorm.LazyBatchNorm1d.html">LazyBatchNorm1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.batchnorm.LazyBatchNorm2d.html">LazyBatchNorm2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.batchnorm.LazyBatchNorm3d.html">LazyBatchNorm3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.normalization.GroupNorm.html">GroupNorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.batchnorm.SyncBatchNorm.html">SyncBatchNorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.instancenorm.InstanceNorm1d.html">InstanceNorm1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.instancenorm.InstanceNorm2d.html">InstanceNorm2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.instancenorm.InstanceNorm3d.html">InstanceNorm3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.instancenorm.LazyInstanceNorm1d.html">LazyInstanceNorm1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.instancenorm.LazyInstanceNorm2d.html">LazyInstanceNorm2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.instancenorm.LazyInstanceNorm3d.html">LazyInstanceNorm3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.normalization.LayerNorm.html">LayerNorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.normalization.LocalResponseNorm.html">LocalResponseNorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.normalization.RMSNorm.html">RMSNorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.rnn.RNNBase.html">RNNBase</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.rnn.RNN.html">RNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.rnn.LSTM.html">LSTM</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.rnn.GRU.html">GRU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.rnn.RNNCell.html">RNNCell</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.rnn.LSTMCell.html">LSTMCell</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.rnn.GRUCell.html">GRUCell</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.transformer.Transformer.html">Transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.transformer.TransformerEncoder.html">TransformerEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.transformer.TransformerDecoder.html">TransformerDecoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.transformer.TransformerEncoderLayer.html">TransformerEncoderLayer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.transformer.TransformerDecoderLayer.html">TransformerDecoderLayer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.linear.Identity.html">Identity</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.linear.Linear.html">Linear</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.linear.Bilinear.html">Bilinear</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.linear.LazyLinear.html">LazyLinear</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.dropout.Dropout.html">Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.dropout.Dropout1d.html">Dropout1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.dropout.Dropout2d.html">Dropout2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.dropout.Dropout3d.html">Dropout3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.dropout.AlphaDropout.html">AlphaDropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.dropout.FeatureAlphaDropout.html">FeatureAlphaDropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.sparse.Embedding.html">Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.sparse.EmbeddingBag.html">EmbeddingBag</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.distance.CosineSimilarity.html">CosineSimilarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.distance.PairwiseDistance.html">PairwiseDistance</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.L1Loss.html">L1Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.MSELoss.html">MSELoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.CrossEntropyLoss.html">CrossEntropyLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.CTCLoss.html">CTCLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.NLLLoss.html">NLLLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.PoissonNLLLoss.html">PoissonNLLLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.GaussianNLLLoss.html">GaussianNLLLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.KLDivLoss.html">KLDivLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.BCELoss.html">BCELoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.BCEWithLogitsLoss.html">BCEWithLogitsLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.MarginRankingLoss.html">MarginRankingLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.HingeEmbeddingLoss.html">HingeEmbeddingLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.MultiLabelMarginLoss.html">MultiLabelMarginLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.HuberLoss.html">HuberLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.SmoothL1Loss.html">SmoothL1Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.SoftMarginLoss.html">SoftMarginLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.MultiLabelSoftMarginLoss.html">MultiLabelSoftMarginLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.CosineEmbeddingLoss.html">CosineEmbeddingLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.MultiMarginLoss.html">MultiMarginLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.TripletMarginLoss.html">TripletMarginLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.loss.TripletMarginWithDistanceLoss.html">TripletMarginWithDistanceLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pixelshuffle.PixelShuffle.html">PixelShuffle</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.pixelshuffle.PixelUnshuffle.html">PixelUnshuffle</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.upsampling.Upsample.html">Upsample</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.upsampling.UpsamplingNearest2d.html">UpsamplingNearest2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.upsampling.UpsamplingBilinear2d.html">UpsamplingBilinear2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.channelshuffle.ChannelShuffle.html">ChannelShuffle</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.clip_grad.clip_grad_norm_.html">torch.nn.utils.clip_grad.clip_grad_norm_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.clip_grad.clip_grad_norm.html">torch.nn.utils.clip_grad.clip_grad_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.clip_grad.clip_grad_value_.html">torch.nn.utils.clip_grad.clip_grad_value_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.convert_parameters.parameters_to_vector.html">torch.nn.utils.convert_parameters.parameters_to_vector</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.convert_parameters.vector_to_parameters.html">torch.nn.utils.convert_parameters.vector_to_parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.fusion.fuse_conv_bn_eval.html">torch.nn.utils.fusion.fuse_conv_bn_eval</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.fusion.fuse_conv_bn_weights.html">torch.nn.utils.fusion.fuse_conv_bn_weights</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.fusion.fuse_linear_bn_eval.html">torch.nn.utils.fusion.fuse_linear_bn_eval</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.fusion.fuse_linear_bn_weights.html">torch.nn.utils.fusion.fuse_linear_bn_weights</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.memory_format.convert_conv2d_weight_memory_format.html">torch.nn.utils.memory_format.convert_conv2d_weight_memory_format</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.memory_format.convert_conv3d_weight_memory_format.html">torch.nn.utils.memory_format.convert_conv3d_weight_memory_format</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.weight_norm.weight_norm.html">torch.nn.utils.weight_norm.weight_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.weight_norm.remove_weight_norm.html">torch.nn.utils.weight_norm.remove_weight_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.spectral_norm.spectral_norm.html">torch.nn.utils.spectral_norm.spectral_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.spectral_norm.remove_spectral_norm.html">torch.nn.utils.spectral_norm.remove_spectral_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.init.skip_init.html">torch.nn.utils.init.skip_init</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nn.html">torch.nn</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.parameter.Buffer.html">Buffer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.parameter.Parameter.html">Parameter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.parameter.UninitializedParameter.html">UninitializedParameter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.parameter.UninitializedBuffer.html">UninitializedBuffer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Module.html">Module</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Sequential.html">Sequential</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ModuleList.html">ModuleList</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ModuleDict.html">ModuleDict</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ParameterList.html">ParameterList</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ParameterDict.html">ParameterDict</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.module.register_module_forward_pre_hook.html">torch.nn.modules.module.register_module_forward_pre_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.module.register_module_forward_hook.html">torch.nn.modules.module.register_module_forward_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.module.register_module_backward_hook.html">torch.nn.modules.module.register_module_backward_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.module.register_module_full_backward_pre_hook.html">torch.nn.modules.module.register_module_full_backward_pre_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.module.register_module_full_backward_hook.html">torch.nn.modules.module.register_module_full_backward_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.module.register_module_buffer_registration_hook.html">torch.nn.modules.module.register_module_buffer_registration_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.module.register_module_module_registration_hook.html">torch.nn.modules.module.register_module_module_registration_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.module.register_module_parameter_registration_hook.html">torch.nn.modules.module.register_module_parameter_registration_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Conv1d.html">Conv1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Conv2d.html">Conv2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Conv3d.html">Conv3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ConvTranspose1d.html">ConvTranspose1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ConvTranspose2d.html">ConvTranspose2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ConvTranspose3d.html">ConvTranspose3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LazyConv1d.html">LazyConv1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LazyConv2d.html">LazyConv2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LazyConv3d.html">LazyConv3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LazyConvTranspose1d.html">LazyConvTranspose1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LazyConvTranspose2d.html">LazyConvTranspose2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LazyConvTranspose3d.html">LazyConvTranspose3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Unfold.html">Unfold</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Fold.html">Fold</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.MaxPool1d.html">MaxPool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.MaxPool2d.html">MaxPool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.MaxPool3d.html">MaxPool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.MaxUnpool1d.html">MaxUnpool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.MaxUnpool2d.html">MaxUnpool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.MaxUnpool3d.html">MaxUnpool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.AvgPool1d.html">AvgPool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.AvgPool2d.html">AvgPool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.AvgPool3d.html">AvgPool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.FractionalMaxPool2d.html">FractionalMaxPool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.FractionalMaxPool3d.html">FractionalMaxPool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LPPool1d.html">LPPool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LPPool2d.html">LPPool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LPPool3d.html">LPPool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.AdaptiveMaxPool1d.html">AdaptiveMaxPool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.AdaptiveMaxPool2d.html">AdaptiveMaxPool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.AdaptiveMaxPool3d.html">AdaptiveMaxPool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.AdaptiveAvgPool1d.html">AdaptiveAvgPool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.AdaptiveAvgPool2d.html">AdaptiveAvgPool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.AdaptiveAvgPool3d.html">AdaptiveAvgPool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ReflectionPad1d.html">ReflectionPad1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ReflectionPad2d.html">ReflectionPad2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ReflectionPad3d.html">ReflectionPad3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ReplicationPad1d.html">ReplicationPad1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ReplicationPad2d.html">ReplicationPad2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ReplicationPad3d.html">ReplicationPad3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ZeroPad1d.html">ZeroPad1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ZeroPad2d.html">ZeroPad2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ZeroPad3d.html">ZeroPad3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ConstantPad1d.html">ConstantPad1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ConstantPad2d.html">ConstantPad2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ConstantPad3d.html">ConstantPad3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.CircularPad1d.html">CircularPad1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.CircularPad2d.html">CircularPad2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.CircularPad3d.html">CircularPad3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ELU.html">ELU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Hardshrink.html">Hardshrink</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Hardsigmoid.html">Hardsigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Hardtanh.html">Hardtanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Hardswish.html">Hardswish</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LeakyReLU.html">LeakyReLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LogSigmoid.html">LogSigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.MultiheadAttention.html">MultiheadAttention</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.PReLU.html">PReLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ReLU.html">ReLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ReLU6.html">ReLU6</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.RReLU.html">RReLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.SELU.html">SELU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.CELU.html">CELU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.GELU.html">GELU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Sigmoid.html">Sigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.SiLU.html">SiLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Mish.html">Mish</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Softplus.html">Softplus</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Softshrink.html">Softshrink</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Softsign.html">Softsign</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Tanh.html">Tanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Tanhshrink.html">Tanhshrink</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Threshold.html">Threshold</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.GLU.html">GLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Softmin.html">Softmin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Softmax.html">Softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Softmax2d.html">Softmax2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LogSoftmax.html">LogSoftmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.AdaptiveLogSoftmaxWithLoss.html">AdaptiveLogSoftmaxWithLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.BatchNorm1d.html">BatchNorm1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.BatchNorm2d.html">BatchNorm2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.BatchNorm3d.html">BatchNorm3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LazyBatchNorm1d.html">LazyBatchNorm1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LazyBatchNorm2d.html">LazyBatchNorm2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LazyBatchNorm3d.html">LazyBatchNorm3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.GroupNorm.html">GroupNorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.SyncBatchNorm.html">SyncBatchNorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.InstanceNorm1d.html">InstanceNorm1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.InstanceNorm2d.html">InstanceNorm2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.InstanceNorm3d.html">InstanceNorm3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LazyInstanceNorm1d.html">LazyInstanceNorm1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LazyInstanceNorm2d.html">LazyInstanceNorm2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LazyInstanceNorm3d.html">LazyInstanceNorm3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LayerNorm.html">LayerNorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LocalResponseNorm.html">LocalResponseNorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.RMSNorm.html">RMSNorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.RNNBase.html">RNNBase</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.RNN.html">RNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LSTM.html">LSTM</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.GRU.html">GRU</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.RNNCell.html">RNNCell</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LSTMCell.html">LSTMCell</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.GRUCell.html">GRUCell</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Transformer.html">Transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.TransformerEncoder.html">TransformerEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.TransformerDecoder.html">TransformerDecoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.TransformerEncoderLayer.html">TransformerEncoderLayer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.TransformerDecoderLayer.html">TransformerDecoderLayer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Identity.html">Identity</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Linear.html">Linear</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Bilinear.html">Bilinear</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.LazyLinear.html">LazyLinear</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Dropout.html">Dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Dropout1d.html">Dropout1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Dropout2d.html">Dropout2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Dropout3d.html">Dropout3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.AlphaDropout.html">AlphaDropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.FeatureAlphaDropout.html">FeatureAlphaDropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Embedding.html">Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.EmbeddingBag.html">EmbeddingBag</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.CosineSimilarity.html">CosineSimilarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.PairwiseDistance.html">PairwiseDistance</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.L1Loss.html">L1Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.MSELoss.html">MSELoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.CrossEntropyLoss.html">CrossEntropyLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.CTCLoss.html">CTCLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.NLLLoss.html">NLLLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.PoissonNLLLoss.html">PoissonNLLLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.GaussianNLLLoss.html">GaussianNLLLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.KLDivLoss.html">KLDivLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.BCELoss.html">BCELoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.BCEWithLogitsLoss.html">BCEWithLogitsLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.MarginRankingLoss.html">MarginRankingLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.HingeEmbeddingLoss.html">HingeEmbeddingLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.MultiLabelMarginLoss.html">MultiLabelMarginLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.HuberLoss.html">HuberLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.SmoothL1Loss.html">SmoothL1Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.SoftMarginLoss.html">SoftMarginLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.MultiLabelSoftMarginLoss.html">MultiLabelSoftMarginLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.CosineEmbeddingLoss.html">CosineEmbeddingLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.MultiMarginLoss.html">MultiMarginLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.TripletMarginLoss.html">TripletMarginLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.TripletMarginWithDistanceLoss.html">TripletMarginWithDistanceLoss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.PixelShuffle.html">PixelShuffle</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.PixelUnshuffle.html">PixelUnshuffle</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.Upsample.html">Upsample</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.UpsamplingNearest2d.html">UpsamplingNearest2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.UpsamplingBilinear2d.html">UpsamplingBilinear2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.ChannelShuffle.html">ChannelShuffle</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.DataParallel.html">DataParallel</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.parallel.DistributedDataParallel.html">DistributedDataParallel</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.clip_grad_norm_.html">torch.nn.utils.clip_grad_norm_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.clip_grad_norm.html">torch.nn.utils.clip_grad_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.clip_grad_value_.html">torch.nn.utils.clip_grad_value_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.get_total_norm.html">torch.nn.utils.get_total_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.clip_grads_with_norm_.html">torch.nn.utils.clip_grads_with_norm_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.parameters_to_vector.html">torch.nn.utils.parameters_to_vector</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.vector_to_parameters.html">torch.nn.utils.vector_to_parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.fuse_conv_bn_eval.html">torch.nn.utils.fuse_conv_bn_eval</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.fuse_conv_bn_weights.html">torch.nn.utils.fuse_conv_bn_weights</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.fuse_linear_bn_eval.html">torch.nn.utils.fuse_linear_bn_eval</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.fuse_linear_bn_weights.html">torch.nn.utils.fuse_linear_bn_weights</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.convert_conv2d_weight_memory_format.html">torch.nn.utils.convert_conv2d_weight_memory_format</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.convert_conv3d_weight_memory_format.html">torch.nn.utils.convert_conv3d_weight_memory_format</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.weight_norm.html">torch.nn.utils.weight_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.remove_weight_norm.html">torch.nn.utils.remove_weight_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.spectral_norm.html">torch.nn.utils.spectral_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.remove_spectral_norm.html">torch.nn.utils.remove_spectral_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.skip_init.html">torch.nn.utils.skip_init</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.BasePruningMethod.html">BasePruningMethod</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.PruningContainer.html">PruningContainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.Identity_class.html">Identity</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.RandomUnstructured.html">RandomUnstructured</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.L1Unstructured.html">L1Unstructured</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.RandomStructured.html">RandomStructured</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.LnStructured.html">LnStructured</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.CustomFromMask.html">CustomFromMask</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.identity_function.html">torch.nn.utils.prune.identity</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.random_unstructured.html">torch.nn.utils.prune.random_unstructured</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.l1_unstructured.html">torch.nn.utils.prune.l1_unstructured</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.random_structured.html">torch.nn.utils.prune.random_structured</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.ln_structured.html">torch.nn.utils.prune.ln_structured</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.global_unstructured.html">torch.nn.utils.prune.global_unstructured</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.custom_from_mask.html">torch.nn.utils.prune.custom_from_mask</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.remove.html">torch.nn.utils.prune.remove</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.prune.is_pruned.html">torch.nn.utils.prune.is_pruned</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.parametrizations.orthogonal.html">torch.nn.utils.parametrizations.orthogonal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.parametrizations.weight_norm.html">torch.nn.utils.parametrizations.weight_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.parametrizations.spectral_norm.html">torch.nn.utils.parametrizations.spectral_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.parametrize.register_parametrization.html">torch.nn.utils.parametrize.register_parametrization</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.parametrize.remove_parametrizations.html">torch.nn.utils.parametrize.remove_parametrizations</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.parametrize.cached.html">torch.nn.utils.parametrize.cached</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.parametrize.is_parametrized.html">torch.nn.utils.parametrize.is_parametrized</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.parametrize.transfer_parametrizations_and_params.html">torch.nn.utils.parametrize.transfer_parametrizations_and_params</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.parametrize.type_before_parametrizations.html">torch.nn.utils.parametrize.type_before_parametrizations</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.parametrize.ParametrizationList.html">ParametrizationList</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.stateless.functional_call.html">torch.nn.utils.stateless.functional_call</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.rnn.PackedSequence.html">PackedSequence</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.rnn.pack_padded_sequence.html">torch.nn.utils.rnn.pack_padded_sequence</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.rnn.pad_packed_sequence.html">torch.nn.utils.rnn.pad_packed_sequence</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.rnn.pad_sequence.html">torch.nn.utils.rnn.pad_sequence</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.rnn.pack_sequence.html">torch.nn.utils.rnn.pack_sequence</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.rnn.unpack_sequence.html">torch.nn.utils.rnn.unpack_sequence</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.rnn.unpad_sequence.html">torch.nn.utils.rnn.unpad_sequence</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.utils.rnn.invert_permutation.html">torch.nn.utils.rnn.invert_permutation</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.parameter.is_lazy.html">torch.nn.parameter.is_lazy</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.factory_kwargs.html">torch.nn.factory_kwargs</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.flatten.Flatten.html">Flatten</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.flatten.Unflatten.html">Unflatten</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.modules.lazy.LazyModuleMixin.html">LazyModuleMixin</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nn.functional.html">torch.nn.functional</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.conv1d.html">torch.nn.functional.conv1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.conv2d.html">torch.nn.functional.conv2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.conv3d.html">torch.nn.functional.conv3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.conv_transpose1d.html">torch.nn.functional.conv_transpose1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.conv_transpose2d.html">torch.nn.functional.conv_transpose2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.conv_transpose3d.html">torch.nn.functional.conv_transpose3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.unfold.html">torch.nn.functional.unfold</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.fold.html">torch.nn.functional.fold</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.avg_pool1d.html">torch.nn.functional.avg_pool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.avg_pool2d.html">torch.nn.functional.avg_pool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.avg_pool3d.html">torch.nn.functional.avg_pool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.max_pool1d.html">torch.nn.functional.max_pool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.max_pool2d.html">torch.nn.functional.max_pool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.max_pool3d.html">torch.nn.functional.max_pool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.max_unpool1d.html">torch.nn.functional.max_unpool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.max_unpool2d.html">torch.nn.functional.max_unpool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.max_unpool3d.html">torch.nn.functional.max_unpool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.lp_pool1d.html">torch.nn.functional.lp_pool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.lp_pool2d.html">torch.nn.functional.lp_pool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.lp_pool3d.html">torch.nn.functional.lp_pool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.adaptive_max_pool1d.html">torch.nn.functional.adaptive_max_pool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.adaptive_max_pool2d.html">torch.nn.functional.adaptive_max_pool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.adaptive_max_pool3d.html">torch.nn.functional.adaptive_max_pool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.adaptive_avg_pool1d.html">torch.nn.functional.adaptive_avg_pool1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.adaptive_avg_pool2d.html">torch.nn.functional.adaptive_avg_pool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.adaptive_avg_pool3d.html">torch.nn.functional.adaptive_avg_pool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.fractional_max_pool2d.html">torch.nn.functional.fractional_max_pool2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.fractional_max_pool3d.html">torch.nn.functional.fractional_max_pool3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.scaled_dot_product_attention.html">torch.nn.functional.scaled_dot_product_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.threshold.html">torch.nn.functional.threshold</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.threshold_.html">torch.nn.functional.threshold_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.relu.html">torch.nn.functional.relu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.relu_.html">torch.nn.functional.relu_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.hardtanh.html">torch.nn.functional.hardtanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.hardtanh_.html">torch.nn.functional.hardtanh_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.hardswish.html">torch.nn.functional.hardswish</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.relu6.html">torch.nn.functional.relu6</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.elu.html">torch.nn.functional.elu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.elu_.html">torch.nn.functional.elu_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.selu.html">torch.nn.functional.selu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.celu.html">torch.nn.functional.celu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.leaky_relu.html">torch.nn.functional.leaky_relu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.leaky_relu_.html">torch.nn.functional.leaky_relu_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.prelu.html">torch.nn.functional.prelu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.rrelu.html">torch.nn.functional.rrelu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.rrelu_.html">torch.nn.functional.rrelu_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.glu.html">torch.nn.functional.glu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.gelu.html">torch.nn.functional.gelu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.logsigmoid.html">torch.nn.functional.logsigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.hardshrink.html">torch.nn.functional.hardshrink</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.tanhshrink.html">torch.nn.functional.tanhshrink</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.softsign.html">torch.nn.functional.softsign</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.softplus.html">torch.nn.functional.softplus</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.softmin.html">torch.nn.functional.softmin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.softmax.html">torch.nn.functional.softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.softshrink.html">torch.nn.functional.softshrink</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.gumbel_softmax.html">torch.nn.functional.gumbel_softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.log_softmax.html">torch.nn.functional.log_softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.tanh.html">torch.nn.functional.tanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.sigmoid.html">torch.nn.functional.sigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.hardsigmoid.html">torch.nn.functional.hardsigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.silu.html">torch.nn.functional.silu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.mish.html">torch.nn.functional.mish</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.batch_norm.html">torch.nn.functional.batch_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.group_norm.html">torch.nn.functional.group_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.instance_norm.html">torch.nn.functional.instance_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.layer_norm.html">torch.nn.functional.layer_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.local_response_norm.html">torch.nn.functional.local_response_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.rms_norm.html">torch.nn.functional.rms_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.normalize.html">torch.nn.functional.normalize</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.linear.html">torch.nn.functional.linear</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.bilinear.html">torch.nn.functional.bilinear</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.dropout.html">torch.nn.functional.dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.alpha_dropout.html">torch.nn.functional.alpha_dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.feature_alpha_dropout.html">torch.nn.functional.feature_alpha_dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.dropout1d.html">torch.nn.functional.dropout1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.dropout2d.html">torch.nn.functional.dropout2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.dropout3d.html">torch.nn.functional.dropout3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.embedding.html">torch.nn.functional.embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.embedding_bag.html">torch.nn.functional.embedding_bag</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.one_hot.html">torch.nn.functional.one_hot</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.pairwise_distance.html">torch.nn.functional.pairwise_distance</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.cosine_similarity.html">torch.nn.functional.cosine_similarity</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.pdist.html">torch.nn.functional.pdist</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.binary_cross_entropy.html">torch.nn.functional.binary_cross_entropy</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.binary_cross_entropy_with_logits.html">torch.nn.functional.binary_cross_entropy_with_logits</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.poisson_nll_loss.html">torch.nn.functional.poisson_nll_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.cosine_embedding_loss.html">torch.nn.functional.cosine_embedding_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.cross_entropy.html">torch.nn.functional.cross_entropy</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.ctc_loss.html">torch.nn.functional.ctc_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.gaussian_nll_loss.html">torch.nn.functional.gaussian_nll_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.hinge_embedding_loss.html">torch.nn.functional.hinge_embedding_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.kl_div.html">torch.nn.functional.kl_div</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.l1_loss.html">torch.nn.functional.l1_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.mse_loss.html">torch.nn.functional.mse_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.margin_ranking_loss.html">torch.nn.functional.margin_ranking_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.multilabel_margin_loss.html">torch.nn.functional.multilabel_margin_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.multilabel_soft_margin_loss.html">torch.nn.functional.multilabel_soft_margin_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.multi_margin_loss.html">torch.nn.functional.multi_margin_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.nll_loss.html">torch.nn.functional.nll_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.huber_loss.html">torch.nn.functional.huber_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.smooth_l1_loss.html">torch.nn.functional.smooth_l1_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.soft_margin_loss.html">torch.nn.functional.soft_margin_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.triplet_margin_loss.html">torch.nn.functional.triplet_margin_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.triplet_margin_with_distance_loss.html">torch.nn.functional.triplet_margin_with_distance_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.pixel_shuffle.html">torch.nn.functional.pixel_shuffle</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.pixel_unshuffle.html">torch.nn.functional.pixel_unshuffle</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.pad.html">torch.nn.functional.pad</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.interpolate.html">torch.nn.functional.interpolate</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.upsample.html">torch.nn.functional.upsample</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.upsample_nearest.html">torch.nn.functional.upsample_nearest</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.upsample_bilinear.html">torch.nn.functional.upsample_bilinear</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.grid_sample.html">torch.nn.functional.grid_sample</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.affine_grid.html">torch.nn.functional.affine_grid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.torch.nn.parallel.data_parallel.html">torch.nn.functional.torch.nn.parallel.data_parallel</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.ScalingType.html">ScalingType</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.SwizzleType.html">SwizzleType</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.grouped_mm.html">torch.nn.functional.grouped_mm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.scaled_mm.html">torch.nn.functional.scaled_mm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.scaled_grouped_mm.html">torch.nn.functional.scaled_grouped_mm</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tensors.html">torch.Tensor</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.new_tensor.html">torch.Tensor.new_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.new_full.html">torch.Tensor.new_full</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.new_empty.html">torch.Tensor.new_empty</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.new_ones.html">torch.Tensor.new_ones</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.new_zeros.html">torch.Tensor.new_zeros</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_cuda.html">torch.Tensor.is_cuda</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_quantized.html">torch.Tensor.is_quantized</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_meta.html">torch.Tensor.is_meta</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.device.html">torch.Tensor.device</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.grad.html">torch.Tensor.grad</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.ndim.html">torch.Tensor.ndim</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.real.html">torch.Tensor.real</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.imag.html">torch.Tensor.imag</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.nbytes.html">torch.Tensor.nbytes</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.itemsize.html">torch.Tensor.itemsize</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.abs.html">torch.Tensor.abs</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.abs_.html">torch.Tensor.abs_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.absolute.html">torch.Tensor.absolute</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.absolute_.html">torch.Tensor.absolute_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.acos.html">torch.Tensor.acos</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.acos_.html">torch.Tensor.acos_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.arccos.html">torch.Tensor.arccos</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.arccos_.html">torch.Tensor.arccos_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.add.html">torch.Tensor.add</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.add_.html">torch.Tensor.add_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.addbmm.html">torch.Tensor.addbmm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.addbmm_.html">torch.Tensor.addbmm_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.addcdiv.html">torch.Tensor.addcdiv</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.addcdiv_.html">torch.Tensor.addcdiv_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.addcmul.html">torch.Tensor.addcmul</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.addcmul_.html">torch.Tensor.addcmul_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.addmm.html">torch.Tensor.addmm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.addmm_.html">torch.Tensor.addmm_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sspaddmm.html">torch.Tensor.sspaddmm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.addmv.html">torch.Tensor.addmv</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.addmv_.html">torch.Tensor.addmv_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.addr.html">torch.Tensor.addr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.addr_.html">torch.Tensor.addr_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.adjoint.html">torch.Tensor.adjoint</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.allclose.html">torch.Tensor.allclose</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.amax.html">torch.Tensor.amax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.amin.html">torch.Tensor.amin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.aminmax.html">torch.Tensor.aminmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.angle.html">torch.Tensor.angle</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.apply_.html">torch.Tensor.apply_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.argmax.html">torch.Tensor.argmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.argmin.html">torch.Tensor.argmin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.argsort.html">torch.Tensor.argsort</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.argwhere.html">torch.Tensor.argwhere</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.asin.html">torch.Tensor.asin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.asin_.html">torch.Tensor.asin_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.arcsin.html">torch.Tensor.arcsin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.arcsin_.html">torch.Tensor.arcsin_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.as_strided.html">torch.Tensor.as_strided</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.atan.html">torch.Tensor.atan</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.atan_.html">torch.Tensor.atan_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.arctan.html">torch.Tensor.arctan</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.arctan_.html">torch.Tensor.arctan_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.atan2.html">torch.Tensor.atan2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.atan2_.html">torch.Tensor.atan2_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.arctan2.html">torch.Tensor.arctan2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.arctan2_.html">torch.Tensor.arctan2_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.all.html">torch.Tensor.all</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.any.html">torch.Tensor.any</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.backward.html">torch.Tensor.backward</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.baddbmm.html">torch.Tensor.baddbmm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.baddbmm_.html">torch.Tensor.baddbmm_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bernoulli.html">torch.Tensor.bernoulli</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bernoulli_.html">torch.Tensor.bernoulli_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bfloat16.html">torch.Tensor.bfloat16</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bincount.html">torch.Tensor.bincount</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bitwise_not.html">torch.Tensor.bitwise_not</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bitwise_not_.html">torch.Tensor.bitwise_not_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bitwise_and.html">torch.Tensor.bitwise_and</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bitwise_and_.html">torch.Tensor.bitwise_and_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bitwise_or.html">torch.Tensor.bitwise_or</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bitwise_or_.html">torch.Tensor.bitwise_or_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bitwise_xor.html">torch.Tensor.bitwise_xor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bitwise_xor_.html">torch.Tensor.bitwise_xor_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bitwise_left_shift.html">torch.Tensor.bitwise_left_shift</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bitwise_left_shift_.html">torch.Tensor.bitwise_left_shift_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bitwise_right_shift.html">torch.Tensor.bitwise_right_shift</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bitwise_right_shift_.html">torch.Tensor.bitwise_right_shift_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bmm.html">torch.Tensor.bmm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.bool.html">torch.Tensor.bool</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.byte.html">torch.Tensor.byte</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.broadcast_to.html">torch.Tensor.broadcast_to</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cauchy_.html">torch.Tensor.cauchy_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.ceil.html">torch.Tensor.ceil</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.ceil_.html">torch.Tensor.ceil_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.char.html">torch.Tensor.char</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cholesky.html">torch.Tensor.cholesky</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cholesky_inverse.html">torch.Tensor.cholesky_inverse</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cholesky_solve.html">torch.Tensor.cholesky_solve</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.chunk.html">torch.Tensor.chunk</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.clamp.html">torch.Tensor.clamp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.clamp_.html">torch.Tensor.clamp_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.clip.html">torch.Tensor.clip</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.clip_.html">torch.Tensor.clip_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.clone.html">torch.Tensor.clone</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.contiguous.html">torch.Tensor.contiguous</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.copy_.html">torch.Tensor.copy_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.conj.html">torch.Tensor.conj</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.conj_physical.html">torch.Tensor.conj_physical</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.conj_physical_.html">torch.Tensor.conj_physical_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.resolve_conj.html">torch.Tensor.resolve_conj</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.resolve_neg.html">torch.Tensor.resolve_neg</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.copysign.html">torch.Tensor.copysign</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.copysign_.html">torch.Tensor.copysign_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cos.html">torch.Tensor.cos</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cos_.html">torch.Tensor.cos_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cosh.html">torch.Tensor.cosh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cosh_.html">torch.Tensor.cosh_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.corrcoef.html">torch.Tensor.corrcoef</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.count_nonzero.html">torch.Tensor.count_nonzero</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cov.html">torch.Tensor.cov</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.acosh.html">torch.Tensor.acosh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.acosh_.html">torch.Tensor.acosh_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.arccosh.html">torch.Tensor.arccosh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.arccosh_.html">torch.Tensor.arccosh_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cpu.html">torch.Tensor.cpu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cross.html">torch.Tensor.cross</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cuda.html">torch.Tensor.cuda</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.logcumsumexp.html">torch.Tensor.logcumsumexp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cummax.html">torch.Tensor.cummax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cummin.html">torch.Tensor.cummin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cumprod.html">torch.Tensor.cumprod</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cumprod_.html">torch.Tensor.cumprod_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cumsum.html">torch.Tensor.cumsum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cumsum_.html">torch.Tensor.cumsum_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.chalf.html">torch.Tensor.chalf</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cfloat.html">torch.Tensor.cfloat</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.cdouble.html">torch.Tensor.cdouble</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.data_ptr.html">torch.Tensor.data_ptr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.deg2rad.html">torch.Tensor.deg2rad</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.dequantize.html">torch.Tensor.dequantize</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.det.html">torch.Tensor.det</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.dense_dim.html">torch.Tensor.dense_dim</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.detach.html">torch.Tensor.detach</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.detach_.html">torch.Tensor.detach_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.diag.html">torch.Tensor.diag</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.diag_embed.html">torch.Tensor.diag_embed</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.diagflat.html">torch.Tensor.diagflat</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.diagonal.html">torch.Tensor.diagonal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.diagonal_scatter.html">torch.Tensor.diagonal_scatter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.fill_diagonal_.html">torch.Tensor.fill_diagonal_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.fmax.html">torch.Tensor.fmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.fmin.html">torch.Tensor.fmin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.diff.html">torch.Tensor.diff</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.digamma.html">torch.Tensor.digamma</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.digamma_.html">torch.Tensor.digamma_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.dim.html">torch.Tensor.dim</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.dim_order.html">torch.Tensor.dim_order</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.dist.html">torch.Tensor.dist</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.div.html">torch.Tensor.div</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.div_.html">torch.Tensor.div_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.divide.html">torch.Tensor.divide</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.divide_.html">torch.Tensor.divide_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.dot.html">torch.Tensor.dot</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.double.html">torch.Tensor.double</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.dsplit.html">torch.Tensor.dsplit</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.element_size.html">torch.Tensor.element_size</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.eq.html">torch.Tensor.eq</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.eq_.html">torch.Tensor.eq_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.equal.html">torch.Tensor.equal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.erf.html">torch.Tensor.erf</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.erf_.html">torch.Tensor.erf_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.erfc.html">torch.Tensor.erfc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.erfc_.html">torch.Tensor.erfc_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.erfinv.html">torch.Tensor.erfinv</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.erfinv_.html">torch.Tensor.erfinv_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.exp.html">torch.Tensor.exp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.exp_.html">torch.Tensor.exp_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.expm1.html">torch.Tensor.expm1</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.expm1_.html">torch.Tensor.expm1_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.expand.html">torch.Tensor.expand</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.expand_as.html">torch.Tensor.expand_as</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.exponential_.html">torch.Tensor.exponential_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.fix.html">torch.Tensor.fix</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.fix_.html">torch.Tensor.fix_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.fill_.html">torch.Tensor.fill_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.flatten.html">torch.Tensor.flatten</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.flip.html">torch.Tensor.flip</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.fliplr.html">torch.Tensor.fliplr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.flipud.html">torch.Tensor.flipud</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.float.html">torch.Tensor.float</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.float_power.html">torch.Tensor.float_power</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.float_power_.html">torch.Tensor.float_power_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.floor.html">torch.Tensor.floor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.floor_.html">torch.Tensor.floor_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.floor_divide.html">torch.Tensor.floor_divide</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.floor_divide_.html">torch.Tensor.floor_divide_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.fmod.html">torch.Tensor.fmod</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.fmod_.html">torch.Tensor.fmod_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.frac.html">torch.Tensor.frac</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.frac_.html">torch.Tensor.frac_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.frexp.html">torch.Tensor.frexp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.gather.html">torch.Tensor.gather</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.gcd.html">torch.Tensor.gcd</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.gcd_.html">torch.Tensor.gcd_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.ge.html">torch.Tensor.ge</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.ge_.html">torch.Tensor.ge_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.greater_equal.html">torch.Tensor.greater_equal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.greater_equal_.html">torch.Tensor.greater_equal_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.geometric_.html">torch.Tensor.geometric_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.geqrf.html">torch.Tensor.geqrf</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.ger.html">torch.Tensor.ger</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.get_device.html">torch.Tensor.get_device</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.gt.html">torch.Tensor.gt</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.gt_.html">torch.Tensor.gt_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.greater.html">torch.Tensor.greater</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.greater_.html">torch.Tensor.greater_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.half.html">torch.Tensor.half</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.hardshrink.html">torch.Tensor.hardshrink</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.heaviside.html">torch.Tensor.heaviside</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.histc.html">torch.Tensor.histc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.histogram.html">torch.Tensor.histogram</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.hsplit.html">torch.Tensor.hsplit</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.hypot.html">torch.Tensor.hypot</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.hypot_.html">torch.Tensor.hypot_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.i0.html">torch.Tensor.i0</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.i0_.html">torch.Tensor.i0_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.igamma.html">torch.Tensor.igamma</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.igamma_.html">torch.Tensor.igamma_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.igammac.html">torch.Tensor.igammac</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.igammac_.html">torch.Tensor.igammac_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.index_add_.html">torch.Tensor.index_add_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.index_add.html">torch.Tensor.index_add</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.index_copy_.html">torch.Tensor.index_copy_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.index_copy.html">torch.Tensor.index_copy</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.index_fill_.html">torch.Tensor.index_fill_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.index_fill.html">torch.Tensor.index_fill</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.index_put_.html">torch.Tensor.index_put_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.index_put.html">torch.Tensor.index_put</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.index_reduce_.html">torch.Tensor.index_reduce_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.index_reduce.html">torch.Tensor.index_reduce</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.index_select.html">torch.Tensor.index_select</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.indices.html">torch.Tensor.indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.inner.html">torch.Tensor.inner</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.int.html">torch.Tensor.int</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.int_repr.html">torch.Tensor.int_repr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.inverse.html">torch.Tensor.inverse</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.isclose.html">torch.Tensor.isclose</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.isfinite.html">torch.Tensor.isfinite</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.isinf.html">torch.Tensor.isinf</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.isposinf.html">torch.Tensor.isposinf</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.isneginf.html">torch.Tensor.isneginf</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.isnan.html">torch.Tensor.isnan</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_contiguous.html">torch.Tensor.is_contiguous</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_complex.html">torch.Tensor.is_complex</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_conj.html">torch.Tensor.is_conj</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_floating_point.html">torch.Tensor.is_floating_point</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_inference.html">torch.Tensor.is_inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_leaf.html">torch.Tensor.is_leaf</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_pinned.html">torch.Tensor.is_pinned</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_set_to.html">torch.Tensor.is_set_to</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_shared.html">torch.Tensor.is_shared</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_signed.html">torch.Tensor.is_signed</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_sparse.html">torch.Tensor.is_sparse</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.istft.html">torch.Tensor.istft</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.isreal.html">torch.Tensor.isreal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.item.html">torch.Tensor.item</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.kthvalue.html">torch.Tensor.kthvalue</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.lcm.html">torch.Tensor.lcm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.lcm_.html">torch.Tensor.lcm_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.ldexp.html">torch.Tensor.ldexp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.ldexp_.html">torch.Tensor.ldexp_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.le.html">torch.Tensor.le</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.le_.html">torch.Tensor.le_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.less_equal.html">torch.Tensor.less_equal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.less_equal_.html">torch.Tensor.less_equal_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.lerp.html">torch.Tensor.lerp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.lerp_.html">torch.Tensor.lerp_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.lgamma.html">torch.Tensor.lgamma</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.lgamma_.html">torch.Tensor.lgamma_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.log.html">torch.Tensor.log</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.log_.html">torch.Tensor.log_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.logdet.html">torch.Tensor.logdet</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.log10.html">torch.Tensor.log10</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.log10_.html">torch.Tensor.log10_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.log1p.html">torch.Tensor.log1p</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.log1p_.html">torch.Tensor.log1p_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.log2.html">torch.Tensor.log2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.log2_.html">torch.Tensor.log2_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.log_normal_.html">torch.Tensor.log_normal_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.logaddexp.html">torch.Tensor.logaddexp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.logaddexp2.html">torch.Tensor.logaddexp2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.logsumexp.html">torch.Tensor.logsumexp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.logical_and.html">torch.Tensor.logical_and</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.logical_and_.html">torch.Tensor.logical_and_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.logical_not.html">torch.Tensor.logical_not</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.logical_not_.html">torch.Tensor.logical_not_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.logical_or.html">torch.Tensor.logical_or</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.logical_or_.html">torch.Tensor.logical_or_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.logical_xor.html">torch.Tensor.logical_xor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.logical_xor_.html">torch.Tensor.logical_xor_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.logit.html">torch.Tensor.logit</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.logit_.html">torch.Tensor.logit_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.long.html">torch.Tensor.long</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.lt.html">torch.Tensor.lt</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.lt_.html">torch.Tensor.lt_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.less.html">torch.Tensor.less</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.less_.html">torch.Tensor.less_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.lu.html">torch.Tensor.lu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.lu_solve.html">torch.Tensor.lu_solve</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.as_subclass.html">torch.Tensor.as_subclass</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.map_.html">torch.Tensor.map_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.masked_scatter_.html">torch.Tensor.masked_scatter_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.masked_scatter.html">torch.Tensor.masked_scatter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.masked_fill_.html">torch.Tensor.masked_fill_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.masked_fill.html">torch.Tensor.masked_fill</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.masked_select.html">torch.Tensor.masked_select</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.matmul.html">torch.Tensor.matmul</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.matrix_power.html">torch.Tensor.matrix_power</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.matrix_exp.html">torch.Tensor.matrix_exp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.max.html">torch.Tensor.max</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.maximum.html">torch.Tensor.maximum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.mean.html">torch.Tensor.mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.module_load.html">torch.Tensor.module_load</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.nanmean.html">torch.Tensor.nanmean</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.median.html">torch.Tensor.median</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.nanmedian.html">torch.Tensor.nanmedian</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.min.html">torch.Tensor.min</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.minimum.html">torch.Tensor.minimum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.mm.html">torch.Tensor.mm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.smm.html">torch.Tensor.smm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.mode.html">torch.Tensor.mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.movedim.html">torch.Tensor.movedim</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.moveaxis.html">torch.Tensor.moveaxis</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.msort.html">torch.Tensor.msort</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.mul.html">torch.Tensor.mul</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.mul_.html">torch.Tensor.mul_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.multiply.html">torch.Tensor.multiply</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.multiply_.html">torch.Tensor.multiply_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.multinomial.html">torch.Tensor.multinomial</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.mv.html">torch.Tensor.mv</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.mvlgamma.html">torch.Tensor.mvlgamma</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.mvlgamma_.html">torch.Tensor.mvlgamma_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.nansum.html">torch.Tensor.nansum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.narrow.html">torch.Tensor.narrow</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.narrow_copy.html">torch.Tensor.narrow_copy</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.ndimension.html">torch.Tensor.ndimension</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.nan_to_num.html">torch.Tensor.nan_to_num</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.nan_to_num_.html">torch.Tensor.nan_to_num_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.ne.html">torch.Tensor.ne</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.ne_.html">torch.Tensor.ne_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.not_equal.html">torch.Tensor.not_equal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.not_equal_.html">torch.Tensor.not_equal_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.neg.html">torch.Tensor.neg</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.neg_.html">torch.Tensor.neg_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.negative.html">torch.Tensor.negative</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.negative_.html">torch.Tensor.negative_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.nelement.html">torch.Tensor.nelement</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.nextafter.html">torch.Tensor.nextafter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.nextafter_.html">torch.Tensor.nextafter_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.nonzero.html">torch.Tensor.nonzero</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.norm.html">torch.Tensor.norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.normal_.html">torch.Tensor.normal_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.numel.html">torch.Tensor.numel</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.numpy.html">torch.Tensor.numpy</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.orgqr.html">torch.Tensor.orgqr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.ormqr.html">torch.Tensor.ormqr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.outer.html">torch.Tensor.outer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.permute.html">torch.Tensor.permute</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.pin_memory.html">torch.Tensor.pin_memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.pinverse.html">torch.Tensor.pinverse</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.polygamma.html">torch.Tensor.polygamma</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.polygamma_.html">torch.Tensor.polygamma_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.positive.html">torch.Tensor.positive</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.pow.html">torch.Tensor.pow</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.pow_.html">torch.Tensor.pow_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.prod.html">torch.Tensor.prod</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.put_.html">torch.Tensor.put_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.qr.html">torch.Tensor.qr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.qscheme.html">torch.Tensor.qscheme</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.quantile.html">torch.Tensor.quantile</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.nanquantile.html">torch.Tensor.nanquantile</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.q_scale.html">torch.Tensor.q_scale</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.q_zero_point.html">torch.Tensor.q_zero_point</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.q_per_channel_scales.html">torch.Tensor.q_per_channel_scales</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.q_per_channel_zero_points.html">torch.Tensor.q_per_channel_zero_points</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.q_per_channel_axis.html">torch.Tensor.q_per_channel_axis</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.rad2deg.html">torch.Tensor.rad2deg</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.random_.html">torch.Tensor.random_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.ravel.html">torch.Tensor.ravel</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.reciprocal.html">torch.Tensor.reciprocal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.reciprocal_.html">torch.Tensor.reciprocal_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.record_stream.html">torch.Tensor.record_stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.register_hook.html">torch.Tensor.register_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.register_post_accumulate_grad_hook.html">torch.Tensor.register_post_accumulate_grad_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.remainder.html">torch.Tensor.remainder</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.remainder_.html">torch.Tensor.remainder_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.renorm.html">torch.Tensor.renorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.renorm_.html">torch.Tensor.renorm_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.repeat.html">torch.Tensor.repeat</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.repeat_interleave.html">torch.Tensor.repeat_interleave</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.requires_grad.html">torch.Tensor.requires_grad</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.requires_grad_.html">torch.Tensor.requires_grad_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.reshape.html">torch.Tensor.reshape</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.reshape_as.html">torch.Tensor.reshape_as</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.resize_.html">torch.Tensor.resize_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.resize_as_.html">torch.Tensor.resize_as_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.retain_grad.html">torch.Tensor.retain_grad</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.retains_grad.html">torch.Tensor.retains_grad</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.roll.html">torch.Tensor.roll</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.rot90.html">torch.Tensor.rot90</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.round.html">torch.Tensor.round</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.round_.html">torch.Tensor.round_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.rsqrt.html">torch.Tensor.rsqrt</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.rsqrt_.html">torch.Tensor.rsqrt_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.scatter.html">torch.Tensor.scatter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.scatter_.html">torch.Tensor.scatter_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.scatter_add_.html">torch.Tensor.scatter_add_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.scatter_add.html">torch.Tensor.scatter_add</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.scatter_reduce_.html">torch.Tensor.scatter_reduce_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.scatter_reduce.html">torch.Tensor.scatter_reduce</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.select.html">torch.Tensor.select</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.select_scatter.html">torch.Tensor.select_scatter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.set_.html">torch.Tensor.set_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.share_memory_.html">torch.Tensor.share_memory_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.short.html">torch.Tensor.short</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sigmoid.html">torch.Tensor.sigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sigmoid_.html">torch.Tensor.sigmoid_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sign.html">torch.Tensor.sign</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sign_.html">torch.Tensor.sign_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.signbit.html">torch.Tensor.signbit</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sgn.html">torch.Tensor.sgn</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sgn_.html">torch.Tensor.sgn_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sin.html">torch.Tensor.sin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sin_.html">torch.Tensor.sin_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sinc.html">torch.Tensor.sinc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sinc_.html">torch.Tensor.sinc_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sinh.html">torch.Tensor.sinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sinh_.html">torch.Tensor.sinh_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.asinh.html">torch.Tensor.asinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.asinh_.html">torch.Tensor.asinh_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.arcsinh.html">torch.Tensor.arcsinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.arcsinh_.html">torch.Tensor.arcsinh_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.shape.html">torch.Tensor.shape</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.size.html">torch.Tensor.size</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.slogdet.html">torch.Tensor.slogdet</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.slice_scatter.html">torch.Tensor.slice_scatter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.softmax.html">torch.Tensor.softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sort.html">torch.Tensor.sort</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.split.html">torch.Tensor.split</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sparse_mask.html">torch.Tensor.sparse_mask</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sparse_dim.html">torch.Tensor.sparse_dim</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sqrt.html">torch.Tensor.sqrt</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sqrt_.html">torch.Tensor.sqrt_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.square.html">torch.Tensor.square</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.square_.html">torch.Tensor.square_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.squeeze.html">torch.Tensor.squeeze</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.squeeze_.html">torch.Tensor.squeeze_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.std.html">torch.Tensor.std</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.stft.html">torch.Tensor.stft</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.storage.html">torch.Tensor.storage</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.untyped_storage.html">torch.Tensor.untyped_storage</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.storage_offset.html">torch.Tensor.storage_offset</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.storage_type.html">torch.Tensor.storage_type</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.stride.html">torch.Tensor.stride</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sub.html">torch.Tensor.sub</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sub_.html">torch.Tensor.sub_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.subtract.html">torch.Tensor.subtract</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.subtract_.html">torch.Tensor.subtract_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sum.html">torch.Tensor.sum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sum_to_size.html">torch.Tensor.sum_to_size</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.svd.html">torch.Tensor.svd</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.swapaxes.html">torch.Tensor.swapaxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.swapdims.html">torch.Tensor.swapdims</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.t.html">torch.Tensor.t</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.t_.html">torch.Tensor.t_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.tensor_split.html">torch.Tensor.tensor_split</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.tile.html">torch.Tensor.tile</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.to.html">torch.Tensor.to</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.to_mkldnn.html">torch.Tensor.to_mkldnn</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.take.html">torch.Tensor.take</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.take_along_dim.html">torch.Tensor.take_along_dim</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.tan.html">torch.Tensor.tan</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.tan_.html">torch.Tensor.tan_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.tanh.html">torch.Tensor.tanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.tanh_.html">torch.Tensor.tanh_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.atanh.html">torch.Tensor.atanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.atanh_.html">torch.Tensor.atanh_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.arctanh.html">torch.Tensor.arctanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.arctanh_.html">torch.Tensor.arctanh_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.tolist.html">torch.Tensor.tolist</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.topk.html">torch.Tensor.topk</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.to_dense.html">torch.Tensor.to_dense</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.to_sparse.html">torch.Tensor.to_sparse</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.to_sparse_csr.html">torch.Tensor.to_sparse_csr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.to_sparse_csc.html">torch.Tensor.to_sparse_csc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.to_sparse_bsr.html">torch.Tensor.to_sparse_bsr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.to_sparse_bsc.html">torch.Tensor.to_sparse_bsc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.trace.html">torch.Tensor.trace</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.transpose.html">torch.Tensor.transpose</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.transpose_.html">torch.Tensor.transpose_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.triangular_solve.html">torch.Tensor.triangular_solve</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.tril.html">torch.Tensor.tril</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.tril_.html">torch.Tensor.tril_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.triu.html">torch.Tensor.triu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.triu_.html">torch.Tensor.triu_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.true_divide.html">torch.Tensor.true_divide</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.true_divide_.html">torch.Tensor.true_divide_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.trunc.html">torch.Tensor.trunc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.trunc_.html">torch.Tensor.trunc_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.type.html">torch.Tensor.type</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.type_as.html">torch.Tensor.type_as</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.unbind.html">torch.Tensor.unbind</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.unflatten.html">torch.Tensor.unflatten</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.unfold.html">torch.Tensor.unfold</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.uniform_.html">torch.Tensor.uniform_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.unique.html">torch.Tensor.unique</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.unique_consecutive.html">torch.Tensor.unique_consecutive</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.unsqueeze.html">torch.Tensor.unsqueeze</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.unsqueeze_.html">torch.Tensor.unsqueeze_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.values.html">torch.Tensor.values</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.var.html">torch.Tensor.var</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.vdot.html">torch.Tensor.vdot</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.view.html">torch.Tensor.view</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.view_as.html">torch.Tensor.view_as</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.vsplit.html">torch.Tensor.vsplit</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.where.html">torch.Tensor.where</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.xlogy.html">torch.Tensor.xlogy</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.xlogy_.html">torch.Tensor.xlogy_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.xpu.html">torch.Tensor.xpu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.zero_.html">torch.Tensor.zero_</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="../amp.html">torch.amp</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../autograd.html">torch.autograd</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.backward.html">torch.autograd.backward</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.grad.html">torch.autograd.grad</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.forward_ad.dual_level.html">dual_level</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.forward_ad.make_dual.html">torch.autograd.forward_ad.make_dual</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.forward_ad.unpack_dual.html">torch.autograd.forward_ad.unpack_dual</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.forward_ad.enter_dual_level.html">torch.autograd.forward_ad.enter_dual_level</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.forward_ad.exit_dual_level.html">torch.autograd.forward_ad.exit_dual_level</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.forward_ad.UnpackedDualTensor.html">UnpackedDualTensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.functional.jacobian.html">torch.autograd.functional.jacobian</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.functional.hessian.html">torch.autograd.functional.hessian</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.functional.vjp.html">torch.autograd.functional.vjp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.functional.jvp.html">torch.autograd.functional.jvp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.functional.vhp.html">torch.autograd.functional.vhp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.functional.hvp.html">torch.autograd.functional.hvp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.Function.forward.html">torch.autograd.Function.forward</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.Function.backward.html">torch.autograd.Function.backward</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.Function.jvp.html">torch.autograd.Function.jvp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.Function.vmap.html">torch.autograd.Function.vmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.function.FunctionCtx.mark_dirty.html">torch.autograd.function.FunctionCtx.mark_dirty</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.function.FunctionCtx.mark_non_differentiable.html">torch.autograd.function.FunctionCtx.mark_non_differentiable</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.function.FunctionCtx.save_for_backward.html">torch.autograd.function.FunctionCtx.save_for_backward</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.function.FunctionCtx.set_materialize_grads.html">torch.autograd.function.FunctionCtx.set_materialize_grads</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.function.once_differentiable.html">torch.autograd.function.once_differentiable</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.function.BackwardCFunction.html">BackwardCFunction</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.function.InplaceFunction.html">InplaceFunction</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.function.NestedIOFunction.html">NestedIOFunction</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.gradcheck.gradcheck.html">torch.autograd.gradcheck.gradcheck</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.gradcheck.gradgradcheck.html">torch.autograd.gradcheck.gradgradcheck</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.gradcheck.GradcheckError.html">torch.autograd.gradcheck.GradcheckError</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.profiler.profile.export_chrome_trace.html">torch.autograd.profiler.profile.export_chrome_trace</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.profiler.profile.key_averages.html">torch.autograd.profiler.profile.key_averages</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.profiler.profile.self_cpu_time_total.html">torch.autograd.profiler.profile.self_cpu_time_total</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.profiler.profile.total_average.html">torch.autograd.profiler.profile.total_average</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.profiler.parse_nvprof_trace.html">torch.autograd.profiler.parse_nvprof_trace</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.profiler.EnforceUnique.html">EnforceUnique</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.profiler.KinetoStepTracker.html">KinetoStepTracker</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.profiler.record_function.html">record_function</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.profiler_util.Interval.html">Interval</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.profiler_util.Kernel.html">Kernel</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.profiler_util.MemRecordsAcc.html">MemRecordsAcc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.profiler_util.StringTable.html">StringTable</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.profiler.load_nvprof.html">torch.autograd.profiler.load_nvprof</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.grad_mode.set_multithreading_enabled.html">set_multithreading_enabled</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.graph.Node.name.html">torch.autograd.graph.Node.name</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.graph.Node.metadata.html">torch.autograd.graph.Node.metadata</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.graph.Node.next_functions.html">torch.autograd.graph.Node.next_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.graph.Node.register_hook.html">torch.autograd.graph.Node.register_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.graph.Node.register_prehook.html">torch.autograd.graph.Node.register_prehook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.autograd.graph.increment_version.html">torch.autograd.graph.increment_version</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../library.html">torch.library</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../accelerator.html">torch.accelerator</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.device_count.html">torch.accelerator.device_count</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.is_available.html">torch.accelerator.is_available</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.current_accelerator.html">torch.accelerator.current_accelerator</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.set_device_index.html">torch.accelerator.set_device_index</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.set_device_idx.html">torch.accelerator.set_device_idx</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.current_device_index.html">torch.accelerator.current_device_index</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.current_device_idx.html">torch.accelerator.current_device_idx</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.set_stream.html">torch.accelerator.set_stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.current_stream.html">torch.accelerator.current_stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.synchronize.html">torch.accelerator.synchronize</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.device_index.html">device_index</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.memory.empty_cache.html">torch.accelerator.memory.empty_cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.memory.get_memory_info.html">torch.accelerator.memory.get_memory_info</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.memory.max_memory_allocated.html">torch.accelerator.memory.max_memory_allocated</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.memory.max_memory_reserved.html">torch.accelerator.memory.max_memory_reserved</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.memory.memory_allocated.html">torch.accelerator.memory.memory_allocated</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.memory.memory_reserved.html">torch.accelerator.memory.memory_reserved</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.memory.memory_stats.html">torch.accelerator.memory.memory_stats</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.memory.reset_accumulated_memory_stats.html">torch.accelerator.memory.reset_accumulated_memory_stats</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.accelerator.memory.reset_peak_memory_stats.html">torch.accelerator.memory.reset_peak_memory_stats</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cpu.html">torch.cpu</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.cpu.current_device.html">torch.cpu.current_device</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cpu.current_stream.html">torch.cpu.current_stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cpu.is_available.html">torch.cpu.is_available</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cpu.is_initialized.html">torch.cpu.is_initialized</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cpu.synchronize.html">torch.cpu.synchronize</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cpu.stream_function.html">torch.cpu.stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cpu.set_device.html">torch.cpu.set_device</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cpu.device_count.html">torch.cpu.device_count</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cpu.StreamContext.html">StreamContext</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cpu.Stream_class.html">Stream</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cuda.html">torch.cuda</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.StreamContext.html">StreamContext</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.can_device_access_peer.html">torch.cuda.can_device_access_peer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.check_error.html">torch.cuda.check_error</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.current_blas_handle.html">torch.cuda.current_blas_handle</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.current_device.html">torch.cuda.current_device</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.current_stream.html">torch.cuda.current_stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.cudart.html">torch.cuda.cudart</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.default_stream.html">torch.cuda.default_stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.device.html">device</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.device_count.html">torch.cuda.device_count</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.device_memory_used.html">torch.cuda.device_memory_used</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.device_of.html">device_of</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.get_arch_list.html">torch.cuda.get_arch_list</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.get_device_capability.html">torch.cuda.get_device_capability</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.get_device_name.html">torch.cuda.get_device_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.get_device_properties.html">torch.cuda.get_device_properties</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.get_gencode_flags.html">torch.cuda.get_gencode_flags</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.get_stream_from_external.html">torch.cuda.get_stream_from_external</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.get_sync_debug_mode.html">torch.cuda.get_sync_debug_mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.init.html">torch.cuda.init</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.ipc_collect.html">torch.cuda.ipc_collect</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.is_available.html">torch.cuda.is_available</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.is_bf16_supported.html">torch.cuda.is_bf16_supported</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.is_initialized.html">torch.cuda.is_initialized</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.is_tf32_supported.html">torch.cuda.is_tf32_supported</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory_usage.html">torch.cuda.memory_usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.set_device.html">torch.cuda.set_device</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.set_stream.html">torch.cuda.set_stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.set_sync_debug_mode.html">torch.cuda.set_sync_debug_mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.stream_function.html">torch.cuda.stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.synchronize.html">torch.cuda.synchronize</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.utilization.html">torch.cuda.utilization</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.temperature.html">torch.cuda.temperature</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.power_draw.html">torch.cuda.power_draw</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.clock_rate.html">torch.cuda.clock_rate</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.AcceleratorError.html">torch.cuda.AcceleratorError</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.OutOfMemoryError.html">torch.cuda.OutOfMemoryError</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.get_rng_state.html">torch.cuda.get_rng_state</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.get_rng_state_all.html">torch.cuda.get_rng_state_all</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.set_rng_state.html">torch.cuda.set_rng_state</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.set_rng_state_all.html">torch.cuda.set_rng_state_all</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.manual_seed.html">torch.cuda.manual_seed</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.manual_seed_all.html">torch.cuda.manual_seed_all</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.seed.html">torch.cuda.seed</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.seed_all.html">torch.cuda.seed_all</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.initial_seed.html">torch.cuda.initial_seed</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.comm.broadcast.html">torch.cuda.comm.broadcast</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.comm.broadcast_coalesced.html">torch.cuda.comm.broadcast_coalesced</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.comm.reduce_add.html">torch.cuda.comm.reduce_add</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.comm.reduce_add_coalesced.html">torch.cuda.comm.reduce_add_coalesced</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.comm.scatter.html">torch.cuda.comm.scatter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.comm.gather.html">torch.cuda.comm.gather</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.Stream_class.html">Stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.ExternalStream.html">ExternalStream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.Event.html">Event</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.is_current_stream_capturing.html">torch.cuda.is_current_stream_capturing</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.graph_pool_handle.html">torch.cuda.graph_pool_handle</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.CUDAGraph.html">CUDAGraph</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.graph.html">graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.make_graphed_callables.html">torch.cuda.make_graphed_callables</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.empty_cache.html">torch.cuda.memory.empty_cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.get_per_process_memory_fraction.html">torch.cuda.memory.get_per_process_memory_fraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.list_gpu_processes.html">torch.cuda.memory.list_gpu_processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.mem_get_info.html">torch.cuda.memory.mem_get_info</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.memory_stats.html">torch.cuda.memory.memory_stats</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.memory_stats_as_nested_dict.html">torch.cuda.memory.memory_stats_as_nested_dict</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.reset_accumulated_memory_stats.html">torch.cuda.memory.reset_accumulated_memory_stats</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.host_memory_stats.html">torch.cuda.memory.host_memory_stats</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.host_memory_stats_as_nested_dict.html">torch.cuda.memory.host_memory_stats_as_nested_dict</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.reset_accumulated_host_memory_stats.html">torch.cuda.memory.reset_accumulated_host_memory_stats</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.memory_summary.html">torch.cuda.memory.memory_summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.memory_snapshot.html">torch.cuda.memory.memory_snapshot</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.memory_allocated.html">torch.cuda.memory.memory_allocated</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.max_memory_allocated.html">torch.cuda.memory.max_memory_allocated</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.reset_max_memory_allocated.html">torch.cuda.memory.reset_max_memory_allocated</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.memory_reserved.html">torch.cuda.memory.memory_reserved</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.max_memory_reserved.html">torch.cuda.memory.max_memory_reserved</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.set_per_process_memory_fraction.html">torch.cuda.memory.set_per_process_memory_fraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.memory_cached.html">torch.cuda.memory.memory_cached</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.max_memory_cached.html">torch.cuda.memory.max_memory_cached</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.reset_max_memory_cached.html">torch.cuda.memory.reset_max_memory_cached</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.reset_peak_memory_stats.html">torch.cuda.memory.reset_peak_memory_stats</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.reset_peak_host_memory_stats.html">torch.cuda.memory.reset_peak_host_memory_stats</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.caching_allocator_alloc.html">torch.cuda.memory.caching_allocator_alloc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.caching_allocator_delete.html">torch.cuda.memory.caching_allocator_delete</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.get_allocator_backend.html">torch.cuda.memory.get_allocator_backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.CUDAPluggableAllocator.html">CUDAPluggableAllocator</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.change_current_allocator.html">torch.cuda.memory.change_current_allocator</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.MemPool.html">MemPool</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.memory.caching_allocator_enable.html">torch.cuda.memory.caching_allocator_enable</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.nvtx.mark.html">torch.cuda.nvtx.mark</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.nvtx.range_push.html">torch.cuda.nvtx.range_push</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.nvtx.range_pop.html">torch.cuda.nvtx.range_pop</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.nvtx.range.html">torch.cuda.nvtx.range</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.jiterator._create_jit_fn.html">torch.cuda.jiterator._create_jit_fn</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.jiterator._create_multi_output_jit_fn.html">torch.cuda.jiterator._create_multi_output_jit_fn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda.tunable.html">TunableOp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda._sanitizer.html">CUDA Stream Sanitizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.gds.gds_register_buffer.html">torch.cuda.gds.gds_register_buffer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.gds.gds_deregister_buffer.html">torch.cuda.gds.gds_deregister_buffer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.gds.GdsFile.html">GdsFile</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cuda.green_contexts.GreenContext.html">GreenContext</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../cuda.aliases.html">Aliases in torch.cuda</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.random.get_rng_state.html">torch.cuda.random.get_rng_state</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.random.get_rng_state_all.html">torch.cuda.random.get_rng_state_all</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.random.set_rng_state.html">torch.cuda.random.set_rng_state</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.random.set_rng_state_all.html">torch.cuda.random.set_rng_state_all</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.random.manual_seed.html">torch.cuda.random.manual_seed</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.random.manual_seed_all.html">torch.cuda.random.manual_seed_all</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.random.seed.html">torch.cuda.random.seed</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.random.seed_all.html">torch.cuda.random.seed_all</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.random.initial_seed.html">torch.cuda.random.initial_seed</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.graphs.is_current_stream_capturing.html">torch.cuda.graphs.is_current_stream_capturing</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.graphs.graph_pool_handle.html">torch.cuda.graphs.graph_pool_handle</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.graphs.CUDAGraph.html">CUDAGraph</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.graphs.graph.html">graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.graphs.make_graphed_callables.html">torch.cuda.graphs.make_graphed_callables</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.streams.Stream.html">Stream</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.streams.ExternalStream.html">ExternalStream</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.cuda.streams.Event.html">Event</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_cuda_memory.html">torch.cuda.memory</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../mps.html">torch.mps</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.device_count.html">torch.mps.device_count</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.synchronize.html">torch.mps.synchronize</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.get_rng_state.html">torch.mps.get_rng_state</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.set_rng_state.html">torch.mps.set_rng_state</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.manual_seed.html">torch.mps.manual_seed</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.seed.html">torch.mps.seed</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.empty_cache.html">torch.mps.empty_cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.set_per_process_memory_fraction.html">torch.mps.set_per_process_memory_fraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.current_allocated_memory.html">torch.mps.current_allocated_memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.driver_allocated_memory.html">torch.mps.driver_allocated_memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.recommended_max_memory.html">torch.mps.recommended_max_memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.compile_shader.html">torch.mps.compile_shader</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.profiler.start.html">torch.mps.profiler.start</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.profiler.stop.html">torch.mps.profiler.stop</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.profiler.profile.html">torch.mps.profiler.profile</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.profiler.is_capturing_metal.html">torch.mps.profiler.is_capturing_metal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.profiler.is_metal_capture_enabled.html">torch.mps.profiler.is_metal_capture_enabled</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.profiler.metal_capture.html">torch.mps.profiler.metal_capture</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mps.event.Event.html">Event</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../xpu.html">torch.xpu</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.StreamContext.html">StreamContext</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.can_device_access_peer.html">torch.xpu.can_device_access_peer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.current_device.html">torch.xpu.current_device</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.current_stream.html">torch.xpu.current_stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.device.html">device</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.device_count.html">torch.xpu.device_count</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.device_of.html">device_of</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.get_arch_list.html">torch.xpu.get_arch_list</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.get_device_capability.html">torch.xpu.get_device_capability</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.get_device_name.html">torch.xpu.get_device_name</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.get_device_properties.html">torch.xpu.get_device_properties</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.get_gencode_flags.html">torch.xpu.get_gencode_flags</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.get_stream_from_external.html">torch.xpu.get_stream_from_external</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.init.html">torch.xpu.init</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.is_available.html">torch.xpu.is_available</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.is_bf16_supported.html">torch.xpu.is_bf16_supported</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.is_initialized.html">torch.xpu.is_initialized</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.is_tf32_supported.html">torch.xpu.is_tf32_supported</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.set_device.html">torch.xpu.set_device</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.set_stream.html">torch.xpu.set_stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.stream_function.html">torch.xpu.stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.synchronize.html">torch.xpu.synchronize</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.get_rng_state.html">torch.xpu.get_rng_state</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.get_rng_state_all.html">torch.xpu.get_rng_state_all</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.initial_seed.html">torch.xpu.initial_seed</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.manual_seed.html">torch.xpu.manual_seed</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.manual_seed_all.html">torch.xpu.manual_seed_all</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.seed.html">torch.xpu.seed</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.seed_all.html">torch.xpu.seed_all</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.set_rng_state.html">torch.xpu.set_rng_state</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.set_rng_state_all.html">torch.xpu.set_rng_state_all</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.Event.html">Event</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.Stream_class.html">Stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.memory.XPUPluggableAllocator.html">XPUPluggableAllocator</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.memory.change_current_allocator.html">torch.xpu.memory.change_current_allocator</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.memory.empty_cache.html">torch.xpu.memory.empty_cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.memory.get_per_process_memory_fraction.html">torch.xpu.memory.get_per_process_memory_fraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.memory.max_memory_allocated.html">torch.xpu.memory.max_memory_allocated</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.memory.max_memory_reserved.html">torch.xpu.memory.max_memory_reserved</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.memory.mem_get_info.html">torch.xpu.memory.mem_get_info</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.memory.memory_allocated.html">torch.xpu.memory.memory_allocated</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.memory.memory_reserved.html">torch.xpu.memory.memory_reserved</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.memory.memory_stats.html">torch.xpu.memory.memory_stats</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.memory.memory_stats_as_nested_dict.html">torch.xpu.memory.memory_stats_as_nested_dict</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.memory.reset_accumulated_memory_stats.html">torch.xpu.memory.reset_accumulated_memory_stats</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.memory.reset_peak_memory_stats.html">torch.xpu.memory.reset_peak_memory_stats</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.xpu.memory.set_per_process_memory_fraction.html">torch.xpu.memory.set_per_process_memory_fraction</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../xpu.aliases.html">Aliases in torch.xpu</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="torch.xpu.random.get_rng_state.html">torch.xpu.random.get_rng_state</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.xpu.random.get_rng_state_all.html">torch.xpu.random.get_rng_state_all</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.xpu.random.initial_seed.html">torch.xpu.random.initial_seed</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.xpu.random.manual_seed.html">torch.xpu.random.manual_seed</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.xpu.random.manual_seed_all.html">torch.xpu.random.manual_seed_all</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.xpu.random.seed.html">torch.xpu.random.seed</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.xpu.random.seed_all.html">torch.xpu.random.seed_all</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.xpu.random.set_rng_state.html">torch.xpu.random.set_rng_state</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.xpu.random.set_rng_state_all.html">torch.xpu.random.set_rng_state_all</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.xpu.streams.Event.html">Event</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.xpu.streams.Stream.html">Stream</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../mtia.html">torch.mtia</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.StreamContext.html">StreamContext</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.current_device.html">torch.mtia.current_device</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.current_stream.html">torch.mtia.current_stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.default_stream.html">torch.mtia.default_stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.device_count.html">torch.mtia.device_count</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.init.html">torch.mtia.init</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.is_available.html">torch.mtia.is_available</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.is_bf16_supported.html">torch.mtia.is_bf16_supported</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.is_initialized.html">torch.mtia.is_initialized</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.memory_stats.html">torch.mtia.memory_stats</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.get_device_capability.html">torch.mtia.get_device_capability</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.empty_cache.html">torch.mtia.empty_cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.record_memory_history.html">torch.mtia.record_memory_history</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.snapshot.html">torch.mtia.snapshot</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.attach_out_of_memory_observer.html">torch.mtia.attach_out_of_memory_observer</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.set_device.html">torch.mtia.set_device</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.set_stream.html">torch.mtia.set_stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.stream_function.html">torch.mtia.stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.synchronize.html">torch.mtia.synchronize</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.device.html">device</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.set_rng_state.html">torch.mtia.set_rng_state</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.get_rng_state.html">torch.mtia.get_rng_state</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.DeferredMtiaCallError.html">torch.mtia.DeferredMtiaCallError</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.Event.html">Event</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.Stream_class.html">Stream</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../mtia.memory.html">torch.mtia.memory</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.memory.memory_stats.html">torch.mtia.memory.memory_stats</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mtia.memory.memory_allocated.html">torch.mtia.memory.memory_allocated</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../mtia.mtia_graph.html">torch.mtia.mtia_graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../meta.html">Meta device</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backends.html">torch.backends</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../user_guide/torch_compiler/export.html">torch.export</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/torch_compiler/export/api_reference.html">torch.export API Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/torch_compiler/export/programming_model.html">torch.export Programming Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/torch_compiler/export/ir_spec.html">torch.export IR Specification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/torch_compiler/export/pt2_archive.html">PT2 Archive Spec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/torch_compiler/export/draft_export.html">Draft Export</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/torch_compiler/export/joint_with_descriptors.html">Joint with descriptors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cond.html">Control Flow - Cond</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="exportdb/index.html">ExportDB</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="exportdb/torch.escape-hatch.html">torch.escape-hatch</a></li>
<li class="toctree-l3"><a class="reference internal" href="exportdb/torch.cond.html">torch.cond</a></li>
<li class="toctree-l3"><a class="reference internal" href="exportdb/torch.dynamic-shape.html">torch.dynamic-shape</a></li>
<li class="toctree-l3"><a class="reference internal" href="exportdb/python.closure.html">python.closure</a></li>
<li class="toctree-l3"><a class="reference internal" href="exportdb/torch.dynamic-value.html">torch.dynamic-value</a></li>
<li class="toctree-l3"><a class="reference internal" href="exportdb/python.data-structure.html">python.data-structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="exportdb/python.assert.html">python.assert</a></li>
<li class="toctree-l3"><a class="reference internal" href="exportdb/python.control-flow.html">python.control-flow</a></li>
<li class="toctree-l3"><a class="reference internal" href="exportdb/torch.map.html">torch.map</a></li>
<li class="toctree-l3"><a class="reference internal" href="exportdb/python.builtin.html">python.builtin</a></li>
<li class="toctree-l3"><a class="reference internal" href="exportdb/python.object-model.html">python.object-model</a></li>
<li class="toctree-l3"><a class="reference internal" href="exportdb/python.context-manager.html">python.context-manager</a></li>
<li class="toctree-l3"><a class="reference internal" href="exportdb/torch.operator.html">torch.operator</a></li>
<li class="toctree-l3"><a class="reference internal" href="exportdb/torch.mutation.html">torch.mutation</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../user_guide/torch_compiler/torch.compiler_aot_inductor.html">AOTInductor: Ahead-Of-Time Compilation for Torch.Export-ed Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../logging.html">torch._logging</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="torch._logging.set_logs.html">torch._logging.set_logs</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/torch_compiler/torch.compiler_aot_inductor_minifier.html">AOTInductor Minifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/torch_compiler/torch.compiler_aot_inductor_debugging_guide.html">AOTInductor Debugging Guide</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/torch_compiler/torch.compiler_ir.html">IRs</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../user_guide/torch_compiler/torch.compiler_dynamic_shapes.html">Dynamic Shapes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/torch_compiler/compile/dynamic_shapes_core_concepts.html">Dynamic Shapes Core Concepts</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../user_guide/torch_compiler/compile/dynamic_shapes_troubleshooting.html">Troubleshooting Dynamic Shapes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/torch_compiler/compile/dynamic_shapes_debugging_tlparse_torch_logs.html">Debugging with <code class="docutils literal notranslate"><span class="pre">tlparse</span></code> and <code class="docutils literal notranslate"><span class="pre">TORCH_LOGS=dynamic</span></code></a></li>

<li class="toctree-l4"><a class="reference internal" href="../user_guide/torch_compiler/compile/dynamic_shapes_troubleshooting_guardon_errors.html">Troubleshooting GuardOnDataDependentSymNode Errors</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/torch_compiler/compile/dynamic_shapes_advanced_control_options.html">Advanced Options to Control Dynamic Behavior</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../user_guide/torch_compiler/compile/dynamic_shapes_beyond_the_basics.html">Beyond the Basics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/torch_compiler/compile/dynamic_shapes_zero_one_specialization.html">The Zero-One Specialization Problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/torch_compiler/compile/dynamic_shapes_backed_unbacked.html">Backed vs Unbacked Symints</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/torch_compiler/torch.compiler_fake_tensor.html">Fake tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/torch_compiler/torch.compiler_transformations.html">Writing Graph Transformations on ATen IR</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../distributed.html">torch.distributed</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../distributed._dist2.html">Experimental Object Oriented Distributed API</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.tensor.html">torch.distributed.tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../distributed.elastic.html">torch.distributed.elastic</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../elastic/quickstart.html">Quickstart</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elastic/train_script.html">Train script</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elastic/examples.html">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elastic/run.html">torchrun (Elastic Launch)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elastic/agent.html">Elastic Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elastic/multiprocessing.html">Multiprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elastic/errors.html">Error Propagation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elastic/rendezvous.html">Rendezvous</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elastic/timer.html">Expiration Timers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elastic/metrics.html">Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elastic/events.html">Events</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elastic/subprocess_handler.html">Subprocess Handling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elastic/control_plane.html">Control Plane</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elastic/numa.html">NUMA Binding Utilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elastic/customization.html">Customization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../elastic/kubernetes.html">TorchElastic Kubernetes</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.fsdp.fully_shard.html">torch.distributed.fsdp.fully_shard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.tensor.parallel.html">torch.distributed.tensor.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.pipelining.html">torch.distributed.pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="../symmetric_memory.html">torch.distributed._symmetric_memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.checkpoint.html">torch.distributed.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributions.html">torch.distributions</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../torch.compiler_api.html">torch.compiler</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.compile.html">torch.compiler.compile</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.reset.html">torch.compiler.reset</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.allow_in_graph.html">torch.compiler.allow_in_graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.substitute_in_graph.html">torch.compiler.substitute_in_graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.assume_constant_result.html">torch.compiler.assume_constant_result</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.list_backends.html">torch.compiler.list_backends</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.disable.html">torch.compiler.disable</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.set_stance.html">torch.compiler.set_stance</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.set_enable_guard_collectives.html">torch.compiler.set_enable_guard_collectives</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.cudagraph_mark_step_begin.html">torch.compiler.cudagraph_mark_step_begin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.is_compiling.html">torch.compiler.is_compiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.is_dynamo_compiling.html">torch.compiler.is_dynamo_compiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.is_exporting.html">torch.compiler.is_exporting</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.skip_guard_on_inbuilt_nn_modules_unsafe.html">torch.compiler.skip_guard_on_inbuilt_nn_modules_unsafe</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.skip_guard_on_all_nn_modules_unsafe.html">torch.compiler.skip_guard_on_all_nn_modules_unsafe</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.keep_tensor_guards_unsafe.html">torch.compiler.keep_tensor_guards_unsafe</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.skip_guard_on_globals_unsafe.html">torch.compiler.skip_guard_on_globals_unsafe</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.skip_all_guards_unsafe.html">torch.compiler.skip_all_guards_unsafe</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.compiler.nested_compile_region.html">torch.compiler.nested_compile_region</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../fft.html">torch.fft</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.fft.html">torch.fft.fft</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.ifft.html">torch.fft.ifft</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.fft2.html">torch.fft.fft2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.ifft2.html">torch.fft.ifft2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.fftn.html">torch.fft.fftn</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.ifftn.html">torch.fft.ifftn</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.rfft.html">torch.fft.rfft</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.irfft.html">torch.fft.irfft</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.rfft2.html">torch.fft.rfft2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.irfft2.html">torch.fft.irfft2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.rfftn.html">torch.fft.rfftn</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.irfftn.html">torch.fft.irfftn</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.hfft.html">torch.fft.hfft</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.ihfft.html">torch.fft.ihfft</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.hfft2.html">torch.fft.hfft2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.ihfft2.html">torch.fft.ihfft2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.hfftn.html">torch.fft.hfftn</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.ihfftn.html">torch.fft.ihfftn</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.fftfreq.html">torch.fft.fftfreq</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.rfftfreq.html">torch.fft.rfftfreq</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.fftshift.html">torch.fft.fftshift</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fft.ifftshift.html">torch.fft.ifftshift</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../func.html">torch.func</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../func.whirlwind_tour.html">torch.func Whirlwind Tour</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../func.api.html">torch.func API Reference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="torch.func.vmap.html">torch.func.vmap</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.func.grad.html">torch.func.grad</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.func.grad_and_value.html">torch.func.grad_and_value</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.func.vjp.html">torch.func.vjp</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.func.jvp.html">torch.func.jvp</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.func.linearize.html">torch.func.linearize</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.func.jacrev.html">torch.func.jacrev</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.func.jacfwd.html">torch.func.jacfwd</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.func.hessian.html">torch.func.hessian</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.func.functionalize.html">torch.func.functionalize</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.func.functional_call.html">torch.func.functional_call</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.func.stack_module_state.html">torch.func.stack_module_state</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.func.replace_all_batch_norm_modules_.html">torch.func.replace_all_batch_norm_modules_</a></li>
<li class="toctree-l3"><a class="reference internal" href="../func.batch_norm.html">Patching Batch Norm</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.func.debug_unwrap.html">torch.func.debug_unwrap</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../func.ux_limitations.html">UX Limitations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func.migrating.html">Migrating from functorch to torch.func</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fx.html">torch.fx</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../fx.experimental.html">torch.fx.experimental</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.sym_node.is_channels_last_contiguous_2d.html">torch.fx.experimental.sym_node.is_channels_last_contiguous_2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.sym_node.is_channels_last_contiguous_3d.html">torch.fx.experimental.sym_node.is_channels_last_contiguous_3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.sym_node.is_channels_last_strides_2d.html">torch.fx.experimental.sym_node.is_channels_last_strides_2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.sym_node.is_channels_last_strides_3d.html">torch.fx.experimental.sym_node.is_channels_last_strides_3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.sym_node.is_contiguous.html">torch.fx.experimental.sym_node.is_contiguous</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.sym_node.is_non_overlapping_and_dense_indicator.html">torch.fx.experimental.sym_node.is_non_overlapping_and_dense_indicator</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.sym_node.method_to_operator.html">torch.fx.experimental.sym_node.method_to_operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.sym_node.sympy_is_channels_last_contiguous_2d.html">torch.fx.experimental.sym_node.sympy_is_channels_last_contiguous_2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.sym_node.sympy_is_channels_last_contiguous_3d.html">torch.fx.experimental.sym_node.sympy_is_channels_last_contiguous_3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.sym_node.sympy_is_channels_last_strides_2d.html">torch.fx.experimental.sym_node.sympy_is_channels_last_strides_2d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.sym_node.sympy_is_channels_last_strides_3d.html">torch.fx.experimental.sym_node.sympy_is_channels_last_strides_3d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.sym_node.sympy_is_channels_last_strides_generic.html">torch.fx.experimental.sym_node.sympy_is_channels_last_strides_generic</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.sym_node.sympy_is_contiguous.html">torch.fx.experimental.sym_node.sympy_is_contiguous</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.sym_node.sympy_is_contiguous_generic.html">torch.fx.experimental.sym_node.sympy_is_contiguous_generic</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.sym_node.to_node.html">torch.fx.experimental.sym_node.to_node</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.ShapeEnv.html">ShapeEnv</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.DimDynamic.html">DimDynamic</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.StrictMinMaxConstraint.html">StrictMinMaxConstraint</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.RelaxedUnspecConstraint.html">RelaxedUnspecConstraint</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.EqualityConstraint.html">EqualityConstraint</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.SymbolicContext.html">SymbolicContext</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.StatelessSymbolicContext.html">StatelessSymbolicContext</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.StatefulSymbolicContext.html">StatefulSymbolicContext</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.SubclassSymbolicContext.html">SubclassSymbolicContext</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.DimConstraints.html">DimConstraints</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.ShapeEnvSettings.html">ShapeEnvSettings</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.ConvertIntKey.html">ConvertIntKey</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.CallMethodKey.html">CallMethodKey</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts.html">PropagateUnbackedSymInts</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.DivideByKey.html">DivideByKey</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.InnerTensorKey.html">InnerTensorKey</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.Specialization.html">Specialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.hint_int.html">torch.fx.experimental.symbolic_shapes.hint_int</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.is_concrete_int.html">torch.fx.experimental.symbolic_shapes.is_concrete_int</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.is_concrete_bool.html">torch.fx.experimental.symbolic_shapes.is_concrete_bool</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.is_concrete_float.html">torch.fx.experimental.symbolic_shapes.is_concrete_float</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.has_free_symbols.html">torch.fx.experimental.symbolic_shapes.has_free_symbols</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.has_free_unbacked_symbols.html">torch.fx.experimental.symbolic_shapes.has_free_unbacked_symbols</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.guard_or_true.html">torch.fx.experimental.symbolic_shapes.guard_or_true</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.guard_or_false.html">torch.fx.experimental.symbolic_shapes.guard_or_false</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.guard_size_oblivious.html">torch.fx.experimental.symbolic_shapes.guard_size_oblivious</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.sym_and.html">torch.fx.experimental.symbolic_shapes.sym_and</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.sym_eq.html">torch.fx.experimental.symbolic_shapes.sym_eq</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.sym_or.html">torch.fx.experimental.symbolic_shapes.sym_or</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.constrain_range.html">torch.fx.experimental.symbolic_shapes.constrain_range</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.constrain_unify.html">torch.fx.experimental.symbolic_shapes.constrain_unify</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.canonicalize_bool_expr.html">torch.fx.experimental.symbolic_shapes.canonicalize_bool_expr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.statically_known_true.html">torch.fx.experimental.symbolic_shapes.statically_known_true</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.statically_known_false.html">torch.fx.experimental.symbolic_shapes.statically_known_false</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.has_static_value.html">torch.fx.experimental.symbolic_shapes.has_static_value</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.lru_cache.html">torch.fx.experimental.symbolic_shapes.lru_cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.check_consistent.html">torch.fx.experimental.symbolic_shapes.check_consistent</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.compute_unbacked_bindings.html">torch.fx.experimental.symbolic_shapes.compute_unbacked_bindings</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.rebind_unbacked.html">torch.fx.experimental.symbolic_shapes.rebind_unbacked</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.resolve_unbacked_bindings.html">torch.fx.experimental.symbolic_shapes.resolve_unbacked_bindings</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.is_accessor_node.html">torch.fx.experimental.symbolic_shapes.is_accessor_node</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.cast_symbool_to_symint_guardless.html">torch.fx.experimental.symbolic_shapes.cast_symbool_to_symint_guardless</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.create_contiguous.html">torch.fx.experimental.symbolic_shapes.create_contiguous</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.error.html">torch.fx.experimental.symbolic_shapes.error</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.eval_guards.html">torch.fx.experimental.symbolic_shapes.eval_guards</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.eval_is_non_overlapping_and_dense.html">torch.fx.experimental.symbolic_shapes.eval_is_non_overlapping_and_dense</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.find_symbol_binding_fx_nodes.html">torch.fx.experimental.symbolic_shapes.find_symbol_binding_fx_nodes</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.free_symbols.html">torch.fx.experimental.symbolic_shapes.free_symbols</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.free_unbacked_symbols.html">torch.fx.experimental.symbolic_shapes.free_unbacked_symbols</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.fx_placeholder_targets.html">torch.fx.experimental.symbolic_shapes.fx_placeholder_targets</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.fx_placeholder_vals.html">torch.fx.experimental.symbolic_shapes.fx_placeholder_vals</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.guard_bool.html">torch.fx.experimental.symbolic_shapes.guard_bool</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.guard_float.html">torch.fx.experimental.symbolic_shapes.guard_float</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.guard_int.html">torch.fx.experimental.symbolic_shapes.guard_int</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.guard_scalar.html">torch.fx.experimental.symbolic_shapes.guard_scalar</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.has_hint.html">torch.fx.experimental.symbolic_shapes.has_hint</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.has_symbolic_sizes_strides.html">torch.fx.experimental.symbolic_shapes.has_symbolic_sizes_strides</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.is_nested_int.html">torch.fx.experimental.symbolic_shapes.is_nested_int</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.is_symbol_binding_fx_node.html">torch.fx.experimental.symbolic_shapes.is_symbol_binding_fx_node</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.is_symbolic.html">torch.fx.experimental.symbolic_shapes.is_symbolic</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.expect_true.html">torch.fx.experimental.symbolic_shapes.expect_true</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.symbolic_shapes.log_lru_cache_stats.html">torch.fx.experimental.symbolic_shapes.log_lru_cache_stats</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.make_fx.html">torch.fx.experimental.proxy_tensor.make_fx</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.handle_sym_dispatch.html">torch.fx.experimental.proxy_tensor.handle_sym_dispatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.get_proxy_mode.html">torch.fx.experimental.proxy_tensor.get_proxy_mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.maybe_enable_thunkify.html">torch.fx.experimental.proxy_tensor.maybe_enable_thunkify</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.maybe_disable_thunkify.html">torch.fx.experimental.proxy_tensor.maybe_disable_thunkify</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.thunkify.html">torch.fx.experimental.proxy_tensor.thunkify</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.track_tensor.html">torch.fx.experimental.proxy_tensor.track_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.track_tensor_tree.html">torch.fx.experimental.proxy_tensor.track_tensor_tree</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.decompose.html">torch.fx.experimental.proxy_tensor.decompose</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.disable_autocast_cache.html">torch.fx.experimental.proxy_tensor.disable_autocast_cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.disable_proxy_modes_tracing.html">torch.fx.experimental.proxy_tensor.disable_proxy_modes_tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.extract_val.html">torch.fx.experimental.proxy_tensor.extract_val</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.fake_signature.html">torch.fx.experimental.proxy_tensor.fake_signature</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.fetch_object_proxy.html">torch.fx.experimental.proxy_tensor.fetch_object_proxy</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.fetch_sym_proxy.html">torch.fx.experimental.proxy_tensor.fetch_sym_proxy</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.has_proxy_slot.html">torch.fx.experimental.proxy_tensor.has_proxy_slot</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.is_sym_node.html">torch.fx.experimental.proxy_tensor.is_sym_node</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.maybe_handle_decomp.html">torch.fx.experimental.proxy_tensor.maybe_handle_decomp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.proxy_call.html">torch.fx.experimental.proxy_tensor.proxy_call</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.set_meta.html">torch.fx.experimental.proxy_tensor.set_meta</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.set_original_aten_op.html">torch.fx.experimental.proxy_tensor.set_original_aten_op</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.set_proxy_slot.html">torch.fx.experimental.proxy_tensor.set_proxy_slot</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.proxy_tensor.snapshot_fake.html">torch.fx.experimental.proxy_tensor.snapshot_fake</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.unification.unification_tools.assoc.html">torch.fx.experimental.unification.unification_tools.assoc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.unification.unification_tools.assoc_in.html">torch.fx.experimental.unification.unification_tools.assoc_in</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.unification.unification_tools.dissoc.html">torch.fx.experimental.unification.unification_tools.dissoc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.unification.unification_tools.first.html">torch.fx.experimental.unification.unification_tools.first</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.unification.unification_tools.keyfilter.html">torch.fx.experimental.unification.unification_tools.keyfilter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.unification.unification_tools.keymap.html">torch.fx.experimental.unification.unification_tools.keymap</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.unification.unification_tools.merge.html">torch.fx.experimental.unification.unification_tools.merge</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.unification.unification_tools.merge_with.html">torch.fx.experimental.unification.unification_tools.merge_with</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.unification.unification_tools.update_in.html">torch.fx.experimental.unification.unification_tools.update_in</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.unification.unification_tools.valfilter.html">torch.fx.experimental.unification.unification_tools.valfilter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.unification.unification_tools.valmap.html">torch.fx.experimental.unification.unification_tools.valmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.unification.unification_tools.itemfilter.html">torch.fx.experimental.unification.unification_tools.itemfilter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.unification.unification_tools.itemmap.html">torch.fx.experimental.unification.unification_tools.itemmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.migrate_gradual_types.transform_to_z3.transform_algebraic_expression.html">torch.fx.experimental.migrate_gradual_types.transform_to_z3.transform_algebraic_expression</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.migrate_gradual_types.transform_to_z3.transform_all_constraints.html">torch.fx.experimental.migrate_gradual_types.transform_to_z3.transform_all_constraints</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.migrate_gradual_types.transform_to_z3.transform_all_constraints_trace_time.html">torch.fx.experimental.migrate_gradual_types.transform_to_z3.transform_all_constraints_trace_time</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.migrate_gradual_types.transform_to_z3.transform_dimension.html">torch.fx.experimental.migrate_gradual_types.transform_to_z3.transform_dimension</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.migrate_gradual_types.transform_to_z3.transform_to_z3.html">torch.fx.experimental.migrate_gradual_types.transform_to_z3.transform_to_z3</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fx.experimental.migrate_gradual_types.transform_to_z3.transform_var.html">torch.fx.experimental.migrate_gradual_types.transform_to_z3.transform_var</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../hub.html">torch.hub</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../jit.html">torch.jit</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../jit_language_reference.html">TorchScript Language Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../jit_language_reference_v2.html">TorchScript Language Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../jit_python_reference.html">Python Language Reference Coverage</a></li>
<li class="toctree-l2"><a class="reference internal" href="../jit_unsupported.html">TorchScript Unsupported PyTorch Constructs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../jit_builtin_functions.html">torch.jit.supported_ops</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.script.html">torch.jit.script</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.trace.html">torch.jit.trace</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.script_if_tracing.html">torch.jit.script_if_tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.trace_module.html">torch.jit.trace_module</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.fork.html">torch.jit.fork</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.wait.html">torch.jit.wait</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.ScriptModule.html">ScriptModule</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.ScriptFunction.html">ScriptFunction</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.freeze.html">torch.jit.freeze</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.optimize_for_inference.html">torch.jit.optimize_for_inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.enable_onednn_fusion.html">torch.jit.enable_onednn_fusion</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.onednn_fusion_enabled.html">torch.jit.onednn_fusion_enabled</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.set_fusion_strategy.html">torch.jit.set_fusion_strategy</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.strict_fusion.html">strict_fusion</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.save.html">torch.jit.save</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.load.html">torch.jit.load</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.ignore.html">torch.jit.ignore</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.unused.html">torch.jit.unused</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.interface.html">torch.jit.interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.isinstance.html">torch.jit.isinstance</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.Attribute.html">Attribute</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.jit.annotate.html">torch.jit.annotate</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../linalg.html">torch.linalg</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.norm.html">torch.linalg.norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.vector_norm.html">torch.linalg.vector_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.matrix_norm.html">torch.linalg.matrix_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.diagonal.html">torch.linalg.diagonal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.det.html">torch.linalg.det</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.slogdet.html">torch.linalg.slogdet</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.cond.html">torch.linalg.cond</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.matrix_rank.html">torch.linalg.matrix_rank</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.cholesky.html">torch.linalg.cholesky</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.qr.html">torch.linalg.qr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.lu.html">torch.linalg.lu</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.lu_factor.html">torch.linalg.lu_factor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.eig.html">torch.linalg.eig</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.eigvals.html">torch.linalg.eigvals</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.eigh.html">torch.linalg.eigh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.eigvalsh.html">torch.linalg.eigvalsh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.svd.html">torch.linalg.svd</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.svdvals.html">torch.linalg.svdvals</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.solve.html">torch.linalg.solve</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.solve_triangular.html">torch.linalg.solve_triangular</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.lu_solve.html">torch.linalg.lu_solve</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.lstsq.html">torch.linalg.lstsq</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.inv.html">torch.linalg.inv</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.pinv.html">torch.linalg.pinv</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.matrix_exp.html">torch.linalg.matrix_exp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.matrix_power.html">torch.linalg.matrix_power</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.cross.html">torch.linalg.cross</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.matmul.html">torch.linalg.matmul</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.vecdot.html">torch.linalg.vecdot</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.multi_dot.html">torch.linalg.multi_dot</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.householder_product.html">torch.linalg.householder_product</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.tensorinv.html">torch.linalg.tensorinv</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.tensorsolve.html">torch.linalg.tensorsolve</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.vander.html">torch.linalg.vander</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.cholesky_ex.html">torch.linalg.cholesky_ex</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.inv_ex.html">torch.linalg.inv_ex</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.solve_ex.html">torch.linalg.solve_ex</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.lu_factor_ex.html">torch.linalg.lu_factor_ex</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.ldl_factor.html">torch.linalg.ldl_factor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.ldl_factor_ex.html">torch.linalg.ldl_factor_ex</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.linalg.ldl_solve.html">torch.linalg.ldl_solve</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../monitor.html">torch.monitor</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../signal.html">torch.signal</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.signal.windows.bartlett.html">torch.signal.windows.bartlett</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.signal.windows.blackman.html">torch.signal.windows.blackman</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.signal.windows.cosine.html">torch.signal.windows.cosine</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.signal.windows.exponential.html">torch.signal.windows.exponential</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.signal.windows.gaussian.html">torch.signal.windows.gaussian</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.signal.windows.general_cosine.html">torch.signal.windows.general_cosine</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.signal.windows.general_hamming.html">torch.signal.windows.general_hamming</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.signal.windows.hamming.html">torch.signal.windows.hamming</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.signal.windows.hann.html">torch.signal.windows.hann</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.signal.windows.kaiser.html">torch.signal.windows.kaiser</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.signal.windows.nuttall.html">torch.signal.windows.nuttall</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nativert.html">torch.nativert</a></li>
<li class="toctree-l1"><a class="reference internal" href="../package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nn.attention.html">torch.nn.attention</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.attention.sdpa_kernel.html">torch.nn.attention.sdpa_kernel</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.attention.SDPBackend.html">SDPBackend</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.attention.register_flash_attention_impl.html">torch.nn.attention.register_flash_attention_impl</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.attention.activate_flash_attention_impl.html">torch.nn.attention.activate_flash_attention_impl</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.attention.list_flash_attention_impls.html">torch.nn.attention.list_flash_attention_impls</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.attention.current_flash_attention_impl.html">torch.nn.attention.current_flash_attention_impl</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nn.attention.flex_attention.html">torch.nn.attention.flex_attention</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../nn.attention.bias.html">torch.nn.attention.bias</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="torch.nn.attention.bias.CausalBias.html">torch.nn.attention.bias.CausalBias</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.nn.attention.bias.causal_lower_right.html">torch.nn.attention.bias.causal_lower_right</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.nn.attention.bias.causal_upper_left.html">torch.nn.attention.bias.causal_upper_left</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.nn.attention.bias.CausalVariant.html">CausalVariant</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../nn.attention.experimental.html">torch.nn.attention.experimental</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nn.attention.varlen.html">torch.nn.attention.varlen</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../onnx.html">torch.onnx</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../onnx_export.html">torch.export-based ONNX Exporter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx_ops.html">torch.onnx.ops</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx_verification.html">torch.onnx.verification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx_testing.html">torch.onnx.testing</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../optim.html">torch.optim</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Optimizer.add_param_group.html">torch.optim.Optimizer.add_param_group</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Optimizer.load_state_dict.html">torch.optim.Optimizer.load_state_dict</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Optimizer.register_load_state_dict_pre_hook.html">torch.optim.Optimizer.register_load_state_dict_pre_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Optimizer.register_load_state_dict_post_hook.html">torch.optim.Optimizer.register_load_state_dict_post_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Optimizer.state_dict.html">torch.optim.Optimizer.state_dict</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Optimizer.register_state_dict_pre_hook.html">torch.optim.Optimizer.register_state_dict_pre_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Optimizer.register_state_dict_post_hook.html">torch.optim.Optimizer.register_state_dict_post_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Optimizer.step.html">torch.optim.Optimizer.step</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Optimizer.register_step_pre_hook.html">torch.optim.Optimizer.register_step_pre_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Optimizer.register_step_post_hook.html">torch.optim.Optimizer.register_step_post_hook</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Optimizer.zero_grad.html">torch.optim.Optimizer.zero_grad</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Adadelta.html">Adadelta</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Adafactor.html">Adafactor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Adagrad.html">Adagrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Adam.html">Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.AdamW.html">AdamW</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.SparseAdam.html">SparseAdam</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Adamax.html">Adamax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.ASGD.html">ASGD</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.LBFGS.html">LBFGS</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Muon.html">Muon</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.NAdam.html">NAdam</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.RAdam.html">RAdam</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.RMSprop.html">RMSprop</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.Rprop.html">Rprop</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.SGD.html">SGD</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.lr_scheduler.LRScheduler.html">LRScheduler</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.lr_scheduler.LambdaLR.html">LambdaLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.lr_scheduler.MultiplicativeLR.html">MultiplicativeLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.lr_scheduler.StepLR.html">StepLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.lr_scheduler.MultiStepLR.html">MultiStepLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.lr_scheduler.ConstantLR.html">ConstantLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.lr_scheduler.LinearLR.html">LinearLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.lr_scheduler.ExponentialLR.html">ExponentialLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.lr_scheduler.PolynomialLR.html">PolynomialLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.lr_scheduler.CosineAnnealingLR.html">CosineAnnealingLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.lr_scheduler.ChainedScheduler.html">ChainedScheduler</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.lr_scheduler.SequentialLR.html">SequentialLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.lr_scheduler.ReduceLROnPlateau.html">ReduceLROnPlateau</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.lr_scheduler.CyclicLR.html">CyclicLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.lr_scheduler.OneCycleLR.html">OneCycleLR</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html">CosineAnnealingWarmRestarts</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.swa_utils.AveragedModel.html">AveragedModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.optim.swa_utils.SWALR.html">SWALR</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../optim.aliases.html">Aliases in torch.optim</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.adadelta.Adadelta_class.html">Adadelta</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.adadelta.adadelta_function.html">torch.optim.adadelta.adadelta</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.adagrad.Adagrad_class.html">Adagrad</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.adagrad.adagrad_function.html">torch.optim.adagrad.adagrad</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.adam.Adam_class.html">Adam</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.adam.adam_function.html">torch.optim.adam.adam</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.adamax.Adamax_class.html">Adamax</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.adamax.adamax_function.html">torch.optim.adamax.adamax</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.adamw.AdamW_class.html">AdamW</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.adamw.adamw_function.html">torch.optim.adamw.adamw</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.asgd.ASGD_class.html">ASGD</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.asgd.asgd_function.html">torch.optim.asgd.asgd</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.lbfgs.LBFGS.html">LBFGS</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.nadam.NAdam_class.html">NAdam</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.nadam.nadam_function.html">torch.optim.nadam.nadam</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.radam.RAdam_class.html">RAdam</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.radam.radam_function.html">torch.optim.radam.radam</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.rmsprop.RMSprop_class.html">RMSprop</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.rmsprop.rmsprop_function.html">torch.optim.rmsprop.rmsprop</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.rprop.Rprop_class.html">Rprop</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.rprop.rprop_function.html">torch.optim.rprop.rprop</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.sgd.SGD_class.html">SGD</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.sgd.sgd_function.html">torch.optim.sgd.sgd</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.optim.sparse_adam.SparseAdam.html">SparseAdam</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ddp_comm_hooks.html">DDP Communication Hooks</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../quantization.html">Quantization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../quantization-support.html">Quantization API Reference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.quantize.html">quantize</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.quantize_dynamic.html">quantize_dynamic</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.quantize_qat.html">quantize_qat</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.prepare.html">prepare</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.prepare_qat.html">prepare_qat</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.convert.html">convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fuse_modules.fuse_modules.html">fuse_modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.QuantStub.html">QuantStub</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.DeQuantStub.html">DeQuantStub</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.QuantWrapper.html">QuantWrapper</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.add_quant_dequant.html">add_quant_dequant</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.swap_module.html">swap_module</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.propagate_qconfig_.html">propagate_qconfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.default_eval_fn.html">default_eval_fn</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.utils.activation_is_dynamically_quantized.html">activation_is_dynamically_quantized</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.utils.activation_is_int32_quantized.html">activation_is_int32_quantized</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.utils.activation_is_int8_quantized.html">activation_is_int8_quantized</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.utils.activation_is_statically_quantized.html">activation_is_statically_quantized</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.utils.determine_qparams.html">determine_qparams</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.utils.check_min_max_valid.html">check_min_max_valid</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.utils.calculate_qmin_qmax.html">calculate_qmin_qmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.utils.validate_qmin_qmax.html">validate_qmin_qmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.quantize_fx.prepare_fx.html">prepare_fx</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.quantize_fx.prepare_qat_fx.html">prepare_qat_fx</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.quantize_fx.convert_fx.html">convert_fx</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.quantize_fx.fuse_fx.html">fuse_fx</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.qconfig_mapping.QConfigMapping.html">QConfigMapping</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.qconfig_mapping.get_default_qconfig_mapping.html">get_default_qconfig_mapping</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.qconfig_mapping.get_default_qat_qconfig_mapping.html">get_default_qat_qconfig_mapping</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.backend_config.BackendConfig.html">BackendConfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.backend_config.BackendPatternConfig.html">BackendPatternConfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.backend_config.DTypeConfig.html">DTypeConfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.backend_config.DTypeWithConstraints.html">DTypeWithConstraints</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.backend_config.ObservationType.html">ObservationType</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.backend_config.utils.entry_to_pretty_str.html">entry_to_pretty_str</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.backend_config.utils.pattern_to_human_readable.html">pattern_to_human_readable</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.backend_config.utils.remove_boolean_dispatch_from_name.html">remove_boolean_dispatch_from_name</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fx.custom_config.FuseCustomConfig.html">FuseCustomConfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html">PrepareCustomConfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fx.custom_config.ConvertCustomConfig.html">ConvertCustomConfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fx.custom_config.StandaloneModuleConfigEntry.html">StandaloneModuleConfigEntry</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fx.utils.all_node_args_except_first.html">all_node_args_except_first</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fx.utils.all_node_args_have_no_tensors.html">all_node_args_have_no_tensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fx.utils.collect_producer_nodes.html">collect_producer_nodes</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fx.utils.create_getattr_from_value.html">create_getattr_from_value</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fx.utils.create_node_from_old_node_preserve_meta.html">create_node_from_old_node_preserve_meta</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fx.utils.graph_module_from_producer_nodes.html">graph_module_from_producer_nodes</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fx.utils.maybe_get_next_module.html">maybe_get_next_module</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fx.utils.node_arg_is_bias.html">node_arg_is_bias</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fx.utils.node_arg_is_weight.html">node_arg_is_weight</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fx.utils.return_arg_list.html">return_arg_list</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.pt2e.export_utils.model_is_exported.html">model_is_exported</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.pt2e.lowering.lower_pt2e_quantized_to_x86.html">lower_pt2e_quantized_to_x86</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.generate_numeric_debug_handle.html">generate_numeric_debug_handle</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.CUSTOM_KEY.html">CUSTOM_KEY</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.NUMERIC_DEBUG_HANDLE_KEY.html">NUMERIC_DEBUG_HANDLE_KEY</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.prepare_for_propagation_comparison.html">prepare_for_propagation_comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.extract_results_from_loggers.html">extract_results_from_loggers</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.compare_results.html">compare_results</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.quantize_per_tensor.html">quantize_per_tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.quantize_per_channel.html">quantize_per_channel</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.dequantize.html">dequantize</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.view.html">torch.Tensor.view</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.as_strided.html">torch.Tensor.as_strided</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.expand.html">torch.Tensor.expand</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.flatten.html">torch.Tensor.flatten</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.select.html">torch.Tensor.select</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.ne.html">torch.Tensor.ne</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.eq.html">torch.Tensor.eq</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.ge.html">torch.Tensor.ge</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.le.html">torch.Tensor.le</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.gt.html">torch.Tensor.gt</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.lt.html">torch.Tensor.lt</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.copy_.html">torch.Tensor.copy_</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.clone.html">torch.Tensor.clone</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.dequantize.html">torch.Tensor.dequantize</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.equal.html">torch.Tensor.equal</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.int_repr.html">torch.Tensor.int_repr</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.max.html">torch.Tensor.max</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.mean.html">torch.Tensor.mean</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.min.html">torch.Tensor.min</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.q_scale.html">torch.Tensor.q_scale</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.q_zero_point.html">torch.Tensor.q_zero_point</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.q_per_channel_scales.html">torch.Tensor.q_per_channel_scales</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.q_per_channel_zero_points.html">torch.Tensor.q_per_channel_zero_points</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.q_per_channel_axis.html">torch.Tensor.q_per_channel_axis</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.resize_.html">torch.Tensor.resize_</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.sort.html">torch.Tensor.sort</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.Tensor.topk.html">torch.Tensor.topk</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.ObserverBase.html">ObserverBase</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.MinMaxObserver.html">MinMaxObserver</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.MovingAverageMinMaxObserver.html">MovingAverageMinMaxObserver</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.PerChannelMinMaxObserver.html">PerChannelMinMaxObserver</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver.html">MovingAveragePerChannelMinMaxObserver</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.HistogramObserver.html">HistogramObserver</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.PlaceholderObserver.html">PlaceholderObserver</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.RecordingObserver.html">RecordingObserver</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.NoopObserver.html">NoopObserver</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.get_observer_state_dict.html">get_observer_state_dict</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.load_observer_state_dict.html">load_observer_state_dict</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.default_observer.html">default_observer</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.default_placeholder_observer.html">default_placeholder_observer</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.default_debug_observer.html">default_debug_observer</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.default_weight_observer.html">default_weight_observer</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.default_histogram_observer.html">default_histogram_observer</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.default_per_channel_weight_observer.html">default_per_channel_weight_observer</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.default_dynamic_quant_observer.html">default_dynamic_quant_observer</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.default_float_qparams_observer.html">default_float_qparams_observer</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.AffineQuantizedObserverBase.html">AffineQuantizedObserverBase</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.Granularity.html">Granularity</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.MappingType.html">MappingType</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.PerAxis.html">PerAxis</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.PerBlock.html">PerBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.PerGroup.html">PerGroup</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.PerRow.html">PerRow</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.PerTensor.html">PerTensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.PerToken.html">PerToken</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.TorchAODType.html">TorchAODType</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.ZeroPointDomain.html">ZeroPointDomain</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.observer.get_block_size.html">get_block_size</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fake_quantize.FakeQuantizeBase.html">FakeQuantizeBase</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fake_quantize.FakeQuantize.html">FakeQuantize</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize.html">FixedQParamsFakeQuantize</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize.html">FusedMovingAvgObsFakeQuantize</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fake_quantize.default_fake_quant.html">default_fake_quant</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fake_quantize.default_weight_fake_quant.html">default_weight_fake_quant</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fake_quantize.default_per_channel_weight_fake_quant.html">default_per_channel_weight_fake_quant</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fake_quantize.default_histogram_fake_quant.html">default_histogram_fake_quant</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fake_quantize.default_fused_act_fake_quant.html">default_fused_act_fake_quant</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fake_quantize.default_fused_wt_fake_quant.html">default_fused_wt_fake_quant</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant.html">default_fused_per_channel_wt_fake_quant</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fake_quantize.disable_fake_quant.html">disable_fake_quant</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fake_quantize.enable_fake_quant.html">enable_fake_quant</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fake_quantize.disable_observer.html">disable_observer</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.fake_quantize.enable_observer.html">enable_observer</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.qconfig.QConfig.html">QConfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.qconfig.default_qconfig.html">default_qconfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.qconfig.default_debug_qconfig.html">default_debug_qconfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.qconfig.default_per_channel_qconfig.html">default_per_channel_qconfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.qconfig.default_dynamic_qconfig.html">default_dynamic_qconfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.qconfig.float16_dynamic_qconfig.html">float16_dynamic_qconfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.qconfig.float16_static_qconfig.html">float16_static_qconfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.qconfig.per_channel_dynamic_qconfig.html">per_channel_dynamic_qconfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.qconfig.float_qparams_weight_only_qconfig.html">float_qparams_weight_only_qconfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.qconfig.default_qat_qconfig.html">default_qat_qconfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.qconfig.default_weight_only_qconfig.html">default_weight_only_qconfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.qconfig.default_activation_only_qconfig.html">default_activation_only_qconfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.quantization.qconfig.default_qat_qconfig_v2.html">default_qat_qconfig_v2</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.ConvReLU1d.html">ConvReLU1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.ConvReLU2d.html">ConvReLU2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.ConvReLU3d.html">ConvReLU3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.LinearReLU.html">LinearReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.ConvBn1d.html">ConvBn1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.ConvBn2d.html">ConvBn2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.ConvBn3d.html">ConvBn3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.ConvBnReLU1d.html">ConvBnReLU1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.ConvBnReLU2d.html">ConvBnReLU2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.ConvBnReLU3d.html">ConvBnReLU3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.BNReLU2d.html">BNReLU2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.BNReLU3d.html">BNReLU3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.LinearReLU.html">LinearReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.ConvBn1d.html">ConvBn1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.ConvBnReLU1d.html">ConvBnReLU1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.ConvBn2d.html">ConvBn2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.ConvBnReLU2d.html">ConvBnReLU2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.ConvReLU2d.html">ConvReLU2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.ConvBn3d.html">ConvBn3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.ConvBnReLU3d.html">ConvBnReLU3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.ConvReLU3d.html">ConvReLU3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.update_bn_stats.html">update_bn_stats</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.freeze_bn_stats.html">freeze_bn_stats</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.BNReLU2d.html">BNReLU2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.BNReLU3d.html">BNReLU3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.ConvReLU1d.html">ConvReLU1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.ConvReLU2d.html">ConvReLU2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.ConvReLU3d.html">ConvReLU3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.LinearReLU.html">LinearReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.dynamic.LinearReLU.html">LinearReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.qat.Conv2d.html">Conv2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.qat.Conv3d.html">Conv3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.qat.Linear.html">Linear</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.qat.dynamic.Linear.html">Linear</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.ReLU6.html">ReLU6</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.Hardswish.html">Hardswish</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.ELU.html">ELU</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.LeakyReLU.html">LeakyReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.Sigmoid.html">Sigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.BatchNorm2d.html">BatchNorm2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.BatchNorm3d.html">BatchNorm3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.Conv1d.html">Conv1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.Conv2d.html">Conv2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.Conv3d.html">Conv3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.ConvTranspose1d.html">ConvTranspose1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.ConvTranspose2d.html">ConvTranspose2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.ConvTranspose3d.html">ConvTranspose3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.Embedding.html">Embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.EmbeddingBag.html">EmbeddingBag</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.FloatFunctional.html">FloatFunctional</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.FXFloatFunctional.html">FXFloatFunctional</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.QFunctional.html">QFunctional</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.Linear.html">Linear</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.LayerNorm.html">LayerNorm</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.GroupNorm.html">GroupNorm</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.InstanceNorm1d.html">InstanceNorm1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.InstanceNorm2d.html">InstanceNorm2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.InstanceNorm3d.html">InstanceNorm3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.avg_pool2d.html">avg_pool2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.avg_pool3d.html">avg_pool3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.adaptive_avg_pool2d.html">adaptive_avg_pool2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.adaptive_avg_pool3d.html">adaptive_avg_pool3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.conv1d.html">conv1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.conv2d.html">conv2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.conv3d.html">conv3d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.interpolate.html">interpolate</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.linear.html">linear</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.max_pool1d.html">max_pool1d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.max_pool2d.html">max_pool2d</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.celu.html">celu</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.leaky_relu.html">leaky_relu</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.hardtanh.html">hardtanh</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.hardswish.html">hardswish</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.threshold.html">threshold</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.elu.html">elu</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.hardsigmoid.html">hardsigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.clamp.html">clamp</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.upsample.html">upsample</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.upsample_bilinear.html">upsample_bilinear</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.functional.upsample_nearest.html">upsample_nearest</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantizable.LSTM.html">LSTM</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantizable.MultiheadAttention.html">MultiheadAttention</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.Linear.html">Linear</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.LSTM.html">LSTM</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.GRU.html">GRU</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.RNNCell.html">RNNCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.LSTMCell.html">LSTMCell</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.GRUCell.html">GRUCell</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../quantization-support.aliases.html">Aliases in torch.ao</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvReLU1d.html">ConvReLU1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvReLU2d.html">ConvReLU2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvReLU3d.html">ConvReLU3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU1d.html">ConvBnReLU1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU2d.html">ConvBnReLU2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU3d.html">ConvBnReLU3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.modules.linear_fused.LinearBn1d.html">LinearBn1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.qat.modules.linear_relu.LinearReLU.html">LinearReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU1d.html">ConvReLU1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d.html">ConvReLU2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU3d.html">ConvReLU3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.modules.bn_relu.BNReLU2d.html">BNReLU2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.modules.bn_relu.BNReLU3d.html">BNReLU3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.modules.conv_add.ConvAdd2d.html">ConvAdd2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.modules.conv_add.ConvAddReLU2d.html">ConvAddReLU2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.modules.linear_relu.LinearLeakyReLU.html">LinearLeakyReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.modules.linear_relu.LinearReLU.html">LinearReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.modules.linear_relu.LinearTanh.html">LinearTanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.quantized.dynamic.modules.linear_relu.LinearReLU.html">LinearReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.modules.fused.ConvAdd2d.html">ConvAdd2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.modules.fused.ConvAddReLU2d.html">ConvAddReLU2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.modules.fused.LinearBn1d.html">LinearBn1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.modules.fused.LinearLeakyReLU.html">LinearLeakyReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.intrinsic.modules.fused.LinearTanh.html">LinearTanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.qat.modules.conv.Conv1d.html">Conv1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.qat.modules.conv.Conv2d.html">Conv2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.qat.modules.conv.Conv3d.html">Conv3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.qat.modules.embedding_ops.Embedding.html">Embedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.qat.modules.embedding_ops.EmbeddingBag.html">EmbeddingBag</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.qat.modules.linear.Linear.html">Linear</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantizable.modules.activation.MultiheadAttention.html">MultiheadAttention</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantizable.modules.rnn.LSTM.html">LSTM</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantizable.modules.rnn.LSTMCell.html">LSTMCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.modules.conv.Conv1d.html">Conv1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.modules.conv.Conv2d.html">Conv2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.modules.conv.Conv3d.html">Conv3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.modules.conv.ConvTranspose1d.html">ConvTranspose1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.modules.conv.ConvTranspose2d.html">ConvTranspose2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.modules.conv.ConvTranspose3d.html">ConvTranspose3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.modules.linear.Linear.html">Linear</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.modules.rnn.GRU.html">GRU</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.modules.rnn.GRUCell.html">GRUCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.modules.rnn.LSTM.html">LSTM</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.modules.rnn.LSTMCell.html">LSTMCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.modules.rnn.PackedParameter.html">PackedParameter</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.modules.rnn.RNNBase.html">RNNBase</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.modules.rnn.RNNCell.html">RNNCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch.ao.nn.quantized.dynamic.modules.rnn.RNNCellBase.html">RNNCellBase</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../rpc.html">Distributed RPC Framework</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../rpc/rref.html">Remote Reference Protocol</a></li>
<li class="toctree-l2"><a class="reference internal" href="../rpc/distributed_autograd.html">Distributed Autograd Design</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../random.html">torch.random</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../masked.html">torch.masked</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.abs.html">torch.abs</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.absolute.html">torch.absolute</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.acos.html">torch.acos</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.arccos.html">torch.arccos</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.acosh.html">torch.acosh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.arccosh.html">torch.arccosh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.angle.html">torch.angle</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.asin.html">torch.asin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.arcsin.html">torch.arcsin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.asinh.html">torch.asinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.arcsinh.html">torch.arcsinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.atan.html">torch.atan</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.arctan.html">torch.arctan</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.atanh.html">torch.atanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.arctanh.html">torch.arctanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bitwise_not.html">torch.bitwise_not</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.ceil.html">torch.ceil</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.clamp.html">torch.clamp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.clip.html">torch.clip</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.conj_physical.html">torch.conj_physical</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cos.html">torch.cos</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cosh.html">torch.cosh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.deg2rad.html">torch.deg2rad</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.digamma.html">torch.digamma</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.erf.html">torch.erf</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.erfc.html">torch.erfc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.erfinv.html">torch.erfinv</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.exp.html">torch.exp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.exp2.html">torch.exp2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.expm1.html">torch.expm1</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fix.html">torch.fix</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.floor.html">torch.floor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.frac.html">torch.frac</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.lgamma.html">torch.lgamma</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.log.html">torch.log</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.log10.html">torch.log10</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.log1p.html">torch.log1p</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.log2.html">torch.log2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.logit.html">torch.logit</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.i0.html">torch.i0</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.isnan.html">torch.isnan</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nan_to_num.html">torch.nan_to_num</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.neg.html">torch.neg</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.negative.html">torch.negative</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.positive.html">torch.positive</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.pow.html">torch.pow</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.rad2deg.html">torch.rad2deg</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.reciprocal.html">torch.reciprocal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.round.html">torch.round</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.rsqrt.html">torch.rsqrt</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sigmoid.html">torch.sigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sign.html">torch.sign</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sgn.html">torch.sgn</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.signbit.html">torch.signbit</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sin.html">torch.sin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sinc.html">torch.sinc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sinh.html">torch.sinh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sqrt.html">torch.sqrt</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.square.html">torch.square</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.tan.html">torch.tan</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.tanh.html">torch.tanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.trunc.html">torch.trunc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.angle.html">torch.angle</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.positive.html">torch.positive</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.signbit.html">torch.signbit</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.isnan.html">torch.isnan</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.add.html">torch.add</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.atan2.html">torch.atan2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.arctan2.html">torch.arctan2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bitwise_and.html">torch.bitwise_and</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bitwise_or.html">torch.bitwise_or</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bitwise_xor.html">torch.bitwise_xor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bitwise_left_shift.html">torch.bitwise_left_shift</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.bitwise_right_shift.html">torch.bitwise_right_shift</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.div.html">torch.div</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.divide.html">torch.divide</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.floor_divide.html">torch.floor_divide</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fmod.html">torch.fmod</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.logaddexp.html">torch.logaddexp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.logaddexp2.html">torch.logaddexp2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mul.html">torch.mul</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.multiply.html">torch.multiply</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nextafter.html">torch.nextafter</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.remainder.html">torch.remainder</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sub.html">torch.sub</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.subtract.html">torch.subtract</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.true_divide.html">torch.true_divide</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.eq.html">torch.eq</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.ne.html">torch.ne</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.le.html">torch.le</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.ge.html">torch.ge</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.greater.html">torch.greater</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.greater_equal.html">torch.greater_equal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.gt.html">torch.gt</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.less_equal.html">torch.less_equal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.lt.html">torch.lt</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.less.html">torch.less</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.maximum.html">torch.maximum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.minimum.html">torch.minimum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fmax.html">torch.fmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fmin.html">torch.fmin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.not_equal.html">torch.not_equal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.logaddexp.html">torch.logaddexp</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.logaddexp2.html">torch.logaddexp2</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.equal.html">torch.equal</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fmin.html">torch.fmin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.minimum.html">torch.minimum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.fmax.html">torch.fmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sum.html">torch.sum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.mean.html">torch.mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.amin.html">torch.amin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.amax.html">torch.amax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.argmin.html">torch.argmin</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.argmax.html">torch.argmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.prod.html">torch.prod</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.all.html">torch.all</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.norm.html">torch.norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.var.html">torch.var</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.std.html">torch.std</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.atleast_1d.html">torch.atleast_1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.broadcast_tensors.html">torch.broadcast_tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.broadcast_to.html">torch.broadcast_to</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.cat.html">torch.cat</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.chunk.html">torch.chunk</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.column_stack.html">torch.column_stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.dsplit.html">torch.dsplit</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.flatten.html">torch.flatten</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.hsplit.html">torch.hsplit</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.hstack.html">torch.hstack</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.kron.html">torch.kron</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.meshgrid.html">torch.meshgrid</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.narrow.html">torch.narrow</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.nn.functional.unfold.html">torch.nn.functional.unfold</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.ravel.html">torch.ravel</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.select.html">torch.select</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.split.html">torch.split</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.stack.html">torch.stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.t.html">torch.t</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.transpose.html">torch.transpose</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.vsplit.html">torch.vsplit</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.vstack.html">torch.vstack</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.expand.html">torch.Tensor.expand</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.expand_as.html">torch.Tensor.expand_as</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.reshape.html">torch.Tensor.reshape</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.reshape_as.html">torch.Tensor.reshape_as</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.unfold.html">torch.Tensor.unfold</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.view.html">torch.Tensor.view</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="../size.html">torch.Size</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../sparse.html">torch.sparse</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_sparse.html">torch.Tensor.is_sparse</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_sparse_csr.html">torch.Tensor.is_sparse_csr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.dense_dim.html">torch.Tensor.dense_dim</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sparse_dim.html">torch.Tensor.sparse_dim</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sparse_mask.html">torch.Tensor.sparse_mask</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.to_sparse.html">torch.Tensor.to_sparse</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.to_sparse_coo.html">torch.Tensor.to_sparse_coo</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.to_sparse_csr.html">torch.Tensor.to_sparse_csr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.to_sparse_csc.html">torch.Tensor.to_sparse_csc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.to_sparse_bsr.html">torch.Tensor.to_sparse_bsr</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.to_sparse_bsc.html">torch.Tensor.to_sparse_bsc</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.to_dense.html">torch.Tensor.to_dense</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.values.html">torch.Tensor.values</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.coalesce.html">torch.Tensor.coalesce</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sparse_resize_.html">torch.Tensor.sparse_resize_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.sparse_resize_and_clear_.html">torch.Tensor.sparse_resize_and_clear_</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.is_coalesced.html">torch.Tensor.is_coalesced</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.indices.html">torch.Tensor.indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.crow_indices.html">torch.Tensor.crow_indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.col_indices.html">torch.Tensor.col_indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.row_indices.html">torch.Tensor.row_indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.Tensor.ccol_indices.html">torch.Tensor.ccol_indices</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse_coo_tensor.html">torch.sparse_coo_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse_csr_tensor.html">torch.sparse_csr_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse_csc_tensor.html">torch.sparse_csc_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse_bsr_tensor.html">torch.sparse_bsr_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse_bsc_tensor.html">torch.sparse_bsc_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse_compressed_tensor.html">torch.sparse_compressed_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse.sum.html">torch.sparse.sum</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse.addmm.html">torch.sparse.addmm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse.sampled_addmm.html">torch.sparse.sampled_addmm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse.mm.html">torch.sparse.mm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sspaddmm.html">torch.sspaddmm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.hspmm.html">torch.hspmm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.smm.html">torch.smm</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse.softmax.html">torch.sparse.softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse.spsolve.html">torch.sparse.spsolve</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse.log_softmax.html">torch.sparse.log_softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse.spdiags.html">torch.sparse.spdiags</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse.check_sparse_tensor_invariants.html">check_sparse_tensor_invariants</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.sparse.as_sparse_gradcheck.html">torch.sparse.as_sparse_gradcheck</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing.html">torch.testing</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../utils.html">torch.utils</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.utils.rename_privateuse1_backend.html">torch.utils.rename_privateuse1_backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.utils.generate_methods_for_privateuse1_backend.html">torch.utils.generate_methods_for_privateuse1_backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.utils.get_cpp_backtrace.html">torch.utils.get_cpp_backtrace</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.utils.set_module.html">torch.utils.set_module</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.utils.swap_tensors.html">torch.utils.swap_tensors</a></li>
</ul>
</details></li>



<li class="toctree-l1"><a class="reference internal" href="../benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deterministic.html">torch.utils.deterministic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../jit_utils.html">torch.utils.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../module_tracker.html">torch.utils.module_tracker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../config_mod.html">torch.__config__</a></li>
<li class="toctree-l1"><a class="reference internal" href="../future_mod.html">torch.__future__</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../logging.html">torch._logging</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="torch._logging.set_logs.html">torch._logging.set_logs</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../torch_environment_variables.html">Torch Environment Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../threading_environment_variables.html">Threading Environment Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cuda_environment_variables.html">CUDA Environment Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mps_environment_variables.html">MPS Environment Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../debugging_environment_variables.html">Debugging Environment Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../miscellaneous_environment_variables.html">Miscellaneous Environment Variables</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../logging.html">torch._logging</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="torch._logging.set_logs.html">torch._logging.set_logs</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../torch_nccl_environment_variables.html">PYTORCH ProcessGroupNCCL Environment Variables</a></li>
</ul>
</details></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../pytorch-api.html" class="nav-link">Reference API</a></li>
    
    
    <li class="breadcrumb-item"><a href="../torch.html" class="nav-link">torch</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">torch.compile</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5"></span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="../pytorch-api.html">
        <meta itemprop="name" content="Reference API">
        <meta itemprop="position" content="1">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="../torch.html">
        <meta itemprop="name" content="torch">
        <meta itemprop="position" content="2">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="torch.compile">
        <meta itemprop="position" content="3">
      </div>
    </div>

    
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="torch-compile">
<h1>torch.compile<a class="headerlink" href="#torch-compile" title="Link to this heading">#</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="torch.compile">
<span class="sig-prename descclassname"><span class="pre">torch.</span></span><span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Callable" title="(in Python v3.14)"><span class="pre">Callable</span></a><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">_InputT</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">_RetT</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fullgraph</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dynamic</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backend</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Callable" title="(in Python v3.14)"><span class="pre">Callable</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'inductor'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)"><span class="pre">dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Callable" title="(in Python v3.14)"><span class="pre">Callable</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Callable" title="(in Python v3.14)"><span class="pre">Callable</span></a><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">_InputT</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">_RetT</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference external" href="https://github.com/pytorch/pytorch/blob/v2.10.0/torch/__init__.py#L2546"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.compile" title="Link to this definition">#</a></dt>
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">torch.</span></span><span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fullgraph</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dynamic</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backend</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Callable" title="(in Python v3.14)"><span class="pre">Callable</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'inductor'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)"><span class="pre">dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Callable" title="(in Python v3.14)"><span class="pre">Callable</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Callable" title="(in Python v3.14)"><span class="pre">Callable</span></a><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Callable" title="(in Python v3.14)"><span class="pre">Callable</span></a><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">_InputT</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">_RetT</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Callable" title="(in Python v3.14)"><span class="pre">Callable</span></a><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">_InputT</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">_RetT</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span></dt>
<dd><p>Optimizes given model/function using TorchDynamo and specified backend.
If you are compiling an <a class="reference internal" href="torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></a>, you can also use <a class="reference internal" href="torch.nn.Module.html#torch.nn.Module.compile" title="torch.nn.Module.compile"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.compile()</span></code></a>
to compile the module inplace without changing its structure.</p>
<p>Concretely, for every frame executed within the compiled region, we will attempt
to compile it and cache the compiled result on the code object for future
use.  A single frame may be compiled multiple times if previous compiled
results are not applicable for subsequent calls (this is called a guard
failure), you can use TORCH_LOGS=guards to debug these situations.
Multiple compiled results can be associated with a frame up to
<code class="docutils literal notranslate"><span class="pre">torch._dynamo.config.recompile_limit</span></code>, which defaults to 8; at which
point we will fall back to eager.  Note that compile caches are per
<em>code object</em>, not frame; if you dynamically create multiple copies of a
function, they will all share the same code cache.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>Callable</em><em> or </em><em>None</em>)  Module/function to optimize</p></li>
<li><p><strong>fullgraph</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>)  If False (default), torch.compile attempts to discover compilable regions
in the function that it will optimize. If True, then we require that the entire function be
capturable into a single graph. If this is not possible (that is, if there are graph breaks),
then this will raise an error. This also opts into unbacked semantics, notably it will turn on
capture_scalar_outputs and capture_dynamic_output_shape_ops on by default.</p></li>
<li><p><strong>dynamic</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em> or </em><em>None</em>)  Use dynamic shape tracing.  When this is True, we will up-front attempt
to generate a kernel that is as dynamic as possible to avoid recompilations when
sizes change.  This may not always work as some operations/optimizations will
force specialization; use TORCH_LOGS=dynamic to debug overspecialization.
When this is False, we will NEVER generate dynamic kernels, we will always specialize.
By default (None), we automatically detect if dynamism has occurred and compile a more
dynamic kernel upon recompile.</p></li>
<li><p><strong>backend</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a><em> or </em><em>Callable</em>)  <p>backend to be used</p>
<ul>
<li><p>inductor is the default backend, which is a good balance between performance and overhead</p></li>
<li><p>Non experimental in-tree backends can be seen with <cite>torch._dynamo.list_backends()</cite></p></li>
<li><p>Experimental or debug in-tree backends can be seen with <cite>torch._dynamo.list_backends(None)</cite></p></li>
<li><p>To register an out-of-tree custom backend:
<a class="reference external" href="https://pytorch.org/docs/main/torch.compiler_custom_backends.html#registering-custom-backends">https://pytorch.org/docs/main/torch.compiler_custom_backends.html#registering-custom-backends</a></p></li>
</ul>
</p></li>
<li><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>)  <p>Can be either default, reduce-overhead, max-autotune or max-autotune-no-cudagraphs</p>
<ul>
<li><p>default is the default mode, which is a good balance between performance and overhead</p></li>
<li><p>reduce-overhead is a mode that reduces the overhead of python with CUDA graphs,
useful for small batches.  Reduction of overhead can come at the cost of more memory
usage, as we will cache the workspace memory required for the invocation so that we
do not have to reallocate it on subsequent runs.  Reduction of overhead is not guaranteed
to work; today, we only reduce overhead for CUDA only graphs which do not mutate inputs.
There are other circumstances where CUDA graphs are not applicable; use TORCH_LOG=perf_hints
to debug.</p></li>
<li><p>max-autotune is a mode that leverages Triton or template based matrix multiplications
on supported devices and Triton based convolutions on GPU.
It enables CUDA graphs by default on GPU.</p></li>
<li><p>max-autotune-no-cudagraphs is a mode similar to max-autotune but without CUDA graphs</p></li>
<li><p>To see the exact configs that each mode sets you can call <cite>torch._inductor.list_mode_options()</cite></p></li>
</ul>
</p></li>
<li><p><strong>options</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.14)"><em>dict</em></a>)  <p>A dictionary of options to pass to the backend. Some notable ones to try out are</p>
<ul>
<li><p><cite>epilogue_fusion</cite> which fuses pointwise ops into templates. Requires <cite>max_autotune</cite> to also be set</p></li>
<li><p><cite>max_autotune</cite> which will profile to pick the best matmul configuration</p></li>
<li><p><cite>fallback_random</cite> which is useful when debugging accuracy issues</p></li>
<li><p><cite>shape_padding</cite> which pads matrix shapes to better align loads on GPUs especially for tensor cores</p></li>
<li><p><cite>triton.cudagraphs</cite> which will reduce the overhead of python with CUDA graphs</p></li>
<li><p><cite>trace.enabled</cite> which is the most useful debugging flag to turn on</p></li>
<li><p><cite>trace.graph_diagram</cite> which will show you a picture of your graph after fusion</p></li>
<li><p><cite>guard_filter_fn</cite> that controls which dynamo guards are saved with compilations.
This is an unsafe feature and there is no backward compatibility guarantee provided
for dynamo guards as data types.
For stable helper functions to use, see the documentations in <cite>torch.compiler</cite>, for example:
- <cite>torch.compiler.skip_guard_on_inbuilt_nn_modules_unsafe</cite>
- <cite>torch.compiler.skip_guard_on_all_nn_modules_unsafe</cite>
- <cite>torch.compiler.keep_tensor_guards_unsafe</cite></p></li>
<li><p>For inductor you can see the full list of configs that it supports by calling <cite>torch._inductor.list_options()</cite></p></li>
</ul>
</p></li>
<li><p><strong>disable</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>)  Turn torch.compile() into a no-op for testing</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;triton.cudagraphs&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">},</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">foo</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5"></span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="torch.cond.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">torch.cond</p>
      </div>
    </a>
    <a class="right-next"
       href="../torch.aliases.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Aliases in torch</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="torch.cond.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">torch.cond</p>
      </div>
    </a>
    <a class="right-next"
       href="../torch.aliases.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Aliases in torch</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#torch.compile"><code class="docutils literal notranslate"><span class="pre">compile()</span></code></a></li>
</ul>
  </nav></div>
    
       <div class="sidebar-secondary-item">
    <div class="tocsection sourcelink">
      <a href="../_sources/generated/torch.compile.rst.txt">
        <i class="fa-solid fa-file-lines"></i> Show Source
      </a>
    </div>
</div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  

<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
      </div>

      <div class="col-md-4">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>




<footer class="site-footer">

  <div class="container footer-container">

    <div class="newsletter" id="newsletter">

      <p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>


      <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
      <script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>


      <p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a
          href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>

    </div>

    <div class="lf-grid">
      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook">
              <path fill="currentColor"
                d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" />
            </svg>
          </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X">
              <path fill="currentColor"
                d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" />
            </svg>
          </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube">
              <path fill="currentColor"
                d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" />
            </svg>
          </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn">
              <rect width="512" height="512" rx="0" fill="currentColor" />
              <circle fill="#000" cx="142" cy="138" r="37" />
              <path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198" />
              <path fill="#000"
                d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" />
            </svg>
          </a></li>
        <li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack">
              <path fill="currentColor"
                d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z">
              </path>
            </svg>
          </a></li>
        <li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat">
              <path fill="currentColor"
                d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z">
              </path>
              <path fill="currentColor"
                d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z">
              </path>
            </svg>
          </a></li>
      </ul>
    </div>
    
    <div class="privacy-policy">
      <div class="copyright">
      
        <p>
          &copy; PyTorch. Copyright  The Linux Foundation. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a
            href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a
            href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
        
      </div>
    </div>


  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebooks Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
       Copyright PyTorch Contributors.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "torch.compile",
       "headline": "torch.compile",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/generated/torch.compile.html",
       "articleBody": "torch.compile# torch.compile(model: Callable[[_InputT], _RetT], *, fullgraph: bool = False, dynamic: bool | None = None, backend: str | Callable = \u0027inductor\u0027, mode: str | None = None, options: dict[str, str | int | bool | Callable] | None = None, disable: bool = False) \u2192 Callable[[_InputT], _RetT][source]# torch.compile(model: None = None, *, fullgraph: bool = False, dynamic: bool | None = None, backend: str | Callable = \u0027inductor\u0027, mode: str | None = None, options: dict[str, str | int | bool | Callable] | None = None, disable: bool = False) \u2192 Callable[[Callable[[_InputT], _RetT]], Callable[[_InputT], _RetT]] Optimizes given model/function using TorchDynamo and specified backend. If you are compiling an torch.nn.Module, you can also use torch.nn.Module.compile() to compile the module inplace without changing its structure. Concretely, for every frame executed within the compiled region, we will attempt to compile it and cache the compiled result on the code object for future use. A single frame may be compiled multiple times if previous compiled results are not applicable for subsequent calls (this is called a \u201cguard failure\u201d), you can use TORCH_LOGS=guards to debug these situations. Multiple compiled results can be associated with a frame up to torch._dynamo.config.recompile_limit, which defaults to 8; at which point we will fall back to eager. Note that compile caches are per code object, not frame; if you dynamically create multiple copies of a function, they will all share the same code cache. Parameters: model (Callable or None) \u2013 Module/function to optimize fullgraph (bool) \u2013 If False (default), torch.compile attempts to discover compilable regions in the function that it will optimize. If True, then we require that the entire function be capturable into a single graph. If this is not possible (that is, if there are graph breaks), then this will raise an error. This also opts into unbacked semantics, notably it will turn on capture_scalar_outputs and capture_dynamic_output_shape_ops on by default. dynamic (bool or None) \u2013 Use dynamic shape tracing. When this is True, we will up-front attempt to generate a kernel that is as dynamic as possible to avoid recompilations when sizes change. This may not always work as some operations/optimizations will force specialization; use TORCH_LOGS=dynamic to debug overspecialization. When this is False, we will NEVER generate dynamic kernels, we will always specialize. By default (None), we automatically detect if dynamism has occurred and compile a more dynamic kernel upon recompile. backend (str or Callable) \u2013 backend to be used \u201dinductor\u201d is the default backend, which is a good balance between performance and overhead Non experimental in-tree backends can be seen with torch._dynamo.list_backends() Experimental or debug in-tree backends can be seen with torch._dynamo.list_backends(None) To register an out-of-tree custom backend: https://pytorch.org/docs/main/torch.compiler_custom_backends.html#registering-custom-backends mode (str) \u2013 Can be either \u201cdefault\u201d, \u201creduce-overhead\u201d, \u201cmax-autotune\u201d or \u201cmax-autotune-no-cudagraphs\u201d \u201ddefault\u201d is the default mode, which is a good balance between performance and overhead \u201dreduce-overhead\u201d is a mode that reduces the overhead of python with CUDA graphs, useful for small batches. Reduction of overhead can come at the cost of more memory usage, as we will cache the workspace memory required for the invocation so that we do not have to reallocate it on subsequent runs. Reduction of overhead is not guaranteed to work; today, we only reduce overhead for CUDA only graphs which do not mutate inputs. There are other circumstances where CUDA graphs are not applicable; use TORCH_LOG=perf_hints to debug. \u201dmax-autotune\u201d is a mode that leverages Triton or template based matrix multiplications on supported devices and Triton based convolutions on GPU. It enables CUDA graphs by default on GPU. \u201dmax-autotune-no-cudagraphs\u201d is a mode similar to \u201cmax-autotune\u201d but without CUDA graphs To see the exact configs that each mode sets you can call torch._inductor.list_mode_options() options (dict) \u2013 A dictionary of options to pass to the backend. Some notable ones to try out are epilogue_fusion which fuses pointwise ops into templates. Requires max_autotune to also be set max_autotune which will profile to pick the best matmul configuration fallback_random which is useful when debugging accuracy issues shape_padding which pads matrix shapes to better align loads on GPUs especially for tensor cores triton.cudagraphs which will reduce the overhead of python with CUDA graphs trace.enabled which is the most useful debugging flag to turn on trace.graph_diagram which will show you a picture of your graph after fusion guard_filter_fn that controls which dynamo guards are saved with compilations. This is an unsafe feature and there is no backward compatibility guarantee provided for dynamo guards as data types. For stable helper functions to use, see the documentations in torch.compiler, for example: - torch.compiler.skip_guard_on_inbuilt_nn_modules_unsafe - torch.compiler.skip_guard_on_all_nn_modules_unsafe - torch.compiler.keep_tensor_guards_unsafe For inductor you can see the full list of configs that it supports by calling torch._inductor.list_options() disable (bool) \u2013 Turn torch.compile() into a no-op for testing Example: @torch.compile(options={\"triton.cudagraphs\": True}, fullgraph=True) def foo(x): return torch.sin(x) + torch.cos(x)",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "https://pytorch.org/docs/stable/_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/generated/torch.compile.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>