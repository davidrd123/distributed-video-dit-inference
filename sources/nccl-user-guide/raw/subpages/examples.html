<!DOCTYPE html>
<html class="writer-html5" lang="en-US">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Examples &mdash; NCCL 2.29.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="_static/theme_overrides.css?v=8eabb79f" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=324d1df1"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="NCCL and MPI" href="mpi.html" />
    <link rel="prev" title="Migrating from NCCL 1 to NCCL 2" href="nccl1.html" />
  <script src="https://assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js"></script>

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" > 

          
          
          <a href="index.html" class="icon icon-home">
            NCCL
          </a>
              <div class="version">
                <a href="https://docs.nvidia.com/deeplearning/sdk/nccl-archived/index.html">2.29</a>
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #76b900;
    }
    .wy-side-nav-search a:link, .wy-nav-top a:link {
      color: #fff;
    }
    .wy-side-nav-search a:visited, .wy-nav-top a:visited {
      color: #fff;
    }
    .wy-side-nav-search a:hover, .wy-nav-top a:hover {
      color: #fff;
    }
    .wy-menu-vertical a:link, .wy-menu-vertical a:visited {
      color: #d9d9d9
    }
    .wy-menu-vertical a:active {
      background-color: #76b900
    }
    .wy-side-nav-search>div.version {
      color: rgba(0, 0, 0, 0.3)
    }
  </style>

        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview of NCCL</a></li>
<li class="toctree-l1"><a class="reference internal" href="setup.html">Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Using NCCL</a><ul>
<li class="toctree-l2"><a class="reference internal" href="usage/communicators.html">Creating a Communicator</a><ul>
<li class="toctree-l3"><a class="reference internal" href="usage/communicators.html#creating-a-communicator-with-options">Creating a communicator with options</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/communicators.html#creating-a-communicator-using-multiple-nccluniqueids">Creating a communicator using multiple ncclUniqueIds</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/communicators.html#shrinking-a-communicator">Shrinking a communicator</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/communicators.html#growing-a-communicator">Growing a communicator</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/communicators.html#creating-more-communicators">Creating more communicators</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/communicators.html#using-multiple-nccl-communicators-concurrently">Using multiple NCCL communicators concurrently</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/communicators.html#finalizing-a-communicator">Finalizing a communicator</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/communicators.html#destroying-a-communicator">Destroying a communicator</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="usage/communicators.html#error-handling-and-communicator-abort">Error handling and communicator abort</a><ul>
<li class="toctree-l3"><a class="reference internal" href="usage/communicators.html#asynchronous-errors-and-error-handling">Asynchronous errors and error handling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="usage/communicators.html#fault-tolerance">Fault Tolerance</a></li>
<li class="toctree-l2"><a class="reference internal" href="usage/communicators.html#quality-of-service">Quality of Service</a></li>
<li class="toctree-l2"><a class="reference internal" href="usage/collectives.html">Collective Operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="usage/collectives.html#allreduce">AllReduce</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/collectives.html#broadcast">Broadcast</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/collectives.html#reduce">Reduce</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/collectives.html#allgather">AllGather</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/collectives.html#reducescatter">ReduceScatter</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/collectives.html#alltoall">AlltoAll</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/collectives.html#gather">Gather</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/collectives.html#scatter">Scatter</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="usage/data.html">Data Pointers</a></li>
<li class="toctree-l2"><a class="reference internal" href="usage/streams.html">CUDA Stream Semantics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="usage/streams.html#mixing-multiple-streams-within-the-same-ncclgroupstart-end-group">Mixing Multiple Streams within the same ncclGroupStart/End() group</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="usage/groups.html">Group Calls</a><ul>
<li class="toctree-l3"><a class="reference internal" href="usage/groups.html#management-of-multiple-gpus-from-one-thread">Management Of Multiple GPUs From One Thread</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/groups.html#aggregated-operations-2-2-and-later">Aggregated Operations (2.2 and later)</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/groups.html#group-operation-ordering-semantics">Group Operation Ordering Semantics</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/groups.html#nonblocking-group-operation">Nonblocking Group Operation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="usage/p2p.html">Point-to-point communication</a><ul>
<li class="toctree-l3"><a class="reference internal" href="usage/p2p.html#two-sided-communication">Two-sided communication</a><ul>
<li class="toctree-l4"><a class="reference internal" href="usage/p2p.html#sendrecv">Sendrecv</a></li>
<li class="toctree-l4"><a class="reference internal" href="usage/p2p.html#one-to-all-scatter">One-to-all (scatter)</a></li>
<li class="toctree-l4"><a class="reference internal" href="usage/p2p.html#all-to-one-gather">All-to-one (gather)</a></li>
<li class="toctree-l4"><a class="reference internal" href="usage/p2p.html#all-to-all">All-to-all</a></li>
<li class="toctree-l4"><a class="reference internal" href="usage/p2p.html#neighbor-exchange">Neighbor exchange</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="usage/p2p.html#one-sided-communication">One-sided communication</a><ul>
<li class="toctree-l4"><a class="reference internal" href="usage/p2p.html#putsignal-and-waitsignal">PutSignal and WaitSignal</a></li>
<li class="toctree-l4"><a class="reference internal" href="usage/p2p.html#barrier">Barrier</a></li>
<li class="toctree-l4"><a class="reference internal" href="usage/p2p.html#id1">All-to-all</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="usage/threadsafety.html">Thread Safety</a></li>
<li class="toctree-l2"><a class="reference internal" href="usage/inplace.html">In-place Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="usage/cudagraph.html">Using NCCL with CUDA Graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="usage/bufferreg.html">User Buffer Registration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="usage/bufferreg.html#nvlink-sharp-buffer-registration">NVLink Sharp Buffer Registration</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/bufferreg.html#ib-sharp-buffer-registration">IB Sharp Buffer Registration</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/bufferreg.html#general-buffer-registration">General Buffer Registration</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/bufferreg.html#buffer-registration-and-pxn">Buffer Registration and PXN</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/bufferreg.html#memory-allocator">Memory Allocator</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/bufferreg.html#window-registration">Window Registration</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/bufferreg.html#zero-cta-optimization">Zero-CTA Optimization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="usage/deviceapi.html">Device-Initiated Communication</a><ul>
<li class="toctree-l3"><a class="reference internal" href="usage/deviceapi.html#device-api">Device API</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/deviceapi.html#requirements">Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/deviceapi.html#host-side-setup">Host-Side Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/deviceapi.html#simple-lsa-kernel">Simple LSA Kernel</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/deviceapi.html#multimem-device-kernel">Multimem Device Kernel</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/deviceapi.html#thread-groups">Thread Groups</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/deviceapi.html#teams">Teams</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/deviceapi.html#host-accessible-device-pointer-functions">Host-Accessible Device Pointer Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="usage/deviceapi.html#gin-device-kernel">GIN Device Kernel</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api.html">NCCL API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="api/comms.html">Communicator Creation and Management Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclgetlasterror">ncclGetLastError</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclgeterrorstring">ncclGetErrorString</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclgetversion">ncclGetVersion</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclgetuniqueid">ncclGetUniqueId</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcomminitrank">ncclCommInitRank</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcomminitall">ncclCommInitAll</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcomminitrankconfig">ncclCommInitRankConfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcomminitrankscalable">ncclCommInitRankScalable</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcommsplit">ncclCommSplit</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcommshrink">ncclCommShrink</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcommgetuniqueid">ncclCommGetUniqueId</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcommgrow">ncclCommGrow</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcommfinalize">ncclCommFinalize</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcommrevoke">ncclCommRevoke</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcommdestroy">ncclCommDestroy</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcommabort">ncclCommAbort</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcommgetasyncerror">ncclCommGetAsyncError</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcommcount">ncclCommCount</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcommcudevice">ncclCommCuDevice</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcommuserrank">ncclCommUserRank</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcommregister">ncclCommRegister</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcommderegister">ncclCommDeregister</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcommwindowregister">ncclCommWindowRegister</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclcommwindowderegister">ncclCommWindowDeregister</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclmemalloc">ncclMemAlloc</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/comms.html#ncclmemfree">ncclMemFree</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api/colls.html">Collective Communication Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api/colls.html#ncclallreduce">ncclAllReduce</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/colls.html#ncclbroadcast">ncclBroadcast</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/colls.html#ncclreduce">ncclReduce</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/colls.html#ncclallgather">ncclAllGather</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/colls.html#ncclreducescatter">ncclReduceScatter</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/colls.html#ncclalltoall">ncclAlltoAll</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/colls.html#ncclgather">ncclGather</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/colls.html#ncclscatter">ncclScatter</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api/group.html">Group Calls</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api/group.html#ncclgroupstart">ncclGroupStart</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/group.html#ncclgroupend">ncclGroupEnd</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/group.html#ncclgroupsimulateend">ncclGroupSimulateEnd</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api/p2p.html">Point To Point Communication Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api/p2p.html#two-sided-point-to-point-operations">Two-Sided Point-to-Point Operations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="api/p2p.html#ncclsend">ncclSend</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/p2p.html#ncclrecv">ncclRecv</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="api/p2p.html#one-sided-point-to-point-operations-rma">One-Sided Point-to-Point Operations (RMA)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="api/p2p.html#ncclputsignal">ncclPutSignal</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/p2p.html#ncclsignal">ncclSignal</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/p2p.html#ncclwaitsignal">ncclWaitSignal</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api/types.html">Types</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api/types.html#ncclcomm-t">ncclComm_t</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/types.html#ncclresult-t">ncclResult_t</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/types.html#nccldatatype-t">ncclDataType_t</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/types.html#ncclredop-t">ncclRedOp_t</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/types.html#ncclscalarresidence-t">ncclScalarResidence_t</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/types.html#ncclconfig-t">ncclConfig_t</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/types.html#ncclsiminfo-t">ncclSimInfo_t</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/types.html#ncclwindow-t">ncclWindow_t</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api/ops.html">User Defined Reduction Operators</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api/ops.html#ncclredopcreatepremulsum">ncclRedOpCreatePreMulSum</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/ops.html#ncclredopdestroy">ncclRedOpDestroy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api/flags.html">NCCL API Supported Flags</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api/flags.html#window-registration-flags">Window Registration Flags</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/flags.html#nccl-communicator-cta-policy-flags">NCCL Communicator CTA Policy Flags</a></li>
<li class="toctree-l3"><a class="reference internal" href="api/flags.html#communicator-shrink-flags">Communicator Shrink Flags</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api/device.html">Device API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api/device.html#host-side-setup">Host-Side Setup</a><ul>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#nccldevcomm">ncclDevComm</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#nccldevcommcreate">ncclDevCommCreate</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#nccldevcommdestroy">ncclDevCommDestroy</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#nccldevcommrequirements">ncclDevCommRequirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#ncclcommqueryproperties">ncclCommQueryProperties</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#ncclcommproperties-t">ncclCommProperties_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#ncclgintype-t">ncclGinType_t</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="api/device.html#lsa">LSA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#nccllsabarriersession">ncclLsaBarrierSession</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#ncclgetpeerpointer">ncclGetPeerPointer</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#ncclgetlsapointer">ncclGetLsaPointer</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#ncclgetlocalpointer">ncclGetLocalPointer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="api/device.html#multimem">Multimem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#ncclgetlsamultimempointer">ncclGetLsaMultimemPointer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="api/device.html#host-accessible-device-pointer-functions">Host-Accessible Device Pointer Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#ncclgetlsamultimemdevicepointer">ncclGetLsaMultimemDevicePointer</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#ncclgetmultimemdevicepointer">ncclGetMultimemDevicePointer</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#ncclgetlsadevicepointer">ncclGetLsaDevicePointer</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#ncclgetpeerdevicepointer">ncclGetPeerDevicePointer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="api/device.html#gin">GIN</a><ul>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#ncclgin">ncclGin</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#signals-and-counters">Signals and Counters</a></li>
<li class="toctree-l4"><a class="reference internal" href="api/device.html#ncclginbarriersession">ncclGinBarrierSession</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nccl1.html">Migrating from NCCL 1 to NCCL 2</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nccl1.html#initialization">Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="nccl1.html#communication">Communication</a></li>
<li class="toctree-l2"><a class="reference internal" href="nccl1.html#counts">Counts</a></li>
<li class="toctree-l2"><a class="reference internal" href="nccl1.html#in-place-usage-for-allgather-and-reducescatter">In-place usage for AllGather and ReduceScatter</a></li>
<li class="toctree-l2"><a class="reference internal" href="nccl1.html#allgather-arguments-order">AllGather arguments order</a></li>
<li class="toctree-l2"><a class="reference internal" href="nccl1.html#datatypes">Datatypes</a></li>
<li class="toctree-l2"><a class="reference internal" href="nccl1.html#error-codes">Error codes</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#communicator-creation-and-destruction-examples">Communicator Creation and Destruction Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#example-1-single-process-single-thread-multiple-devices">Example 1: Single Process, Single Thread, Multiple Devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example-2-one-device-per-process-or-thread">Example 2: One Device per Process or Thread</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example-3-multiple-devices-per-thread">Example 3: Multiple Devices per Thread</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example-4-multiple-communicators-per-device">Example 4: Multiple communicators per device</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#communication-examples">Communication Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#example-1-one-device-per-process-or-thread">Example 1: One Device per Process or Thread</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example-2-multiple-devices-per-thread">Example 2: Multiple Devices per Thread</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mpi.html">NCCL and MPI</a><ul>
<li class="toctree-l2"><a class="reference internal" href="mpi.html#api">API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="mpi.html#using-multiple-devices-per-process">Using multiple devices per process</a></li>
<li class="toctree-l3"><a class="reference internal" href="mpi.html#reducescatter-operation">ReduceScatter operation</a></li>
<li class="toctree-l3"><a class="reference internal" href="mpi.html#send-and-receive-counts">Send and Receive counts</a></li>
<li class="toctree-l3"><a class="reference internal" href="mpi.html#other-collectives-and-point-to-point-operations">Other collectives and point-to-point operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="mpi.html#in-place-operations">In-place operations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mpi.html#using-nccl-within-an-mpi-program">Using NCCL within an MPI Program</a><ul>
<li class="toctree-l3"><a class="reference internal" href="mpi.html#mpi-progress">MPI Progress</a></li>
<li class="toctree-l3"><a class="reference internal" href="mpi.html#inter-gpu-communication-with-cuda-aware-mpi">Inter-GPU Communication with CUDA-aware MPI</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="env.html">Environment Variables</a><ul>
<li class="toctree-l2"><a class="reference internal" href="env.html#system-configuration">System configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-socket-ifname">NCCL_SOCKET_IFNAME</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#values-accepted">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-socket-family">NCCL_SOCKET_FAMILY</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id2">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-socket-retry-cnt">NCCL_SOCKET_RETRY_CNT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id3">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-socket-retry-sleep-msec">NCCL_SOCKET_RETRY_SLEEP_MSEC</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id4">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-socket-poll-timeout-msec">NCCL_SOCKET_POLL_TIMEOUT_MSEC</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id5">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-socket-nthreads">NCCL_SOCKET_NTHREADS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id6">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-nsocks-perthread">NCCL_NSOCKS_PERTHREAD</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id7">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-cross-nic">NCCL_CROSS_NIC</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id8">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-hca">NCCL_IB_HCA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id9">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-timeout">NCCL_IB_TIMEOUT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id10">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-retry-cnt">NCCL_IB_RETRY_CNT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id11">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-gid-index">NCCL_IB_GID_INDEX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id12">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-addr-family">NCCL_IB_ADDR_FAMILY</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id13">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-addr-range">NCCL_IB_ADDR_RANGE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id14">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-roce-version-num">NCCL_IB_ROCE_VERSION_NUM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id15">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-sl">NCCL_IB_SL</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id16">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-tc">NCCL_IB_TC</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id17">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-fifo-tc">NCCL_IB_FIFO_TC</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id18">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-return-async-events">NCCL_IB_RETURN_ASYNC_EVENTS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id19">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-oob-net-enable">NCCL_OOB_NET_ENABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id20">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-oob-net-ifname">NCCL_OOB_NET_IFNAME</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id21">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-uid-stagger-threshold">NCCL_UID_STAGGER_THRESHOLD</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id22">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-uid-stagger-rate">NCCL_UID_STAGGER_RATE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id23">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-net">NCCL_NET</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id24">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-net-plugin">NCCL_NET_PLUGIN</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id25">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-tuner-plugin">NCCL_TUNER_PLUGIN</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id26">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-profiler-plugin">NCCL_PROFILER_PLUGIN</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id27">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-env-plugin">NCCL_ENV_PLUGIN</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id28">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ignore-cpu-affinity">NCCL_IGNORE_CPU_AFFINITY</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id29">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-conf-file">NCCL_CONF_FILE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id30">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-debug">NCCL_DEBUG</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id32">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-debug-file">NCCL_DEBUG_FILE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id33">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-debug-subsys">NCCL_DEBUG_SUBSYS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id34">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-debug-timestamp-format">NCCL_DEBUG_TIMESTAMP_FORMAT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#value-accepted">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-debug-timestamp-levels">NCCL_DEBUG_TIMESTAMP_LEVELS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id35">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-collnet-enable">NCCL_COLLNET_ENABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id36">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-collnet-node-threshold">NCCL_COLLNET_NODE_THRESHOLD</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id37">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-cta-policy">NCCL_CTA_POLICY</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id38">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-netdevs-policy">NCCL_NETDEVS_POLICY</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id39">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-topo-file">NCCL_TOPO_FILE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id40">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-topo-dump-file">NCCL_TOPO_DUMP_FILE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id41">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-set-thread-name">NCCL_SET_THREAD_NAME</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id42">Value accepted</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="env.html#debugging">Debugging</a><ul>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-p2p-disable">NCCL_P2P_DISABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id43">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-p2p-level">NCCL_P2P_LEVEL</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id44">Values accepted</a></li>
<li class="toctree-l4"><a class="reference internal" href="env.html#integer-values-legacy">Integer Values (Legacy)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-p2p-direct-disable">NCCL_P2P_DIRECT_DISABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id45">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-shm-disable">NCCL_SHM_DISABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id46">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-buffsize">NCCL_BUFFSIZE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id47">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-nthreads">NCCL_NTHREADS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id48">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-max-nchannels">NCCL_MAX_NCHANNELS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id49">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-min-nchannels">NCCL_MIN_NCHANNELS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id50">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-checks-disable">NCCL_CHECKS_DISABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id51">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-check-pointers">NCCL_CHECK_POINTERS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id52">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-launch-mode">NCCL_LAUNCH_MODE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id53">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-disable">NCCL_IB_DISABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id54">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-ar-threshold">NCCL_IB_AR_THRESHOLD</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id55">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-qps-per-connection">NCCL_IB_QPS_PER_CONNECTION</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id56">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-split-data-on-qps">NCCL_IB_SPLIT_DATA_ON_QPS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id57">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-cuda-support">NCCL_IB_CUDA_SUPPORT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id58">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-pci-relaxed-ordering">NCCL_IB_PCI_RELAXED_ORDERING</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id59">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-adaptive-routing">NCCL_IB_ADAPTIVE_ROUTING</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id60">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-ece-enable">NCCL_IB_ECE_ENABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id61">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-mem-sync-domain">NCCL_MEM_SYNC_DOMAIN</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id62">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-cumem-enable">NCCL_CUMEM_ENABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id63">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-cumem-host-enable">NCCL_CUMEM_HOST_ENABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id64">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-net-gdr-level-formerly-nccl-ib-gdr-level">NCCL_NET_GDR_LEVEL (formerly NCCL_IB_GDR_LEVEL)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id65">Values accepted</a></li>
<li class="toctree-l4"><a class="reference internal" href="env.html#id66">Integer Values (Legacy)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-net-gdr-c2c">NCCL_NET_GDR_C2C</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id67">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-net-gdr-read">NCCL_NET_GDR_READ</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id68">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-net-shared-buffers">NCCL_NET_SHARED_BUFFERS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id69">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-net-shared-comms">NCCL_NET_SHARED_COMMS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id70">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-single-ring-threshold">NCCL_SINGLE_RING_THRESHOLD</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id71">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ll-threshold">NCCL_LL_THRESHOLD</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id72">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-tree-threshold">NCCL_TREE_THRESHOLD</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id73">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-algo">NCCL_ALGO</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id74">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-proto">NCCL_PROTO</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id75">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-nvb-disable">NCCL_NVB_DISABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id76">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-pxn-disable">NCCL_PXN_DISABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id77">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-p2p-pxn-level">NCCL_P2P_PXN_LEVEL</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id78">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-pxn-c2c">NCCL_PXN_C2C</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id79">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-runtime-connect">NCCL_RUNTIME_CONNECT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id80">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-graph-register">NCCL_GRAPH_REGISTER</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id82">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-local-register">NCCL_LOCAL_REGISTER</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id83">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-legacy-cuda-register">NCCL_LEGACY_CUDA_REGISTER</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id84">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-win-enable">NCCL_WIN_ENABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id85">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-set-stack-size">NCCL_SET_STACK_SIZE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id86">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-graph-mixing-support">NCCL_GRAPH_MIXING_SUPPORT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id88">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-dmabuf-enable">NCCL_DMABUF_ENABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id89">Value accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-p2p-net-chunksize">NCCL_P2P_NET_CHUNKSIZE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id90">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-p2p-ll-threshold">NCCL_P2P_LL_THRESHOLD</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id91">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-alloc-p2p-net-ll-buffers">NCCL_ALLOC_P2P_NET_LL_BUFFERS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id92">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-comm-blocking">NCCL_COMM_BLOCKING</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id93">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-cga-cluster-size">NCCL_CGA_CLUSTER_SIZE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id94">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-max-ctas">NCCL_MAX_CTAS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id95">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-min-ctas">NCCL_MIN_CTAS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id96">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-nvls-enable">NCCL_NVLS_ENABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id97">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ib-merge-nics">NCCL_IB_MERGE_NICS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id98">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-mnnvl-enable">NCCL_MNNVL_ENABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id99">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-mnnvl-uuid">NCCL_MNNVL_UUID</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id100">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-mnnvl-clique-id">NCCL_MNNVL_CLIQUE_ID</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id101">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ras-enable">NCCL_RAS_ENABLE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id102">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ras-addr">NCCL_RAS_ADDR</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id103">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ras-timeout-factor">NCCL_RAS_TIMEOUT_FACTOR</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id104">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-launch-order-implicit">NCCL_LAUNCH_ORDER_IMPLICIT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id106">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-launch-race-fatal">NCCL_LAUNCH_RACE_FATAL</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id107">Values accepted</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="env.html#nccl-ipc-use-abstract-socket">NCCL_IPC_USE_ABSTRACT_SOCKET</a><ul>
<li class="toctree-l4"><a class="reference internal" href="env.html#id108">Values accepted</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="troubleshooting.html">Troubleshooting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="troubleshooting.html#errors">Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="troubleshooting.html#ras">RAS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="troubleshooting/ras.html">RAS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="troubleshooting/ras.html#principle-of-operation">Principle of Operation</a></li>
<li class="toctree-l4"><a class="reference internal" href="troubleshooting/ras.html#ras-queries">RAS Queries</a></li>
<li class="toctree-l4"><a class="reference internal" href="troubleshooting/ras.html#sample-output">Sample Output</a></li>
<li class="toctree-l4"><a class="reference internal" href="troubleshooting/ras.html#json-output">JSON Output</a></li>
<li class="toctree-l4"><a class="reference internal" href="troubleshooting/ras.html#monitoring-mode">Monitoring Mode</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="troubleshooting.html#gpu-direct">GPU Direct</a><ul>
<li class="toctree-l3"><a class="reference internal" href="troubleshooting.html#gpu-to-gpu-communication">GPU-to-GPU communication</a></li>
<li class="toctree-l3"><a class="reference internal" href="troubleshooting.html#gpu-to-nic-communication">GPU-to-NIC communication</a></li>
<li class="toctree-l3"><a class="reference internal" href="troubleshooting.html#pci-access-control-services-acs">PCI Access Control Services (ACS)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="troubleshooting.html#topology-detection">Topology detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="troubleshooting.html#memory-issues">Memory issues</a><ul>
<li class="toctree-l3"><a class="reference internal" href="troubleshooting.html#shared-memory">Shared memory</a></li>
<li class="toctree-l3"><a class="reference internal" href="troubleshooting.html#stack-size">Stack size</a></li>
<li class="toctree-l3"><a class="reference internal" href="troubleshooting.html#unified-memory-uvm">Unified Memory (UVM)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="troubleshooting.html#networking-issues">Networking issues</a><ul>
<li class="toctree-l3"><a class="reference internal" href="troubleshooting.html#ip-network-interfaces">IP Network Interfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="troubleshooting.html#ip-ports">IP Ports</a></li>
<li class="toctree-l3"><a class="reference internal" href="troubleshooting.html#infiniband">InfiniBand</a></li>
<li class="toctree-l3"><a class="reference internal" href="troubleshooting.html#rdma-over-converged-ethernet-roce">RDMA over Converged Ethernet (RoCE)</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">NCCL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Examples</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/examples.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="examples">
<h1>Examples<a class="headerlink" href="#examples" title="Permalink to this heading"></a></h1>
<p>The examples in this section provide an overall view of how to use NCCL in various environments, combining one or multiple techniques:</p>
<ul class="simple">
<li><p>using multiple GPUs per thread/process</p></li>
<li><p>using multiple threads</p></li>
<li><p>using multiple processes - the examples with multiple processes use MPI as parallel runtime environment, but any multi-process system should be able to work similarly.</p></li>
</ul>
<p>Ensure that you always check the return codes from the NCCL functions.  For clarity, the following examples do not contain error checking.</p>
<section id="communicator-creation-and-destruction-examples">
<h2>Communicator Creation and Destruction Examples<a class="headerlink" href="#communicator-creation-and-destruction-examples" title="Permalink to this heading"></a></h2>
<p>The following examples demonstrate common use cases for NCCL initialization.</p>
<section id="example-1-single-process-single-thread-multiple-devices">
<h3>Example 1: Single Process, Single Thread, Multiple Devices<a class="headerlink" href="#example-1-single-process-single-thread-multiple-devices" title="Permalink to this heading"></a></h3>
<p>In the specific case of a single process, ncclCommInitAll can be used. Here is an example creating a communicator for 4 devices, therefore, there are 4 communicator objects:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">ncclComm_t</span><span class="w"> </span><span class="n">comms</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>
<span class="kt">int</span><span class="w"> </span><span class="n">devs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="p">};</span>
<span class="n">ncclCommInitAll</span><span class="p">(</span><span class="n">comms</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="n">devs</span><span class="p">);</span>
</pre></div>
</div>
<p>Next, you can call NCCL collective operations using a single thread and group calls, or multiple threads, each provided with a comm object.</p>
<p>At the end of the program, all of the communicator objects are destroyed:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">&lt;</span><span class="mi">4</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">  </span><span class="n">ncclCommDestroy</span><span class="p">(</span><span class="n">comms</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</pre></div>
</div>
<p>The following code depicts a complete working example with a single process that manages multiple devices:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdlib.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;cuda_runtime.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;nccl.h&quot;</span>

<span class="cp">#define CUDACHECK(cmd) do {                         \</span>
<span class="cp">  cudaError_t err = cmd;                            \</span>
<span class="cp">  if (err != cudaSuccess) {                         \</span>
<span class="cp">    printf(&quot;Failed: Cuda error %s:%d &#39;%s&#39;\n&quot;,       \</span>
<span class="cp">        __FILE__,__LINE__,cudaGetErrorString(err)); \</span>
<span class="cp">    exit(EXIT_FAILURE);                             \</span>
<span class="cp">  }                                                 \</span>
<span class="cp">} while(0)</span>


<span class="cp">#define NCCLCHECK(cmd) do {                         \</span>
<span class="cp">  ncclResult_t res = cmd;                           \</span>
<span class="cp">  if (res != ncclSuccess) {                         \</span>
<span class="cp">    printf(&quot;Failed, NCCL error %s:%d &#39;%s&#39;\n&quot;,       \</span>
<span class="cp">        __FILE__,__LINE__,ncclGetErrorString(res)); \</span>
<span class="cp">    exit(EXIT_FAILURE);                             \</span>
<span class="cp">  }                                                 \</span>
<span class="cp">} while(0)</span>


<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
<span class="w">  </span><span class="n">ncclComm_t</span><span class="w"> </span><span class="n">comms</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>


<span class="w">  </span><span class="c1">//managing 4 devices</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">nDev</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">32</span><span class="o">*</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">devs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="p">};</span>


<span class="w">  </span><span class="c1">//allocating and initializing device buffers</span>
<span class="w">  </span><span class="kt">float</span><span class="o">**</span><span class="w"> </span><span class="n">sendbuff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="o">**</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">nDev</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">));</span>
<span class="w">  </span><span class="kt">float</span><span class="o">**</span><span class="w"> </span><span class="n">recvbuff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="o">**</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">nDev</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">));</span>
<span class="w">  </span><span class="n">cudaStream_t</span><span class="o">*</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">cudaStream_t</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="n">cudaStream_t</span><span class="p">)</span><span class="o">*</span><span class="n">nDev</span><span class="p">);</span>


<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nDev</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">i</span><span class="p">));</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="n">sendbuff</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)));</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="n">recvbuff</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)));</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaMemset</span><span class="p">(</span><span class="n">sendbuff</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)));</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaMemset</span><span class="p">(</span><span class="n">recvbuff</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)));</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaStreamCreate</span><span class="p">(</span><span class="n">s</span><span class="o">+</span><span class="n">i</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>


<span class="w">  </span><span class="c1">//initializing NCCL</span>
<span class="w">  </span><span class="n">NCCLCHECK</span><span class="p">(</span><span class="n">ncclCommInitAll</span><span class="p">(</span><span class="n">comms</span><span class="p">,</span><span class="w"> </span><span class="n">nDev</span><span class="p">,</span><span class="w"> </span><span class="n">devs</span><span class="p">));</span>


<span class="w">   </span><span class="c1">//calling NCCL communication API. Group API is required when using</span>
<span class="w">   </span><span class="c1">//multiple devices per thread</span>
<span class="w">  </span><span class="n">NCCLCHECK</span><span class="p">(</span><span class="n">ncclGroupStart</span><span class="p">());</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nDev</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span>
<span class="w">    </span><span class="n">NCCLCHECK</span><span class="p">(</span><span class="n">ncclAllReduce</span><span class="p">((</span><span class="k">const</span><span class="w"> </span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="n">sendbuff</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="n">recvbuff</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">ncclFloat</span><span class="p">,</span><span class="w"> </span><span class="n">ncclSum</span><span class="p">,</span>
<span class="w">        </span><span class="n">comms</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">s</span><span class="p">[</span><span class="n">i</span><span class="p">]));</span>
<span class="w">  </span><span class="n">NCCLCHECK</span><span class="p">(</span><span class="n">ncclGroupEnd</span><span class="p">());</span>


<span class="w">  </span><span class="c1">//synchronizing on CUDA streams to wait for completion of NCCL operation</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nDev</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">i</span><span class="p">));</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaStreamSynchronize</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="n">i</span><span class="p">]));</span>
<span class="w">  </span><span class="p">}</span>


<span class="w">  </span><span class="c1">//free device buffers</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nDev</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">i</span><span class="p">));</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaFree</span><span class="p">(</span><span class="n">sendbuff</span><span class="p">[</span><span class="n">i</span><span class="p">]));</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaFree</span><span class="p">(</span><span class="n">recvbuff</span><span class="p">[</span><span class="n">i</span><span class="p">]));</span>
<span class="w">  </span><span class="p">}</span>


<span class="w">  </span><span class="c1">//finalizing NCCL</span>
<span class="w">  </span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nDev</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span>
<span class="w">      </span><span class="n">ncclCommDestroy</span><span class="p">(</span><span class="n">comms</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>


<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Success </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="example-2-one-device-per-process-or-thread">
<h3>Example 2: One Device per Process or Thread<a class="headerlink" href="#example-2-one-device-per-process-or-thread" title="Permalink to this heading"></a></h3>
<p>When a process or host thread is responsible for at most one GPU, ncclCommInitRank can be used as a collective call to create a communicator. Each thread or process will get its own object.</p>
<p>The following code is an example of a communicator creation in the context of MPI, using one device per MPI rank.</p>
<p>First, we retrieve MPI information about processes:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="n">myRank</span><span class="p">,</span><span class="w"> </span><span class="n">nRanks</span><span class="p">;</span>
<span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">myRank</span><span class="p">);</span>
<span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nRanks</span><span class="p">);</span>
</pre></div>
</div>
<p>Next, a single rank will create a unique ID and send it to all other ranks to make sure everyone has it:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">ncclUniqueId</span><span class="w"> </span><span class="n">id</span><span class="p">;</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">myRank</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="n">ncclGetUniqueId</span><span class="p">(</span><span class="o">&amp;</span><span class="n">id</span><span class="p">);</span>
<span class="n">MPI_Bcast</span><span class="p">(</span><span class="o">&amp;</span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">id</span><span class="p">),</span><span class="w"> </span><span class="n">MPI_BYTE</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
</pre></div>
</div>
<p>Finally, we create the communicator:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">ncclComm_t</span><span class="w"> </span><span class="n">comm</span><span class="p">;</span>
<span class="n">ncclCommInitRank</span><span class="p">(</span><span class="o">&amp;</span><span class="n">comm</span><span class="p">,</span><span class="w"> </span><span class="n">nRanks</span><span class="p">,</span><span class="w"> </span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="n">myRank</span><span class="p">);</span>
</pre></div>
</div>
<p>We can now call the NCCL collective operations using the communicator.</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">ncclAllReduce</span><span class="p">(</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="n">comm</span><span class="p">);</span>
</pre></div>
</div>
<p>Finally, we destroy the communicator object:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">ncclCommDestroy</span><span class="p">(</span><span class="n">comm</span><span class="p">);</span>
</pre></div>
</div>
<p>The following code depicts a complete working example with multiple MPI processes and one device per process:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;cuda_runtime.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;nccl.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;mpi.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;unistd.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdint.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdlib.h&gt;</span>


<span class="cp">#define MPICHECK(cmd) do {                          \</span>
<span class="cp">  int e = cmd;                                      \</span>
<span class="cp">  if( e != MPI_SUCCESS ) {                          \</span>
<span class="cp">    printf(&quot;Failed: MPI error %s:%d &#39;%d&#39;\n&quot;,        \</span>
<span class="cp">        __FILE__,__LINE__, e);   \</span>
<span class="cp">    exit(EXIT_FAILURE);                             \</span>
<span class="cp">  }                                                 \</span>
<span class="cp">} while(0)</span>


<span class="cp">#define CUDACHECK(cmd) do {                         \</span>
<span class="cp">  cudaError_t e = cmd;                              \</span>
<span class="cp">  if( e != cudaSuccess ) {                          \</span>
<span class="cp">    printf(&quot;Failed: Cuda error %s:%d &#39;%s&#39;\n&quot;,             \</span>
<span class="cp">        __FILE__,__LINE__,cudaGetErrorString(e));   \</span>
<span class="cp">    exit(EXIT_FAILURE);                             \</span>
<span class="cp">  }                                                 \</span>
<span class="cp">} while(0)</span>


<span class="cp">#define NCCLCHECK(cmd) do {                         \</span>
<span class="cp">  ncclResult_t r = cmd;                             \</span>
<span class="cp">  if (r!= ncclSuccess) {                            \</span>
<span class="cp">    printf(&quot;Failed, NCCL error %s:%d &#39;%s&#39;\n&quot;,             \</span>
<span class="cp">        __FILE__,__LINE__,ncclGetErrorString(r));   \</span>
<span class="cp">    exit(EXIT_FAILURE);                             \</span>
<span class="cp">  }                                                 \</span>
<span class="cp">} while(0)</span>


<span class="k">static</span><span class="w"> </span><span class="kt">uint64_t</span><span class="w"> </span><span class="nf">getHash</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">string</span><span class="p">,</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Based on DJB2a, result = result * 33 ^ char</span>
<span class="w">  </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5381</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">c</span><span class="o">++</span><span class="p">){</span>
<span class="w">    </span><span class="n">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">((</span><span class="n">result</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="mi">5</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">result</span><span class="p">)</span><span class="w"> </span><span class="o">^</span><span class="w"> </span><span class="n">string</span><span class="p">[</span><span class="n">c</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">result</span><span class="p">;</span>
<span class="p">}</span>

<span class="cm">/* Generate a hash of the unique identifying string for this host</span>
<span class="cm"> * that will be unique for both bare-metal and container instances</span>
<span class="cm"> * Equivalent of a hash of;</span>
<span class="cm"> *</span>
<span class="cm"> * $(hostname)$(cat /proc/sys/kernel/random/boot_id)</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="cp">#define HOSTID_FILE &quot;/proc/sys/kernel/random/boot_id&quot;</span>
<span class="k">static</span><span class="w"> </span><span class="kt">uint64_t</span><span class="w"> </span><span class="nf">getHostHash</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">hostname</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">char</span><span class="w"> </span><span class="n">hostHash</span><span class="p">[</span><span class="mi">1024</span><span class="p">];</span>

<span class="w">  </span><span class="c1">// Fall back is the hostname if something fails</span>
<span class="w">  </span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="n">strncpy</span><span class="p">(</span><span class="n">hostHash</span><span class="p">,</span><span class="w"> </span><span class="n">hostname</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">hostHash</span><span class="p">));</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">strlen</span><span class="p">(</span><span class="n">hostHash</span><span class="p">);</span>

<span class="w">  </span><span class="kt">FILE</span><span class="w"> </span><span class="o">*</span><span class="n">file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fopen</span><span class="p">(</span><span class="n">HOSTID_FILE</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;r&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">file</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">p</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">fscanf</span><span class="p">(</span><span class="n">file</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;%ms&quot;</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">p</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">strncpy</span><span class="p">(</span><span class="n">hostHash</span><span class="o">+</span><span class="n">offset</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">hostHash</span><span class="p">)</span><span class="o">-</span><span class="n">offset</span><span class="mi">-1</span><span class="p">);</span>
<span class="w">        </span><span class="n">free</span><span class="p">(</span><span class="n">p</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">fclose</span><span class="p">(</span><span class="n">file</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Make sure the string is terminated</span>
<span class="w">  </span><span class="n">hostHash</span><span class="p">[</span><span class="k">sizeof</span><span class="p">(</span><span class="n">hostHash</span><span class="p">)</span><span class="mi">-1</span><span class="p">]</span><span class="o">=</span><span class="sc">&#39;\0&#39;</span><span class="p">;</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">getHash</span><span class="p">(</span><span class="n">hostHash</span><span class="p">,</span><span class="w"> </span><span class="n">strlen</span><span class="p">(</span><span class="n">hostHash</span><span class="p">));</span>
<span class="p">}</span>

<span class="k">static</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">getHostName</span><span class="p">(</span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">hostname</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">maxlen</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">gethostname</span><span class="p">(</span><span class="n">hostname</span><span class="p">,</span><span class="w"> </span><span class="n">maxlen</span><span class="p">);</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">&lt;</span><span class="w"> </span><span class="n">maxlen</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">hostname</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="sc">&#39;.&#39;</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">hostname</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="sc">&#39;\0&#39;</span><span class="p">;</span>
<span class="w">        </span><span class="k">return</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>


<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">32</span><span class="o">*</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">;</span>


<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">myRank</span><span class="p">,</span><span class="w"> </span><span class="n">nRanks</span><span class="p">,</span><span class="w"> </span><span class="n">localRank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>


<span class="w">  </span><span class="c1">//initializing MPI</span>
<span class="w">  </span><span class="n">MPICHECK</span><span class="p">(</span><span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">argv</span><span class="p">));</span>
<span class="w">  </span><span class="n">MPICHECK</span><span class="p">(</span><span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">myRank</span><span class="p">));</span>
<span class="w">  </span><span class="n">MPICHECK</span><span class="p">(</span><span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nRanks</span><span class="p">));</span>


<span class="w">  </span><span class="c1">//calculating localRank based on hostname which is used in selecting a GPU</span>
<span class="w">  </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">hostHashs</span><span class="p">[</span><span class="n">nRanks</span><span class="p">];</span>
<span class="w">  </span><span class="kt">char</span><span class="w"> </span><span class="n">hostname</span><span class="p">[</span><span class="mi">1024</span><span class="p">];</span>
<span class="w">  </span><span class="n">getHostName</span><span class="p">(</span><span class="n">hostname</span><span class="p">,</span><span class="w"> </span><span class="mi">1024</span><span class="p">);</span>
<span class="w">  </span><span class="n">hostHashs</span><span class="p">[</span><span class="n">myRank</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">getHostHash</span><span class="p">(</span><span class="n">hostname</span><span class="p">);</span>
<span class="w">  </span><span class="n">MPICHECK</span><span class="p">(</span><span class="n">MPI_Allgather</span><span class="p">(</span><span class="n">MPI_IN_PLACE</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DATATYPE_NULL</span><span class="p">,</span><span class="w"> </span><span class="n">hostHashs</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">uint64_t</span><span class="p">),</span><span class="w"> </span><span class="n">MPI_BYTE</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">));</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">p</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">p</span><span class="o">&lt;</span><span class="n">nRanks</span><span class="p">;</span><span class="w"> </span><span class="n">p</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">p</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">myRank</span><span class="p">)</span><span class="w"> </span><span class="k">break</span><span class="p">;</span>
<span class="w">     </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">hostHashs</span><span class="p">[</span><span class="n">p</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">hostHashs</span><span class="p">[</span><span class="n">myRank</span><span class="p">])</span><span class="w"> </span><span class="n">localRank</span><span class="o">++</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>


<span class="w">  </span><span class="n">ncclUniqueId</span><span class="w"> </span><span class="n">id</span><span class="p">;</span>
<span class="w">  </span><span class="n">ncclComm_t</span><span class="w"> </span><span class="n">comm</span><span class="p">;</span>
<span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">sendbuff</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">recvbuff</span><span class="p">;</span>
<span class="w">  </span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">s</span><span class="p">;</span>


<span class="w">  </span><span class="c1">//get NCCL unique ID at rank 0 and broadcast it to all others</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">myRank</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="n">ncclGetUniqueId</span><span class="p">(</span><span class="o">&amp;</span><span class="n">id</span><span class="p">);</span>
<span class="w">  </span><span class="n">MPICHECK</span><span class="p">(</span><span class="n">MPI_Bcast</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">id</span><span class="p">),</span><span class="w"> </span><span class="n">MPI_BYTE</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">));</span>


<span class="w">  </span><span class="c1">//picking a GPU based on localRank, allocate device buffers</span>
<span class="w">  </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">localRank</span><span class="p">));</span>
<span class="w">  </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sendbuff</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)));</span>
<span class="w">  </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">recvbuff</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)));</span>
<span class="w">  </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaStreamCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">s</span><span class="p">));</span>


<span class="w">  </span><span class="c1">//initializing NCCL</span>
<span class="w">  </span><span class="n">NCCLCHECK</span><span class="p">(</span><span class="n">ncclCommInitRank</span><span class="p">(</span><span class="o">&amp;</span><span class="n">comm</span><span class="p">,</span><span class="w"> </span><span class="n">nRanks</span><span class="p">,</span><span class="w"> </span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="n">myRank</span><span class="p">));</span>


<span class="w">  </span><span class="c1">//communicating using NCCL</span>
<span class="w">  </span><span class="n">NCCLCHECK</span><span class="p">(</span><span class="n">ncclAllReduce</span><span class="p">((</span><span class="k">const</span><span class="w"> </span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="n">sendbuff</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="n">recvbuff</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">ncclFloat</span><span class="p">,</span><span class="w"> </span><span class="n">ncclSum</span><span class="p">,</span>
<span class="w">        </span><span class="n">comm</span><span class="p">,</span><span class="w"> </span><span class="n">s</span><span class="p">));</span>


<span class="w">  </span><span class="c1">//completing NCCL operation by synchronizing on the CUDA stream</span>
<span class="w">  </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaStreamSynchronize</span><span class="p">(</span><span class="n">s</span><span class="p">));</span>


<span class="w">  </span><span class="c1">//free device buffers</span>
<span class="w">  </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaFree</span><span class="p">(</span><span class="n">sendbuff</span><span class="p">));</span>
<span class="w">  </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaFree</span><span class="p">(</span><span class="n">recvbuff</span><span class="p">));</span>


<span class="w">  </span><span class="c1">//finalizing NCCL</span>
<span class="w">  </span><span class="n">ncclCommDestroy</span><span class="p">(</span><span class="n">comm</span><span class="p">);</span>


<span class="w">  </span><span class="c1">//finalizing MPI</span>
<span class="w">  </span><span class="n">MPICHECK</span><span class="p">(</span><span class="n">MPI_Finalize</span><span class="p">());</span>


<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;[MPI Rank %d] Success </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">myRank</span><span class="p">);</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="example-3-multiple-devices-per-thread">
<span id="ex3"></span><h3>Example 3: Multiple Devices per Thread<a class="headerlink" href="#example-3-multiple-devices-per-thread" title="Permalink to this heading"></a></h3>
<p>You can combine both multiple process or threads and multiple device per process or thread. In this case, we need to use group semantics.</p>
<p>The following example combines MPI and multiple devices per process (=MPI rank).</p>
<p>First, we retrieve MPI information about processes:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="n">myRank</span><span class="p">,</span><span class="w"> </span><span class="n">nRanks</span><span class="p">;</span>
<span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">myRank</span><span class="p">);</span>
<span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nRanks</span><span class="p">);</span>
</pre></div>
</div>
<p>Next, a single rank will create a unique ID and send it to all other ranks to make sure everyone has it:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">ncclUniqueId</span><span class="w"> </span><span class="n">id</span><span class="p">;</span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">myRank</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="n">ncclGetUniqueId</span><span class="p">(</span><span class="o">&amp;</span><span class="n">id</span><span class="p">);</span>
<span class="n">MPI_Bcast</span><span class="p">(</span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">id</span><span class="p">),</span><span class="w"> </span><span class="n">MPI_BYTE</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
</pre></div>
</div>
<p>Then, we create our ngpus communicator objects, which are part of a larger group of ngpus*nRanks:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">ncclComm_t</span><span class="w"> </span><span class="n">comms</span><span class="p">[</span><span class="n">ngpus</span><span class="p">];</span>
<span class="n">ncclGroupStart</span><span class="p">();</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">&lt;</span><span class="n">ngpus</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">devs</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="n">ncclCommInitRank</span><span class="p">(</span><span class="n">comms</span><span class="o">+</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">ngpus</span><span class="o">*</span><span class="n">nRanks</span><span class="p">,</span><span class="w"> </span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="n">myRank</span><span class="o">*</span><span class="n">ngpus</span><span class="o">+</span><span class="n">i</span><span class="p">);</span>
<span class="p">}</span>
<span class="n">ncclGroupEnd</span><span class="p">();</span>
</pre></div>
</div>
<p>Next, we call NCCL collective operations using a single thread and group calls, or multiple threads, each provided with a comm object.</p>
<p>At the end of the program, we destroy all communicators objects:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">&lt;</span><span class="n">ngpus</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">  </span><span class="n">ncclCommDestroy</span><span class="p">(</span><span class="n">comms</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</pre></div>
</div>
<p>The following code depicts a complete working example with multiple MPI processes and multiple devices per process:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;cuda_runtime.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;nccl.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;mpi.h&quot;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;unistd.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdint.h&gt;</span>


<span class="cp">#define MPICHECK(cmd) do {                          \</span>
<span class="cp">  int e = cmd;                                      \</span>
<span class="cp">  if( e != MPI_SUCCESS ) {                          \</span>
<span class="cp">    printf(&quot;Failed: MPI error %s:%d &#39;%d&#39;\n&quot;,        \</span>
<span class="cp">        __FILE__,__LINE__, e);   \</span>
<span class="cp">    exit(EXIT_FAILURE);                             \</span>
<span class="cp">  }                                                 \</span>
<span class="cp">} while(0)</span>


<span class="cp">#define CUDACHECK(cmd) do {                         \</span>
<span class="cp">  cudaError_t e = cmd;                              \</span>
<span class="cp">  if( e != cudaSuccess ) {                          \</span>
<span class="cp">    printf(&quot;Failed: Cuda error %s:%d &#39;%s&#39;\n&quot;,             \</span>
<span class="cp">        __FILE__,__LINE__,cudaGetErrorString(e));   \</span>
<span class="cp">    exit(EXIT_FAILURE);                             \</span>
<span class="cp">  }                                                 \</span>
<span class="cp">} while(0)</span>


<span class="cp">#define NCCLCHECK(cmd) do {                         \</span>
<span class="cp">  ncclResult_t r = cmd;                             \</span>
<span class="cp">  if (r!= ncclSuccess) {                            \</span>
<span class="cp">    printf(&quot;Failed, NCCL error %s:%d &#39;%s&#39;\n&quot;,             \</span>
<span class="cp">        __FILE__,__LINE__,ncclGetErrorString(r));   \</span>
<span class="cp">    exit(EXIT_FAILURE);                             \</span>
<span class="cp">  }                                                 \</span>
<span class="cp">} while(0)</span>


<span class="k">static</span><span class="w"> </span><span class="kt">uint64_t</span><span class="w"> </span><span class="nf">getHash</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">string</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Based on DJB2a, result = result * 33 ^ char</span>
<span class="w">  </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5381</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">string</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="sc">&#39;\0&#39;</span><span class="p">;</span><span class="w"> </span><span class="n">c</span><span class="o">++</span><span class="p">){</span>
<span class="w">    </span><span class="n">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">((</span><span class="n">result</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="mi">5</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">result</span><span class="p">)</span><span class="w"> </span><span class="o">^</span><span class="w"> </span><span class="n">string</span><span class="p">[</span><span class="n">c</span><span class="p">];</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">result</span><span class="p">;</span>
<span class="p">}</span>

<span class="cm">/* Generate a hash of the unique identifying string for this host</span>
<span class="cm"> * that will be unique for both bare-metal and container instances</span>
<span class="cm"> * Equivalent of a hash of;</span>
<span class="cm"> *</span>
<span class="cm"> * $(hostname)$(cat /proc/sys/kernel/random/boot_id)</span>
<span class="cm"> *</span>
<span class="cm"> */</span>
<span class="cp">#define HOSTID_FILE &quot;/proc/sys/kernel/random/boot_id&quot;</span>
<span class="k">static</span><span class="w"> </span><span class="kt">uint64_t</span><span class="w"> </span><span class="nf">getHostHash</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">hostname</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">char</span><span class="w"> </span><span class="n">hostHash</span><span class="p">[</span><span class="mi">1024</span><span class="p">];</span>

<span class="w">  </span><span class="c1">// Fall back is the hostname if something fails</span>
<span class="w">  </span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="n">strncpy</span><span class="p">(</span><span class="n">hostHash</span><span class="p">,</span><span class="w"> </span><span class="n">hostname</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">hostHash</span><span class="p">));</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">strlen</span><span class="p">(</span><span class="n">hostHash</span><span class="p">);</span>

<span class="w">  </span><span class="kt">FILE</span><span class="w"> </span><span class="o">*</span><span class="n">file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fopen</span><span class="p">(</span><span class="n">HOSTID_FILE</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;r&quot;</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">file</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">p</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">fscanf</span><span class="p">(</span><span class="n">file</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;%ms&quot;</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">p</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">strncpy</span><span class="p">(</span><span class="n">hostHash</span><span class="o">+</span><span class="n">offset</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">hostHash</span><span class="p">)</span><span class="o">-</span><span class="n">offset</span><span class="mi">-1</span><span class="p">);</span>
<span class="w">        </span><span class="n">free</span><span class="p">(</span><span class="n">p</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">fclose</span><span class="p">(</span><span class="n">file</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Make sure the string is terminated</span>
<span class="w">  </span><span class="n">hostHash</span><span class="p">[</span><span class="k">sizeof</span><span class="p">(</span><span class="n">hostHash</span><span class="p">)</span><span class="mi">-1</span><span class="p">]</span><span class="o">=</span><span class="sc">&#39;\0&#39;</span><span class="p">;</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">getHash</span><span class="p">(</span><span class="n">hostHash</span><span class="p">,</span><span class="w"> </span><span class="n">strlen</span><span class="p">(</span><span class="n">hostHash</span><span class="p">));</span>
<span class="p">}</span>

<span class="k">static</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">getHostName</span><span class="p">(</span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">hostname</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">maxlen</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">gethostname</span><span class="p">(</span><span class="n">hostname</span><span class="p">,</span><span class="w"> </span><span class="n">maxlen</span><span class="p">);</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">&lt;</span><span class="w"> </span><span class="n">maxlen</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">hostname</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="sc">&#39;.&#39;</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">hostname</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="sc">&#39;\0&#39;</span><span class="p">;</span>
<span class="w">        </span><span class="k">return</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>


<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">32</span><span class="o">*</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">;</span>


<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">myRank</span><span class="p">,</span><span class="w"> </span><span class="n">nRanks</span><span class="p">,</span><span class="w"> </span><span class="n">localRank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>


<span class="w">  </span><span class="c1">//initializing MPI</span>
<span class="w">  </span><span class="n">MPICHECK</span><span class="p">(</span><span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">argv</span><span class="p">));</span>
<span class="w">  </span><span class="n">MPICHECK</span><span class="p">(</span><span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">myRank</span><span class="p">));</span>
<span class="w">  </span><span class="n">MPICHECK</span><span class="p">(</span><span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nRanks</span><span class="p">));</span>


<span class="w">  </span><span class="c1">//calculating localRank which is used in selecting a GPU</span>
<span class="w">  </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">hostHashs</span><span class="p">[</span><span class="n">nRanks</span><span class="p">];</span>
<span class="w">  </span><span class="kt">char</span><span class="w"> </span><span class="n">hostname</span><span class="p">[</span><span class="mi">1024</span><span class="p">];</span>
<span class="w">  </span><span class="n">getHostName</span><span class="p">(</span><span class="n">hostname</span><span class="p">,</span><span class="w"> </span><span class="mi">1024</span><span class="p">);</span>
<span class="w">  </span><span class="n">hostHashs</span><span class="p">[</span><span class="n">myRank</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">getHostHash</span><span class="p">(</span><span class="n">hostname</span><span class="p">);</span>
<span class="w">  </span><span class="n">MPICHECK</span><span class="p">(</span><span class="n">MPI_Allgather</span><span class="p">(</span><span class="n">MPI_IN_PLACE</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DATATYPE_NULL</span><span class="p">,</span><span class="w"> </span><span class="n">hostHashs</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">uint64_t</span><span class="p">),</span><span class="w"> </span><span class="n">MPI_BYTE</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">));</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">p</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">p</span><span class="o">&lt;</span><span class="n">nRanks</span><span class="p">;</span><span class="w"> </span><span class="n">p</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">p</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">myRank</span><span class="p">)</span><span class="w"> </span><span class="k">break</span><span class="p">;</span>
<span class="w">     </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">hostHashs</span><span class="p">[</span><span class="n">p</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">hostHashs</span><span class="p">[</span><span class="n">myRank</span><span class="p">])</span><span class="w"> </span><span class="n">localRank</span><span class="o">++</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>


<span class="w">  </span><span class="c1">//each process is using two GPUs</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">nDev</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>


<span class="w">  </span><span class="kt">float</span><span class="o">**</span><span class="w"> </span><span class="n">sendbuff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="o">**</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">nDev</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">));</span>
<span class="w">  </span><span class="kt">float</span><span class="o">**</span><span class="w"> </span><span class="n">recvbuff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="o">**</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">nDev</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">));</span>
<span class="w">  </span><span class="n">cudaStream_t</span><span class="o">*</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">cudaStream_t</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="n">cudaStream_t</span><span class="p">)</span><span class="o">*</span><span class="n">nDev</span><span class="p">);</span>


<span class="w">  </span><span class="c1">//picking GPUs based on localRank</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nDev</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">localRank</span><span class="o">*</span><span class="n">nDev</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">));</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">(</span><span class="n">sendbuff</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)));</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaMalloc</span><span class="p">(</span><span class="n">recvbuff</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)));</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaMemset</span><span class="p">(</span><span class="n">sendbuff</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)));</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaMemset</span><span class="p">(</span><span class="n">recvbuff</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)));</span>
<span class="w">    </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaStreamCreate</span><span class="p">(</span><span class="n">s</span><span class="o">+</span><span class="n">i</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>


<span class="w">  </span><span class="n">ncclUniqueId</span><span class="w"> </span><span class="n">id</span><span class="p">;</span>
<span class="w">  </span><span class="n">ncclComm_t</span><span class="w"> </span><span class="n">comms</span><span class="p">[</span><span class="n">nDev</span><span class="p">];</span>


<span class="w">  </span><span class="c1">//generating NCCL unique ID at one process and broadcasting it to all</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">myRank</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="n">ncclGetUniqueId</span><span class="p">(</span><span class="o">&amp;</span><span class="n">id</span><span class="p">);</span>
<span class="w">  </span><span class="n">MPICHECK</span><span class="p">(</span><span class="n">MPI_Bcast</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">id</span><span class="p">),</span><span class="w"> </span><span class="n">MPI_BYTE</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">));</span>


<span class="w">  </span><span class="c1">//initializing NCCL, group API is required around ncclCommInitRank as it is</span>
<span class="w">  </span><span class="c1">//called across multiple GPUs in each thread/process</span>
<span class="w">  </span><span class="n">NCCLCHECK</span><span class="p">(</span><span class="n">ncclGroupStart</span><span class="p">());</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">&lt;</span><span class="n">nDev</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">localRank</span><span class="o">*</span><span class="n">nDev</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">));</span>
<span class="w">     </span><span class="n">NCCLCHECK</span><span class="p">(</span><span class="n">ncclCommInitRank</span><span class="p">(</span><span class="n">comms</span><span class="o">+</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">nRanks</span><span class="o">*</span><span class="n">nDev</span><span class="p">,</span><span class="w"> </span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="n">myRank</span><span class="o">*</span><span class="n">nDev</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">NCCLCHECK</span><span class="p">(</span><span class="n">ncclGroupEnd</span><span class="p">());</span>


<span class="w">  </span><span class="c1">//calling NCCL communication API. Group API is required when using</span>
<span class="w">  </span><span class="c1">//multiple devices per thread/process</span>
<span class="w">  </span><span class="n">NCCLCHECK</span><span class="p">(</span><span class="n">ncclGroupStart</span><span class="p">());</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">&lt;</span><span class="n">nDev</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">     </span><span class="n">NCCLCHECK</span><span class="p">(</span><span class="n">ncclAllReduce</span><span class="p">((</span><span class="k">const</span><span class="w"> </span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="n">sendbuff</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="n">recvbuff</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">ncclFloat</span><span class="p">,</span><span class="w"> </span><span class="n">ncclSum</span><span class="p">,</span>
<span class="w">           </span><span class="n">comms</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">s</span><span class="p">[</span><span class="n">i</span><span class="p">]));</span>
<span class="w">  </span><span class="n">NCCLCHECK</span><span class="p">(</span><span class="n">ncclGroupEnd</span><span class="p">());</span>


<span class="w">  </span><span class="c1">//synchronizing on CUDA stream to complete NCCL communication</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">&lt;</span><span class="n">nDev</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">      </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaStreamSynchronize</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="n">i</span><span class="p">]));</span>


<span class="w">  </span><span class="c1">//freeing device memory</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">&lt;</span><span class="n">nDev</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaFree</span><span class="p">(</span><span class="n">sendbuff</span><span class="p">[</span><span class="n">i</span><span class="p">]));</span>
<span class="w">     </span><span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaFree</span><span class="p">(</span><span class="n">recvbuff</span><span class="p">[</span><span class="n">i</span><span class="p">]));</span>
<span class="w">  </span><span class="p">}</span>


<span class="w">  </span><span class="c1">//finalizing NCCL</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">&lt;</span><span class="n">nDev</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="n">ncclCommDestroy</span><span class="p">(</span><span class="n">comms</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">  </span><span class="p">}</span>


<span class="w">  </span><span class="c1">//finalizing MPI</span>
<span class="w">  </span><span class="n">MPICHECK</span><span class="p">(</span><span class="n">MPI_Finalize</span><span class="p">());</span>


<span class="w">  </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;[MPI Rank %d] Success </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">myRank</span><span class="p">);</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="example-4-multiple-communicators-per-device">
<span id="ex4"></span><h3>Example 4: Multiple communicators per device<a class="headerlink" href="#example-4-multiple-communicators-per-device" title="Permalink to this heading"></a></h3>
<p>NCCL allows users to create multiple communicators per device. The following code shows an example with multiple MPI processes, one device per process, and multiple communicators per device:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="c1">// blocking communicators</span>
<span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">localRank</span><span class="p">));</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">commNum</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">myRank</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="n">ncclGetUniqueId</span><span class="p">(</span><span class="o">&amp;</span><span class="n">id</span><span class="p">);</span>
<span class="w">  </span><span class="n">MPICHECK</span><span class="p">(</span><span class="n">MPI_Bcast</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">id</span><span class="p">),</span><span class="w"> </span><span class="n">MPI_BYTE</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">));</span>
<span class="w">  </span><span class="n">NCCLCHECK</span><span class="p">(</span><span class="n">ncclCommInitRank</span><span class="p">(</span><span class="o">&amp;</span><span class="n">blockingComms</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">nRanks</span><span class="p">,</span><span class="w"> </span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="n">myRank</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// non-blocking communicators</span>
<span class="n">CUDACHECK</span><span class="p">(</span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">localRank</span><span class="p">));</span>
<span class="n">ncclConfig_t</span><span class="w"> </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">NCCL_CONFIG_INITIALIZER</span><span class="p">;</span>
<span class="n">config</span><span class="p">.</span><span class="n">blocking</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">commNum</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">myRank</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="n">ncclGetUniqueId</span><span class="p">(</span><span class="o">&amp;</span><span class="n">id</span><span class="p">);</span>
<span class="w">  </span><span class="n">MPICHECK</span><span class="p">(</span><span class="n">MPI_Bcast</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">id</span><span class="p">),</span><span class="w"> </span><span class="n">MPI_BYTE</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">));</span>
<span class="w">  </span><span class="n">NCCLCHECK</span><span class="p">(</span><span class="n">ncclCommInitRankConfig</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nonblockingComms</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">nRanks</span><span class="p">,</span><span class="w"> </span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="n">myRank</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">config</span><span class="p">));</span>
<span class="w">  </span><span class="k">do</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">NCCLCHECK</span><span class="p">(</span><span class="n">ncclCommGetAsyncError</span><span class="p">(</span><span class="n">nonblockingComms</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="o">&amp;</span><span class="n">state</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">while</span><span class="p">(</span><span class="n">state</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">ncclInProgress</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">checkTimeout</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p><cite>checkTimeout()</cite> should be a user-defined function. For more nonblocking communicator usage, please check <a class="reference internal" href="usage/communicators.html#ft"><span class="std std-ref">Fault Tolerance</span></a>.
In addition, if you want to split communicators instead of creating a new one, please check <a class="reference internal" href="api/comms.html#c.ncclCommSplit" title="ncclCommSplit"><code class="xref c c-func docutils literal notranslate"><span class="pre">ncclCommSplit()</span></code></a>.</p>
</section>
</section>
<section id="communication-examples">
<h2>Communication Examples<a class="headerlink" href="#communication-examples" title="Permalink to this heading"></a></h2>
<p>The following examples demonstrate common patterns for executing NCCL collectives.</p>
<section id="example-1-one-device-per-process-or-thread">
<h3>Example 1: One Device per Process or Thread<a class="headerlink" href="#example-1-one-device-per-process-or-thread" title="Permalink to this heading"></a></h3>
<p>If you have a thread or process per device, then each thread calls the collective operation for its device, for example, AllReduce:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">ncclAllReduce</span><span class="p">(</span><span class="n">sendbuff</span><span class="p">,</span><span class="w"> </span><span class="n">recvbuff</span><span class="p">,</span><span class="w"> </span><span class="n">count</span><span class="p">,</span><span class="w"> </span><span class="n">datatype</span><span class="p">,</span><span class="w"> </span><span class="n">op</span><span class="p">,</span><span class="w"> </span><span class="n">comm</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
</pre></div>
</div>
<p>After the call, the operation has been enqueued to the stream.  Therefore, you can call cudaStreamSynchronize if you want to wait for the operation to be complete:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">cudaStreamSynchronize</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>
</pre></div>
</div>
<p>For a complete working example with MPI and single device per MPI process, see Example 2: One Device per Process or Thread.</p>
</section>
<section id="example-2-multiple-devices-per-thread">
<h3>Example 2: Multiple Devices per Thread<a class="headerlink" href="#example-2-multiple-devices-per-thread" title="Permalink to this heading"></a></h3>
<p>When a single thread manages multiple devices, you need to use group semantics to launch the operation on multiple devices at once:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="n">ncclGroupStart</span><span class="p">();</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">&lt;</span><span class="n">ngpus</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">  </span><span class="n">ncclAllReduce</span><span class="p">(</span><span class="n">sendbuffs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">recvbuff</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">count</span><span class="p">,</span><span class="w"> </span><span class="n">datatype</span><span class="p">,</span><span class="w"> </span><span class="n">op</span><span class="p">,</span><span class="w"> </span><span class="n">comms</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">streams</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="n">ncclGroupEnd</span><span class="p">();</span>
</pre></div>
</div>
<p>After ncclGroupEnd, all of the operations have been enqueued to the stream.  Therefore, you can now call cudaStreamSynchronize if you want to wait for the operation to be complete:</p>
<div class="highlight-C notranslate"><div class="highlight"><pre><span></span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">&lt;</span><span class="n">ngpus</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">  </span><span class="n">cudaStreamSynchronize</span><span class="p">(</span><span class="n">streams</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</pre></div>
</div>
<p>For a complete working example with MPI and multiple devices per MPI process, see <a class="reference internal" href="#ex3"><span class="std std-ref">Example 3: Multiple Devices per Thread</span></a>.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="nccl1.html" class="btn btn-neutral float-left" title="Migrating from NCCL 1 to NCCL 2" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mpi.html" class="btn btn-neutral float-right" title="NCCL and MPI" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020-2025, NVIDIA Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>  
  <style>
  a:link, a:visited {
    color: #76b900;
  }
  a:hover {
    color: #8c0;
  }
  .rst-content dl:not(.docutils) dt {
    background: rgba(118, 185, 0, 0.1) !important;
    color: rgba(59,93,0,1) !important;
    border-top: solid 3px rgba(59,93,0,1) !important;
  }
  </style>
  <script type="text/javascript">_satellite.pageBottom();</script>


</body>
</html>