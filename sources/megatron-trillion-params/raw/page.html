<!doctype html>
<html lang="en-US" id="html">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge"><script type="text/javascript">(window.NREUM||(NREUM={})).init={ajax:{deny_list:["bam.nr-data.net"]},feature_flags:["soft_nav"]};(window.NREUM||(NREUM={})).loader_config={licenseKey:"NRJS-2b0defbeb07862260b2",applicationID:"745178505",browserID:"745179240"};;/*! For license information please see nr-loader-rum-1.310.1.min.js.LICENSE.txt */
(()=>{var e,t,r={163:(e,t,r)=>{"use strict";r.d(t,{j:()=>E});var n=r(384),i=r(1741);var s=r(2555);r(860).K7.genericEvents;const a="experimental.resources",o="register",c=e=>{if(!e||"string"!=typeof e)return!1;try{document.createDocumentFragment().querySelector(e)}catch{return!1}return!0};var d=r(2614),u=r(944),l=r(8122);const f="[data-nr-mask]",g=e=>(0,l.a)(e,(()=>{const e={feature_flags:[],experimental:{allow_registered_children:!1,resources:!1},mask_selector:"*",block_selector:"[data-nr-block]",mask_input_options:{color:!1,date:!1,"datetime-local":!1,email:!1,month:!1,number:!1,range:!1,search:!1,tel:!1,text:!1,time:!1,url:!1,week:!1,textarea:!1,select:!1,password:!0}};return{ajax:{deny_list:void 0,block_internal:!0,enabled:!0,autoStart:!0},api:{get allow_registered_children(){return e.feature_flags.includes(o)||e.experimental.allow_registered_children},set allow_registered_children(t){e.experimental.allow_registered_children=t},duplicate_registered_data:!1},browser_consent_mode:{enabled:!1},distributed_tracing:{enabled:void 0,exclude_newrelic_header:void 0,cors_use_newrelic_header:void 0,cors_use_tracecontext_headers:void 0,allowed_origins:void 0},get feature_flags(){return e.feature_flags},set feature_flags(t){e.feature_flags=t},generic_events:{enabled:!0,autoStart:!0},harvest:{interval:30},jserrors:{enabled:!0,autoStart:!0},logging:{enabled:!0,autoStart:!0},metrics:{enabled:!0,autoStart:!0},obfuscate:void 0,page_action:{enabled:!0},page_view_event:{enabled:!0,autoStart:!0},page_view_timing:{enabled:!0,autoStart:!0},performance:{capture_marks:!1,capture_measures:!1,capture_detail:!0,resources:{get enabled(){return e.feature_flags.includes(a)||e.experimental.resources},set enabled(t){e.experimental.resources=t},asset_types:[],first_party_domains:[],ignore_newrelic:!0}},privacy:{cookies_enabled:!0},proxy:{assets:void 0,beacon:void 0},session:{expiresMs:d.wk,inactiveMs:d.BB},session_replay:{autoStart:!0,enabled:!1,preload:!1,sampling_rate:10,error_sampling_rate:100,collect_fonts:!1,inline_images:!1,fix_stylesheets:!0,mask_all_inputs:!0,get mask_text_selector(){return e.mask_selector},set mask_text_selector(t){c(t)?e.mask_selector="".concat(t,",").concat(f):""===t||null===t?e.mask_selector=f:(0,u.R)(5,t)},get block_class(){return"nr-block"},get ignore_class(){return"nr-ignore"},get mask_text_class(){return"nr-mask"},get block_selector(){return e.block_selector},set block_selector(t){c(t)?e.block_selector+=",".concat(t):""!==t&&(0,u.R)(6,t)},get mask_input_options(){return e.mask_input_options},set mask_input_options(t){t&&"object"==typeof t?e.mask_input_options={...t,password:!0}:(0,u.R)(7,t)}},session_trace:{enabled:!0,autoStart:!0},soft_navigations:{enabled:!0,autoStart:!0},ssl:void 0,user_actions:{enabled:!0,elementAttributes:["id","className","tagName","type"]}}})());var p=r(6154),h=r(9324);let m=0;const v={buildEnv:h.F3,distMethod:h.Xs,version:h.xv,originTime:p.WN},b={consented:!1},y={appMetadata:{},get consented(){return this.session?.state?.consent||b.consented},set consented(e){b.consented=e},customTransaction:void 0,denyList:void 0,disabled:!1,harvester:void 0,isolatedBacklog:!1,isRecording:!1,loaderType:void 0,maxBytes:3e4,obfuscator:void 0,onerror:void 0,ptid:void 0,releaseIds:{},session:void 0,timeKeeper:void 0,registeredEntities:[],jsAttributesMetadata:{bytes:0},get harvestCount(){return++m}},_=e=>{const t=(0,l.a)(e,y),r=Object.keys(v).reduce((e,t)=>(e[t]={value:v[t],writable:!1,configurable:!0,enumerable:!0},e),{});return Object.defineProperties(t,r)};var w=r(5701);const x=e=>{const t=e.startsWith("http");e+="/",r.p=t?e:"https://"+e};var k=r(7836),R=r(3241);const A={accountID:void 0,trustKey:void 0,agentID:void 0,licenseKey:void 0,applicationID:void 0,xpid:void 0},S=e=>(0,l.a)(e,A),T=new Set;function E(e,t={},r,a){let{init:o,info:c,loader_config:d,runtime:u={},exposed:l=!0}=t;if(!c){const e=(0,n.pV)();o=e.init,c=e.info,d=e.loader_config}e.init=g(o||{}),e.loader_config=S(d||{}),c.jsAttributes??={},p.bv&&(c.jsAttributes.isWorker=!0),e.info=(0,s.D)(c);const f=e.init,h=[c.beacon,c.errorBeacon];T.has(e.agentIdentifier)||(f.proxy.assets&&(x(f.proxy.assets),h.push(f.proxy.assets)),f.proxy.beacon&&h.push(f.proxy.beacon),e.beacons=[...h],function(e){const t=(0,n.pV)();Object.getOwnPropertyNames(i.W.prototype).forEach(r=>{const n=i.W.prototype[r];if("function"!=typeof n||"constructor"===n)return;let s=t[r];e[r]&&!1!==e.exposed&&"micro-agent"!==e.runtime?.loaderType&&(t[r]=(...t)=>{const n=e[r](...t);return s?s(...t):n})})}(e),(0,n.US)("activatedFeatures",w.B)),u.denyList=[...f.ajax.deny_list||[],...f.ajax.block_internal?h:[]],u.ptid=e.agentIdentifier,u.loaderType=r,e.runtime=_(u),T.has(e.agentIdentifier)||(e.ee=k.ee.get(e.agentIdentifier),e.exposed=l,(0,R.W)({agentIdentifier:e.agentIdentifier,drained:!!w.B?.[e.agentIdentifier],type:"lifecycle",name:"initialize",feature:void 0,data:e.config})),T.add(e.agentIdentifier)}},384:(e,t,r)=>{"use strict";r.d(t,{NT:()=>o,US:()=>l,Zm:()=>c,bQ:()=>u,dV:()=>d,pV:()=>f});var n=r(6154),i=r(1863),s=r(944),a=r(1910);const o={beacon:"bam.nr-data.net",errorBeacon:"bam.nr-data.net"};function c(){return n.gm.NREUM||(n.gm.NREUM={}),void 0===n.gm.newrelic&&(n.gm.newrelic=n.gm.NREUM),n.gm.NREUM}function d(){let e=c();return e.o||(e.o={ST:n.gm.setTimeout,SI:n.gm.setImmediate||n.gm.setInterval,CT:n.gm.clearTimeout,XHR:n.gm.XMLHttpRequest,REQ:n.gm.Request,EV:n.gm.Event,PR:n.gm.Promise,MO:n.gm.MutationObserver,FETCH:n.gm.fetch,WS:n.gm.WebSocket},(0,a.i)(...Object.values(e.o))),e}function u(e,t){let r=c();r.initializedAgents??={},t.initializedAt={ms:(0,i.t)(),date:new Date},r.initializedAgents[e]=t,2===Object.keys(r.initializedAgents).length&&(0,s.R)(69)}function l(e,t){c()[e]=t}function f(){return function(){let e=c();const t=e.info||{};e.info={beacon:o.beacon,errorBeacon:o.errorBeacon,...t}}(),function(){let e=c();const t=e.init||{};e.init={...t}}(),d(),function(){let e=c();const t=e.loader_config||{};e.loader_config={...t}}(),c()}},782:(e,t,r)=>{"use strict";r.d(t,{T:()=>n});const n=r(860).K7.pageViewTiming},860:(e,t,r)=>{"use strict";r.d(t,{$J:()=>u,K7:()=>c,P3:()=>d,XX:()=>i,Yy:()=>o,df:()=>s,qY:()=>n,v4:()=>a});const n="events",i="jserrors",s="browser/blobs",a="rum",o="browser/logs",c={ajax:"ajax",genericEvents:"generic_events",jserrors:i,logging:"logging",metrics:"metrics",pageAction:"page_action",pageViewEvent:"page_view_event",pageViewTiming:"page_view_timing",sessionReplay:"session_replay",sessionTrace:"session_trace",softNav:"soft_navigations"},d={[c.pageViewEvent]:1,[c.pageViewTiming]:2,[c.metrics]:3,[c.jserrors]:4,[c.softNav]:5,[c.ajax]:6,[c.sessionTrace]:7,[c.sessionReplay]:8,[c.logging]:9,[c.genericEvents]:10},u={[c.pageViewEvent]:a,[c.pageViewTiming]:n,[c.ajax]:n,[c.softNav]:n,[c.metrics]:i,[c.jserrors]:i,[c.sessionTrace]:s,[c.sessionReplay]:s,[c.logging]:o,[c.genericEvents]:"ins"}},944:(e,t,r)=>{"use strict";r.d(t,{R:()=>i});var n=r(3241);function i(e,t){"function"==typeof console.debug&&(console.debug("New Relic Warning: https://github.com/newrelic/newrelic-browser-agent/blob/main/docs/warning-codes.md#".concat(e),t),(0,n.W)({agentIdentifier:null,drained:null,type:"data",name:"warn",feature:"warn",data:{code:e,secondary:t}}))}},1687:(e,t,r)=>{"use strict";r.d(t,{Ak:()=>d,Ze:()=>f,x3:()=>u});var n=r(3241),i=r(7836),s=r(3606),a=r(860),o=r(2646);const c={};function d(e,t){const r={staged:!1,priority:a.P3[t]||0};l(e),c[e].get(t)||c[e].set(t,r)}function u(e,t){e&&c[e]&&(c[e].get(t)&&c[e].delete(t),p(e,t,!1),c[e].size&&g(e))}function l(e){if(!e)throw new Error("agentIdentifier required");c[e]||(c[e]=new Map)}function f(e="",t="feature",r=!1){if(l(e),!e||!c[e].get(t)||r)return p(e,t);c[e].get(t).staged=!0,g(e)}function g(e){const t=Array.from(c[e]);t.every(([e,t])=>t.staged)&&(t.sort((e,t)=>e[1].priority-t[1].priority),t.forEach(([t])=>{c[e].delete(t),p(e,t)}))}function p(e,t,r=!0){const a=e?i.ee.get(e):i.ee,c=s.i.handlers;if(!a.aborted&&a.backlog&&c){if((0,n.W)({agentIdentifier:e,type:"lifecycle",name:"drain",feature:t}),r){const e=a.backlog[t],r=c[t];if(r){for(let t=0;e&&t<e.length;++t)h(e[t],r);Object.entries(r).forEach(([e,t])=>{Object.values(t||{}).forEach(t=>{t[0]?.on&&t[0].context()instanceof o.y&&!t[0].listeners(e).includes(t[1])&&t[0].on(e,t[1])})})}}a.isolatedBacklog||delete c[t],a.backlog[t]=null,a.emit("drain-"+t,[])}}function h(e,t){var r=e[1];Object.values(t[r]||{}).forEach(t=>{var r=e[0];if(t[0]===r){var n=t[1],i=e[3],s=e[2];n.apply(i,s)}})}},1738:(e,t,r)=>{"use strict";r.d(t,{U:()=>g,Y:()=>f});var n=r(3241),i=r(9908),s=r(1863),a=r(944),o=r(5701),c=r(3969),d=r(8362),u=r(860),l=r(4261);function f(e,t,r,s){const f=s||r;!f||f[e]&&f[e]!==d.d.prototype[e]||(f[e]=function(){(0,i.p)(c.xV,["API/"+e+"/called"],void 0,u.K7.metrics,r.ee),(0,n.W)({agentIdentifier:r.agentIdentifier,drained:!!o.B?.[r.agentIdentifier],type:"data",name:"api",feature:l.Pl+e,data:{}});try{return t.apply(this,arguments)}catch(e){(0,a.R)(23,e)}})}function g(e,t,r,n,a){const o=e.info;null===r?delete o.jsAttributes[t]:o.jsAttributes[t]=r,(a||null===r)&&(0,i.p)(l.Pl+n,[(0,s.t)(),t,r],void 0,"session",e.ee)}},1741:(e,t,r)=>{"use strict";r.d(t,{W:()=>s});var n=r(944),i=r(4261);class s{#e(e,...t){if(this[e]!==s.prototype[e])return this[e](...t);(0,n.R)(35,e)}addPageAction(e,t){return this.#e(i.hG,e,t)}register(e){return this.#e(i.eY,e)}recordCustomEvent(e,t){return this.#e(i.fF,e,t)}setPageViewName(e,t){return this.#e(i.Fw,e,t)}setCustomAttribute(e,t,r){return this.#e(i.cD,e,t,r)}noticeError(e,t){return this.#e(i.o5,e,t)}setUserId(e,t=!1){return this.#e(i.Dl,e,t)}setApplicationVersion(e){return this.#e(i.nb,e)}setErrorHandler(e){return this.#e(i.bt,e)}addRelease(e,t){return this.#e(i.k6,e,t)}log(e,t){return this.#e(i.$9,e,t)}start(){return this.#e(i.d3)}finished(e){return this.#e(i.BL,e)}recordReplay(){return this.#e(i.CH)}pauseReplay(){return this.#e(i.Tb)}addToTrace(e){return this.#e(i.U2,e)}setCurrentRouteName(e){return this.#e(i.PA,e)}interaction(e){return this.#e(i.dT,e)}wrapLogger(e,t,r){return this.#e(i.Wb,e,t,r)}measure(e,t){return this.#e(i.V1,e,t)}consent(e){return this.#e(i.Pv,e)}}},1863:(e,t,r)=>{"use strict";function n(){return Math.floor(performance.now())}r.d(t,{t:()=>n})},1910:(e,t,r)=>{"use strict";r.d(t,{i:()=>s});var n=r(944);const i=new Map;function s(...e){return e.every(e=>{if(i.has(e))return i.get(e);const t="function"==typeof e?e.toString():"",r=t.includes("[native code]"),s=t.includes("nrWrapper");return r||s||(0,n.R)(64,e?.name||t),i.set(e,r),r})}},2555:(e,t,r)=>{"use strict";r.d(t,{D:()=>o,f:()=>a});var n=r(384),i=r(8122);const s={beacon:n.NT.beacon,errorBeacon:n.NT.errorBeacon,licenseKey:void 0,applicationID:void 0,sa:void 0,queueTime:void 0,applicationTime:void 0,ttGuid:void 0,user:void 0,account:void 0,product:void 0,extra:void 0,jsAttributes:{},userAttributes:void 0,atts:void 0,transactionName:void 0,tNamePlain:void 0};function a(e){try{return!!e.licenseKey&&!!e.errorBeacon&&!!e.applicationID}catch(e){return!1}}const o=e=>(0,i.a)(e,s)},2614:(e,t,r)=>{"use strict";r.d(t,{BB:()=>a,H3:()=>n,g:()=>d,iL:()=>c,tS:()=>o,uh:()=>i,wk:()=>s});const n="NRBA",i="SESSION",s=144e5,a=18e5,o={STARTED:"session-started",PAUSE:"session-pause",RESET:"session-reset",RESUME:"session-resume",UPDATE:"session-update"},c={SAME_TAB:"same-tab",CROSS_TAB:"cross-tab"},d={OFF:0,FULL:1,ERROR:2}},2646:(e,t,r)=>{"use strict";r.d(t,{y:()=>n});class n{constructor(e){this.contextId=e}}},2843:(e,t,r)=>{"use strict";r.d(t,{G:()=>s,u:()=>i});var n=r(3878);function i(e,t=!1,r,i){(0,n.DD)("visibilitychange",function(){if(t)return void("hidden"===document.visibilityState&&e());e(document.visibilityState)},r,i)}function s(e,t,r){(0,n.sp)("pagehide",e,t,r)}},3241:(e,t,r)=>{"use strict";r.d(t,{W:()=>s});var n=r(6154);const i="newrelic";function s(e={}){try{n.gm.dispatchEvent(new CustomEvent(i,{detail:e}))}catch(e){}}},3606:(e,t,r)=>{"use strict";r.d(t,{i:()=>s});var n=r(9908);s.on=a;var i=s.handlers={};function s(e,t,r,s){a(s||n.d,i,e,t,r)}function a(e,t,r,i,s){s||(s="feature"),e||(e=n.d);var a=t[s]=t[s]||{};(a[r]=a[r]||[]).push([e,i])}},3878:(e,t,r)=>{"use strict";function n(e,t){return{capture:e,passive:!1,signal:t}}function i(e,t,r=!1,i){window.addEventListener(e,t,n(r,i))}function s(e,t,r=!1,i){document.addEventListener(e,t,n(r,i))}r.d(t,{DD:()=>s,jT:()=>n,sp:()=>i})},3969:(e,t,r)=>{"use strict";r.d(t,{TZ:()=>n,XG:()=>o,rs:()=>i,xV:()=>a,z_:()=>s});const n=r(860).K7.metrics,i="sm",s="cm",a="storeSupportabilityMetrics",o="storeEventMetrics"},4234:(e,t,r)=>{"use strict";r.d(t,{W:()=>s});var n=r(7836),i=r(1687);class s{constructor(e,t){this.agentIdentifier=e,this.ee=n.ee.get(e),this.featureName=t,this.blocked=!1}deregisterDrain(){(0,i.x3)(this.agentIdentifier,this.featureName)}}},4261:(e,t,r)=>{"use strict";r.d(t,{$9:()=>d,BL:()=>o,CH:()=>g,Dl:()=>_,Fw:()=>y,PA:()=>m,Pl:()=>n,Pv:()=>R,Tb:()=>l,U2:()=>s,V1:()=>k,Wb:()=>x,bt:()=>b,cD:()=>v,d3:()=>w,dT:()=>c,eY:()=>p,fF:()=>f,hG:()=>i,k6:()=>a,nb:()=>h,o5:()=>u});const n="api-",i="addPageAction",s="addToTrace",a="addRelease",o="finished",c="interaction",d="log",u="noticeError",l="pauseReplay",f="recordCustomEvent",g="recordReplay",p="register",h="setApplicationVersion",m="setCurrentRouteName",v="setCustomAttribute",b="setErrorHandler",y="setPageViewName",_="setUserId",w="start",x="wrapLogger",k="measure",R="consent"},5289:(e,t,r)=>{"use strict";r.d(t,{GG:()=>a,Qr:()=>c,sB:()=>o});var n=r(3878),i=r(6389);function s(){return"undefined"==typeof document||"complete"===document.readyState}function a(e,t){if(s())return e();const r=(0,i.J)(e),a=setInterval(()=>{s()&&(clearInterval(a),r())},500);(0,n.sp)("load",r,t)}function o(e){if(s())return e();(0,n.DD)("DOMContentLoaded",e)}function c(e){if(s())return e();(0,n.sp)("popstate",e)}},5607:(e,t,r)=>{"use strict";r.d(t,{W:()=>n});const n=(0,r(9566).bz)()},5701:(e,t,r)=>{"use strict";r.d(t,{B:()=>s,t:()=>a});var n=r(3241);const i=new Set,s={};function a(e,t){const r=t.agentIdentifier;s[r]??={},e&&"object"==typeof e&&(i.has(r)||(t.ee.emit("rumresp",[e]),s[r]=e,i.add(r),(0,n.W)({agentIdentifier:r,loaded:!0,drained:!0,type:"lifecycle",name:"load",feature:void 0,data:e})))}},6154:(e,t,r)=>{"use strict";r.d(t,{OF:()=>c,RI:()=>i,WN:()=>u,bv:()=>s,eN:()=>l,gm:()=>a,mw:()=>o,sb:()=>d});var n=r(1863);const i="undefined"!=typeof window&&!!window.document,s="undefined"!=typeof WorkerGlobalScope&&("undefined"!=typeof self&&self instanceof WorkerGlobalScope&&self.navigator instanceof WorkerNavigator||"undefined"!=typeof globalThis&&globalThis instanceof WorkerGlobalScope&&globalThis.navigator instanceof WorkerNavigator),a=i?window:"undefined"!=typeof WorkerGlobalScope&&("undefined"!=typeof self&&self instanceof WorkerGlobalScope&&self||"undefined"!=typeof globalThis&&globalThis instanceof WorkerGlobalScope&&globalThis),o=Boolean("hidden"===a?.document?.visibilityState),c=/iPad|iPhone|iPod/.test(a.navigator?.userAgent),d=c&&"undefined"==typeof SharedWorker,u=((()=>{const e=a.navigator?.userAgent?.match(/Firefox[/\s](\d+\.\d+)/);Array.isArray(e)&&e.length>=2&&e[1]})(),Date.now()-(0,n.t)()),l=()=>"undefined"!=typeof PerformanceNavigationTiming&&a?.performance?.getEntriesByType("navigation")?.[0]?.responseStart},6389:(e,t,r)=>{"use strict";function n(e,t=500,r={}){const n=r?.leading||!1;let i;return(...r)=>{n&&void 0===i&&(e.apply(this,r),i=setTimeout(()=>{i=clearTimeout(i)},t)),n||(clearTimeout(i),i=setTimeout(()=>{e.apply(this,r)},t))}}function i(e){let t=!1;return(...r)=>{t||(t=!0,e.apply(this,r))}}r.d(t,{J:()=>i,s:()=>n})},6630:(e,t,r)=>{"use strict";r.d(t,{T:()=>n});const n=r(860).K7.pageViewEvent},7699:(e,t,r)=>{"use strict";r.d(t,{It:()=>s,KC:()=>o,No:()=>i,qh:()=>a});var n=r(860);const i=16e3,s=1e6,a="SESSION_ERROR",o={[n.K7.logging]:!0,[n.K7.genericEvents]:!1,[n.K7.jserrors]:!1,[n.K7.ajax]:!1}},7836:(e,t,r)=>{"use strict";r.d(t,{P:()=>o,ee:()=>c});var n=r(384),i=r(8990),s=r(2646),a=r(5607);const o="nr@context:".concat(a.W),c=function e(t,r){var n={},a={},u={},l=!1;try{l=16===r.length&&d.initializedAgents?.[r]?.runtime.isolatedBacklog}catch(e){}var f={on:p,addEventListener:p,removeEventListener:function(e,t){var r=n[e];if(!r)return;for(var i=0;i<r.length;i++)r[i]===t&&r.splice(i,1)},emit:function(e,r,n,i,s){!1!==s&&(s=!0);if(c.aborted&&!i)return;t&&s&&t.emit(e,r,n);var o=g(n);h(e).forEach(e=>{e.apply(o,r)});var d=v()[a[e]];d&&d.push([f,e,r,o]);return o},get:m,listeners:h,context:g,buffer:function(e,t){const r=v();if(t=t||"feature",f.aborted)return;Object.entries(e||{}).forEach(([e,n])=>{a[n]=t,t in r||(r[t]=[])})},abort:function(){f._aborted=!0,Object.keys(f.backlog).forEach(e=>{delete f.backlog[e]})},isBuffering:function(e){return!!v()[a[e]]},debugId:r,backlog:l?{}:t&&"object"==typeof t.backlog?t.backlog:{},isolatedBacklog:l};return Object.defineProperty(f,"aborted",{get:()=>{let e=f._aborted||!1;return e||(t&&(e=t.aborted),e)}}),f;function g(e){return e&&e instanceof s.y?e:e?(0,i.I)(e,o,()=>new s.y(o)):new s.y(o)}function p(e,t){n[e]=h(e).concat(t)}function h(e){return n[e]||[]}function m(t){return u[t]=u[t]||e(f,t)}function v(){return f.backlog}}(void 0,"globalEE"),d=(0,n.Zm)();d.ee||(d.ee=c)},8122:(e,t,r)=>{"use strict";r.d(t,{a:()=>i});var n=r(944);function i(e,t){try{if(!e||"object"!=typeof e)return(0,n.R)(3);if(!t||"object"!=typeof t)return(0,n.R)(4);const r=Object.create(Object.getPrototypeOf(t),Object.getOwnPropertyDescriptors(t)),s=0===Object.keys(r).length?e:r;for(let a in s)if(void 0!==e[a])try{if(null===e[a]){r[a]=null;continue}Array.isArray(e[a])&&Array.isArray(t[a])?r[a]=Array.from(new Set([...e[a],...t[a]])):"object"==typeof e[a]&&"object"==typeof t[a]?r[a]=i(e[a],t[a]):r[a]=e[a]}catch(e){r[a]||(0,n.R)(1,e)}return r}catch(e){(0,n.R)(2,e)}}},8362:(e,t,r)=>{"use strict";r.d(t,{d:()=>s});var n=r(9566),i=r(1741);class s extends i.W{agentIdentifier=(0,n.LA)(16)}},8374:(e,t,r)=>{r.nc=(()=>{try{return document?.currentScript?.nonce}catch(e){}return""})()},8990:(e,t,r)=>{"use strict";r.d(t,{I:()=>i});var n=Object.prototype.hasOwnProperty;function i(e,t,r){if(n.call(e,t))return e[t];var i=r();if(Object.defineProperty&&Object.keys)try{return Object.defineProperty(e,t,{value:i,writable:!0,enumerable:!1}),i}catch(e){}return e[t]=i,i}},9324:(e,t,r)=>{"use strict";r.d(t,{F3:()=>i,Xs:()=>s,xv:()=>n});const n="1.310.1",i="PROD",s="CDN"},9566:(e,t,r)=>{"use strict";r.d(t,{LA:()=>o,bz:()=>a});var n=r(6154);const i="xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx";function s(e,t){return e?15&e[t]:16*Math.random()|0}function a(){const e=n.gm?.crypto||n.gm?.msCrypto;let t,r=0;return e&&e.getRandomValues&&(t=e.getRandomValues(new Uint8Array(30))),i.split("").map(e=>"x"===e?s(t,r++).toString(16):"y"===e?(3&s()|8).toString(16):e).join("")}function o(e){const t=n.gm?.crypto||n.gm?.msCrypto;let r,i=0;t&&t.getRandomValues&&(r=t.getRandomValues(new Uint8Array(e)));const a=[];for(var o=0;o<e;o++)a.push(s(r,i++).toString(16));return a.join("")}},9908:(e,t,r)=>{"use strict";r.d(t,{d:()=>n,p:()=>i});var n=r(7836).ee.get("handle");function i(e,t,r,i,s){s?(s.buffer([e],i),s.emit(e,t,r)):(n.buffer([e],i),n.emit(e,t,r))}}},n={};function i(e){var t=n[e];if(void 0!==t)return t.exports;var s=n[e]={exports:{}};return r[e](s,s.exports,i),s.exports}i.m=r,i.d=(e,t)=>{for(var r in t)i.o(t,r)&&!i.o(e,r)&&Object.defineProperty(e,r,{enumerable:!0,get:t[r]})},i.f={},i.e=e=>Promise.all(Object.keys(i.f).reduce((t,r)=>(i.f[r](e,t),t),[])),i.u=e=>"nr-rum-1.310.1.min.js",i.o=(e,t)=>Object.prototype.hasOwnProperty.call(e,t),e={},t="NRBA-1.310.1.PROD:",i.l=(r,n,s,a)=>{if(e[r])e[r].push(n);else{var o,c;if(void 0!==s)for(var d=document.getElementsByTagName("script"),u=0;u<d.length;u++){var l=d[u];if(l.getAttribute("src")==r||l.getAttribute("data-webpack")==t+s){o=l;break}}if(!o){c=!0;var f={296:"sha512-8LEsRObgfHgVhp/OH+e1LIJ8trYoEGGugVcM4cNSUs2rZ3CNt/VHMq+3wUpYKaA5/dW4oR9cdBp7CsljXO+9fA=="};(o=document.createElement("script")).charset="utf-8",i.nc&&o.setAttribute("nonce",i.nc),o.setAttribute("data-webpack",t+s),o.src=r,0!==o.src.indexOf(window.location.origin+"/")&&(o.crossOrigin="anonymous"),f[a]&&(o.integrity=f[a])}e[r]=[n];var g=(t,n)=>{o.onerror=o.onload=null,clearTimeout(p);var i=e[r];if(delete e[r],o.parentNode&&o.parentNode.removeChild(o),i&&i.forEach(e=>e(n)),t)return t(n)},p=setTimeout(g.bind(null,void 0,{type:"timeout",target:o}),12e4);o.onerror=g.bind(null,o.onerror),o.onload=g.bind(null,o.onload),c&&document.head.appendChild(o)}},i.r=e=>{"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},i.p="https://js-agent.newrelic.com/",(()=>{var e={374:0,840:0};i.f.j=(t,r)=>{var n=i.o(e,t)?e[t]:void 0;if(0!==n)if(n)r.push(n[2]);else{var s=new Promise((r,i)=>n=e[t]=[r,i]);r.push(n[2]=s);var a=i.p+i.u(t),o=new Error;i.l(a,r=>{if(i.o(e,t)&&(0!==(n=e[t])&&(e[t]=void 0),n)){var s=r&&("load"===r.type?"missing":r.type),a=r&&r.target&&r.target.src;o.message="Loading chunk "+t+" failed: ("+s+": "+a+")",o.name="ChunkLoadError",o.type=s,o.request=a,n[1](o)}},"chunk-"+t,t)}};var t=(t,r)=>{var n,s,[a,o,c]=r,d=0;if(a.some(t=>0!==e[t])){for(n in o)i.o(o,n)&&(i.m[n]=o[n]);if(c)c(i)}for(t&&t(r);d<a.length;d++)s=a[d],i.o(e,s)&&e[s]&&e[s][0](),e[s]=0},r=self["webpackChunk:NRBA-1.310.1.PROD"]=self["webpackChunk:NRBA-1.310.1.PROD"]||[];r.forEach(t.bind(null,0)),r.push=t.bind(null,r.push.bind(r))})(),(()=>{"use strict";i(8374);var e=i(8362),t=i(860);const r=Object.values(t.K7);var n=i(163);var s=i(9908),a=i(1863),o=i(4261),c=i(1738);var d=i(1687),u=i(4234),l=i(5289),f=i(6154),g=i(944),p=i(384);const h=e=>f.RI&&!0===e?.privacy.cookies_enabled;function m(e){return!!(0,p.dV)().o.MO&&h(e)&&!0===e?.session_trace.enabled}var v=i(6389),b=i(7699);class y extends u.W{constructor(e,t){super(e.agentIdentifier,t),this.agentRef=e,this.abortHandler=void 0,this.featAggregate=void 0,this.loadedSuccessfully=void 0,this.onAggregateImported=new Promise(e=>{this.loadedSuccessfully=e}),this.deferred=Promise.resolve(),!1===e.init[this.featureName].autoStart?this.deferred=new Promise((t,r)=>{this.ee.on("manual-start-all",(0,v.J)(()=>{(0,d.Ak)(e.agentIdentifier,this.featureName),t()}))}):(0,d.Ak)(e.agentIdentifier,t)}importAggregator(e,t,r={}){if(this.featAggregate)return;const n=async()=>{let n;await this.deferred;try{if(h(e.init)){const{setupAgentSession:t}=await i.e(296).then(i.bind(i,3305));n=t(e)}}catch(e){(0,g.R)(20,e),this.ee.emit("internal-error",[e]),(0,s.p)(b.qh,[e],void 0,this.featureName,this.ee)}try{if(!this.#t(this.featureName,n,e.init))return(0,d.Ze)(this.agentIdentifier,this.featureName),void this.loadedSuccessfully(!1);const{Aggregate:i}=await t();this.featAggregate=new i(e,r),e.runtime.harvester.initializedAggregates.push(this.featAggregate),this.loadedSuccessfully(!0)}catch(e){(0,g.R)(34,e),this.abortHandler?.(),(0,d.Ze)(this.agentIdentifier,this.featureName,!0),this.loadedSuccessfully(!1),this.ee&&this.ee.abort()}};f.RI?(0,l.GG)(()=>n(),!0):n()}#t(e,r,n){if(this.blocked)return!1;switch(e){case t.K7.sessionReplay:return m(n)&&!!r;case t.K7.sessionTrace:return!!r;default:return!0}}}var _=i(6630),w=i(2614),x=i(3241);class k extends y{static featureName=_.T;constructor(e){var t;super(e,_.T),this.setupInspectionEvents(e.agentIdentifier),t=e,(0,c.Y)(o.Fw,function(e,r){"string"==typeof e&&("/"!==e.charAt(0)&&(e="/"+e),t.runtime.customTransaction=(r||"http://custom.transaction")+e,(0,s.p)(o.Pl+o.Fw,[(0,a.t)()],void 0,void 0,t.ee))},t),this.importAggregator(e,()=>i.e(296).then(i.bind(i,3943)))}setupInspectionEvents(e){const t=(t,r)=>{t&&(0,x.W)({agentIdentifier:e,timeStamp:t.timeStamp,loaded:"complete"===t.target.readyState,type:"window",name:r,data:t.target.location+""})};(0,l.sB)(e=>{t(e,"DOMContentLoaded")}),(0,l.GG)(e=>{t(e,"load")}),(0,l.Qr)(e=>{t(e,"navigate")}),this.ee.on(w.tS.UPDATE,(t,r)=>{(0,x.W)({agentIdentifier:e,type:"lifecycle",name:"session",data:r})})}}class R extends e.d{constructor(e){var t;(super(),f.gm)?(this.features={},(0,p.bQ)(this.agentIdentifier,this),this.desiredFeatures=new Set(e.features||[]),this.desiredFeatures.add(k),(0,n.j)(this,e,e.loaderType||"agent"),t=this,(0,c.Y)(o.cD,function(e,r,n=!1){if("string"==typeof e){if(["string","number","boolean"].includes(typeof r)||null===r)return(0,c.U)(t,e,r,o.cD,n);(0,g.R)(40,typeof r)}else(0,g.R)(39,typeof e)},t),function(e){(0,c.Y)(o.Dl,function(t,r=!1){if("string"!=typeof t&&null!==t)return void(0,g.R)(41,typeof t);const n=e.info.jsAttributes["enduser.id"];r&&null!=n&&n!==t?(0,s.p)(o.Pl+"setUserIdAndResetSession",[t],void 0,"session",e.ee):(0,c.U)(e,"enduser.id",t,o.Dl,!0)},e)}(this),function(e){(0,c.Y)(o.nb,function(t){if("string"==typeof t||null===t)return(0,c.U)(e,"application.version",t,o.nb,!1);(0,g.R)(42,typeof t)},e)}(this),function(e){(0,c.Y)(o.d3,function(){e.ee.emit("manual-start-all")},e)}(this),function(e){(0,c.Y)(o.Pv,function(t=!0){if("boolean"==typeof t){if((0,s.p)(o.Pl+o.Pv,[t],void 0,"session",e.ee),e.runtime.consented=t,t){const t=e.features.page_view_event;t.onAggregateImported.then(e=>{const r=t.featAggregate;e&&!r.sentRum&&r.sendRum()})}}else(0,g.R)(65,typeof t)},e)}(this),this.run()):(0,g.R)(21)}get config(){return{info:this.info,init:this.init,loader_config:this.loader_config,runtime:this.runtime}}get api(){return this}run(){try{const e=function(e){const t={};return r.forEach(r=>{t[r]=!!e[r]?.enabled}),t}(this.init),n=[...this.desiredFeatures];n.sort((e,r)=>t.P3[e.featureName]-t.P3[r.featureName]),n.forEach(r=>{if(!e[r.featureName]&&r.featureName!==t.K7.pageViewEvent)return;const n=function(e){switch(e){case t.K7.ajax:return[t.K7.jserrors];case t.K7.sessionTrace:return[t.K7.ajax,t.K7.pageViewEvent];case t.K7.sessionReplay:return[t.K7.sessionTrace];case t.K7.pageViewTiming:return[t.K7.pageViewEvent];default:return[]}}(r.featureName).filter(e=>!(e in this.features));n.length>0&&(0,g.R)(36,{targetFeature:r.featureName,missingDependencies:n}),this.features[r.featureName]=new r(this)})}catch(e){(0,g.R)(22,e);for(const e in this.features)this.features[e].abortHandler?.();const t=(0,p.Zm)();delete t.initializedAgents[this.agentIdentifier]?.features,delete this.sharedAggregator;return t.ee.get(this.agentIdentifier).abort(),!1}}}var A=i(2843),S=i(782);class T extends y{static featureName=S.T;constructor(e){super(e,S.T),f.RI&&((0,A.u)(()=>(0,s.p)("docHidden",[(0,a.t)()],void 0,S.T,this.ee),!0),(0,A.G)(()=>(0,s.p)("winPagehide",[(0,a.t)()],void 0,S.T,this.ee)),this.importAggregator(e,()=>i.e(296).then(i.bind(i,2117))))}}var E=i(3969);class j extends y{static featureName=E.TZ;constructor(e){super(e,E.TZ),f.RI&&document.addEventListener("securitypolicyviolation",e=>{(0,s.p)(E.xV,["Generic/CSPViolation/Detected"],void 0,this.featureName,this.ee)}),this.importAggregator(e,()=>i.e(296).then(i.bind(i,9623)))}}new R({features:[k,T,j],loaderType:"lite"})})()})();</script>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="shortcut icon" href="https://developer-blogs.nvidia.com/wp-content/themes/nvidia/dist/images/favicon_300a1064.ico" type="image/vnd.microsoft.icon">
  <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Organization",
  "name": "NVIDIA Developer",
  "url": "https://developer.nvidia.com",
  "logo": "https://www.nvidia.com/en-us/about-nvidia/legal-info/logo-brand-usage/_jcr_content/root/responsivegrid/nv_container_392921705/nv_container_412055486/nv_image.coreimg.100.630.png/1703060329095/nvidia-logo-horz.png",
  "sameAs": [
    "https://github.com/nvidia",
    "https://www.linkedin.com/company/nvidia/",
    "https://x.com/nvidiadeveloper"
  ]
}
</script>
  <link media="all" href="https://developer-blogs.nvidia.com/wp-content/uploads/autoptimize/1/css/aggregated_8292c258e89720f385ed585756aa25e7.css" rel="stylesheet"><title>Scaling Language Model Training to a Trillion Parameters Using Megatron | NVIDIA Technical Blog</title>
	
	<!-- OneTrust Cookies Consent Notice start for nvidia.com -->
<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="3e2b62ff-7ae7-4ac5-87c8-d5949ecafff5" ></script>
<script type="text/javascript">
function OptanonWrapper() {        
        var event = new Event('bannerLoaded');
        window.dispatchEvent(event);
    }
</script>
<!-- OneTrust Cookies Consent Notice end for nvidia.com --><link rel="preload" href="https://developer-blogs.nvidia.com/wp-content/themes/nvidia/dist/scripts/main_0e427d4f.js" as="script"><script src="//app-sj14.marketo.com/js/forms2/js/forms2.min.js?ver=5.6.2" defer></script>
<!-- The SEO Framework by Sybre Waaijer -->
<meta name="robots" content="max-snippet:-1,max-image-preview:standard,max-video-preview:-1" />
<link rel="canonical" href="https://developer.nvidia.com/blog/scaling-language-model-training-to-a-trillion-parameters-using-megatron/" />
<link rel="shortlink" href="https://developer.nvidia.com/blog/?p=24760" />
<meta name="description" content="Natural Language Processing (NLP) has seen rapid progress in recent years as computation at scale has become more available and datasets have become larger." />
<meta property="og:type" content="article" />
<meta property="og:locale" content="en_US" />
<meta property="og:site_name" content="NVIDIA Technical Blog" />
<meta property="og:title" content="Scaling Language Model Training to a Trillion Parameters Using Megatron | NVIDIA Technical Blog" />
<meta property="og:description" content="Natural Language Processing (NLP) has seen rapid progress in recent years as computation at scale has become more available and datasets have become larger. At the same time, recent work has shown&#8230;" />
<meta property="og:url" content="https://developer.nvidia.com/blog/scaling-language-model-training-to-a-trillion-parameters-using-megatron/" />
<meta property="og:image" content="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Achieved_petaFLOPs.png" />
<meta property="og:image:width" content="2002" />
<meta property="og:image:height" content="1100" />
<meta property="article:published_time" content="2021-04-12T17:00:00+00:00" />
<meta property="article:modified_time" content="2023-03-22T01:12:02+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:title" content="Scaling Language Model Training to a Trillion Parameters Using Megatron | NVIDIA Technical Blog" />
<meta name="twitter:description" content="Natural Language Processing (NLP) has seen rapid progress in recent years as computation at scale has become more available and datasets have become larger. At the same time, recent work has shown&#8230;" />
<meta name="twitter:image" content="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Achieved_petaFLOPs.png" />
<script type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://developer.nvidia.com/blog/#/schema/WebSite","url":"https://developer.nvidia.com/blog/","name":"NVIDIA Technical Blog","description":"News and tutorials for developers, data scientists, and IT admins","inLanguage":"en-US","potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://developer.nvidia.com/blog/search/{search_term_string}/"},"query-input":"required name=search_term_string"},"publisher":{"@type":"Organization","@id":"https://developer.nvidia.com/blog/#/schema/Organization","name":"NVIDIA Technical Blog","url":"https://developer.nvidia.com/blog/","logo":{"@type":"ImageObject","url":"https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/nvidia_news_logo.png","contentUrl":"https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/nvidia_news_logo.png","width":1000,"height":1000,"inLanguage":"en-US","caption":"NVIDIA News","contentSize":"95193"}}},{"@type":"WebPage","@id":"https://developer.nvidia.com/blog/scaling-language-model-training-to-a-trillion-parameters-using-megatron/","url":"https://developer.nvidia.com/blog/scaling-language-model-training-to-a-trillion-parameters-using-megatron/","name":"Scaling Language Model Training to a Trillion Parameters Using Megatron | NVIDIA Technical Blog","description":"Natural Language Processing (NLP) has seen rapid progress in recent years as computation at scale has become more available and datasets have become larger.","inLanguage":"en-US","isPartOf":{"@id":"https://developer.nvidia.com/blog/#/schema/WebSite"},"breadcrumb":{"@type":"BreadcrumbList","@id":"https://developer.nvidia.com/blog/#/schema/BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":"https://developer.nvidia.com/blog/","name":"NVIDIA Technical Blog"},{"@type":"ListItem","position":2,"item":"https://developer.nvidia.com/blog/category/data-center-cloud/","name":"Category: Data Center / Cloud"},{"@type":"ListItem","position":3,"name":"Scaling Language Model Training to a Trillion Parameters Using Megatron"}]},"potentialAction":{"@type":"ReadAction","target":"https://developer.nvidia.com/blog/scaling-language-model-training-to-a-trillion-parameters-using-megatron/"},"datePublished":"2021-04-12T17:00:00+00:00","dateModified":"2023-03-22T01:12:02+00:00","author":{"@type":"Person","@id":"https://developer.nvidia.com/blog/#/schema/Person/438fd3473538da328df97701c8074e49","name":"Deepak Narayanan","description":"Deepak Narayanan is a senior applied deep learning research scientist in the ADLR group at NVIDIA, where he looks at making the training and inference of LLMs faster and more reliable. He holds a PhD in Computer Science from Stanford University."}}]}</script>
<script type="application/ld+json">{"@context":"https://schema.org","@type":"NewsArticle","mainEntityOfPage":{"@type":"WebPage","@id":"https://developer.nvidia.com/blog/scaling-language-model-training-to-a-trillion-parameters-using-megatron/"},"headline":"Scaling Language Model Training to a Trillion Parameters Using Megatron","image":{"@type":"ImageObject","url":"https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Achieved_petaFLOPs.png","width":2002,"height":1100},"datePublished":"2021-04-12T17:00:00+00:00","dateModified":"2023-03-22T01:12:02+00:00","author":{"@type":"Person","name":"Deepak Narayanan","url":"https://developer.nvidia.com/blog/author/dnarayanan/"},"publisher":{"@type":"Organization","name":"NVIDIA Technical Blog","logo":{"@type":"ImageObject","url":"https://developer-blogs.nvidia.com/wp-content/uploads/2020/08/nvidia-logo-77x60.png","width":77,"height":60}},"description":"Natural Language Processing (NLP) has seen rapid progress in recent years as computation at scale has become more available and datasets have become larger."}</script>
<!-- / The SEO Framework by Sybre Waaijer | 19.58ms meta | 0.42ms boot -->

<link rel='dns-prefetch' href='//secure.gravatar.com' />
<link rel='dns-prefetch' href='//widgets.wp.com' />
<link rel='dns-prefetch' href='//s0.wp.com' />
<link rel='dns-prefetch' href='//0.gravatar.com' />
<link rel='dns-prefetch' href='//1.gravatar.com' />
<link rel='dns-prefetch' href='//2.gravatar.com' />
<link rel='dns-prefetch' href='//v0.wordpress.com' />
<link href='https://assets.adobedtm.com' rel='preconnect' />
<link href='https://cdn.cookielaw.org' rel='preconnect' />
<link href='https://munchkin.marketo.net' rel='preconnect' />
<link href='https://nvidia.tt.omtrdc.net' rel='preconnect' />
<link href='https://unpkg.com' rel='preconnect' />
<link href='https://j.6sc.co' rel='preconnect' />
<link href='https://ipv6.6sc.co' rel='preconnect' />
<link href='https://156-ofn-742.mktoresp.com' rel='preconnect' />
<link href='https://cdnjs.cloudflare.com' rel='preconnect' />
<link href='https://d29g4g2dyqv443.cloudfront.net' rel='preconnect' />
<link rel="alternate" type="application/atom+xml" title="NVIDIA Technical Blog &raquo; Scaling Language Model Training to a Trillion Parameters Using Megatron Comments Feed" href="https://developer.nvidia.com/blog/scaling-language-model-training-to-a-trillion-parameters-using-megatron/feed/" />













<script type="text/javascript" src="https://developer-blogs.nvidia.com/wp-includes/js/jquery/jquery.min.js?ver=3.7.1" id="jquery-core-js"></script>
<script type="text/javascript" src="https://developer-blogs.nvidia.com/wp-content/themes/nvidia/resources/assets/scripts/munchkin.js?ver=1771711330" id="munchkin-js-js"></script>
<script type="text/javascript" src="https://developer-blogs.nvidia.com/wp-content/themes/nvidia/resources/assets/scripts/user-dropdown.js?ver=1771711330" id="user_dropdown.js-js"></script>
<link rel="https://api.w.org/" href="https://developer-blogs.nvidia.com/wp-json/" /><link rel="alternate" title="JSON" type="application/json" href="https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/24760" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://developer-blogs.nvidia.com/xmlrpc.php?rsd" />
<link rel="alternate" title="oEmbed (JSON)" type="application/json+oembed" href="https://developer-blogs.nvidia.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fdeveloper.nvidia.com%2Fblog%2Fscaling-language-model-training-to-a-trillion-parameters-using-megatron%2F" />
<link rel="alternate" title="oEmbed (XML)" type="text/xml+oembed" href="https://developer-blogs.nvidia.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fdeveloper.nvidia.com%2Fblog%2Fscaling-language-model-training-to-a-trillion-parameters-using-megatron%2F&#038;format=xml" />
<link rel="alternate" hreflang="x-default" href="https://developer.nvidia.com/blog/scaling-language-model-training-to-a-trillion-parameters-using-megatron/" title="en_US" />
<!-- Stream WordPress user activity plugin v4.1.1 -->
<meta name="generator" content="webp-uploads 2.5.1">

	<!--wp code prettify-->  <script src="//assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js" data-ot-ignore="true"></script>
  <link rel="stylesheet" href="https://pro.fontawesome.com/releases/v5.12.1/css/all.css" integrity="sha384-TxKWSXbsweFt0o2WqfkfJRRNVaPdzXJ/YLqgStggBVRREXkwU7OKz+xXtqOU4u8+" crossorigin="anonymous" media="none" onload="if(media!='all')media='all'">
    </head>
  <body class="wp-singular post-template-default single single-post postid-24760 single-format-standard wp-theme-nvidiaresources metaslider-plugin scaling-language-model-training-to-a-trillion-parameters-using-megatron app-data index-data singular-data single-data single-post-data single-post-scaling-language-model-training-to-a-trillion-parameters-using-megatron-data">
            <svg xmlns="http://www.w3.org/2000/svg" class="hide" style="display: none;">
  <symbol id="n24-user-circle" viewBox="0 0 24 24">
    <defs>
      
    </defs>
    <rect id="n24-icon-user-circle-bounds" class="n24-bounds" width="24" height="24"></rect>
    <g id="n24-icon-user-circle">
      <circle id="user-circle" class="n24-user-circle-cls-1" cx="12" cy="12" r="9.75"></circle>
      <polyline id="user-body" class="n24-user-circle-cls-1" points="17.55 20.01 16.34 15.48 7.66 15.48 6.45 20.01"></polyline>
      <circle id="user-head" class="n24-user-circle-cls-1" cx="12" cy="9.91" r="3.48"></circle>
    </g>
  </symbol>
</svg>

  <header class="page-header">
    <div class="container">
      <button class="navbar-toggle" type="button">
  <span class="icon-bar"></span>
  <span class="icon-bar"></span>
  <span class="icon-bar"></span>
</button>
      <div class="logo">
  <a class="primary-logo" href="/" title="Home" data-wpel-link="internal">
    <noscript><img alt="Home" width="142" height="32" src="https://developer-blogs.nvidia.com/wp-content/themes/nvidia/dist/images/nvidia-logo_28b633c7.svg"></noscript><img class="lazyload" alt="Home" width="142" height="32" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20142%2032%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/themes/nvidia/dist/images/nvidia-logo_28b633c7.svg">
  </a>
  <a class="secondary-logo" href="/" title="Home" data-wpel-link="internal">DEVELOPER</a>
</div>
      <nav class="navbar primary navbar-expand-md navbar-inverse">
  <div class="collapse navbar-collapse" id="navbarSupportedContent">
          <div class="menu-top-menu-container"><ul id="menu-top-menu" class="menu nav navbar-nav primary mr-auto"><li id="menu-item-25291" class="menu-item menu-item-type-custom menu-item-object-custom nav-item nav-item-25291"><a title="Home" href="/" class="nav-link" data-wpel-link="internal">Home</a></li><li id="menu-item-25292" class="menu-item menu-item-type-custom menu-item-object-custom nav-item nav-item-25292"><a title="Blog" href="/blog" class="nav-link active" data-wpel-link="internal">Blog</a></li><li id="menu-item-25293" class="menu-item menu-item-type-custom menu-item-object-custom nav-item nav-item-25293"><a title="Forums" href="https://forums.developer.nvidia.com/" class="nav-link" data-wpel-link="internal">Forums</a></li><li id="menu-item-25294" class="menu-item menu-item-type-custom menu-item-object-custom nav-item nav-item-25294"><a title="Docs" href="https://docs.nvidia.com/" class="nav-link" data-wpel-link="internal">Docs</a></li><li id="menu-item-25295" class="menu-item menu-item-type-custom menu-item-object-custom nav-item nav-item-25295"><a title="Downloads" href="https://developer.nvidia.com/downloads" class="nav-link" data-wpel-link="internal">Downloads</a></li><li id="menu-item-25296" class="menu-item menu-item-type-custom menu-item-object-custom nav-item nav-item-25296"><a title="Training" href="https://www.nvidia.com/en-us/training/" class="nav-link" data-wpel-link="internal">Training</a></li></ul></div>
      </div>
</nav>
      <nav class="navbar navbar-right" id="topRightNavbar">
  <ul class="nav navbar-nav navbar-margin navbar-right navbar-margin-media login-nav">
    <li class="search" id="search-top">
      <div class="search-form" id="search-top-form">
        <form id="nvidia-site-search-form" class="gss form-search content-search" action="https://developer.nvidia.com/search">
  <div class="input-group">
    <div id="top-site-search-form">
      <input
        class="form-control form-text"
        placeholder="Search"
        type="text"
        id="edit-term"
        name="q"
        value=""
        size="15"
        maxlength="128">
      <input type="hidden" name="page" value="1">
    </div>
    <span class="input-group-btn">
        <button type="submit" class="btn btn-default">
          <i class="fa fa-search" aria-hidden="true"></i>
        </button>
      </span>
  </div>
</form>
          </div>
    </li>
        <li class="leaf" id="dzauth_join_link">
      <a href="https://developer.nvidia.com/login" class="cta--prim nv-join" data-wpel-link="internal">
        Join
      </a>
    </li>
    <li class="leaf last" id="dzauth_login_link">
      <a href="https://developer.nvidia.com/login" class="nv-login" data-wpel-link="internal">
        <svg aria-label="User Account" class="n24-icon nvprofileicon n24-account" width="24px" height="24px">
          <use xlink:href="#n24-user-circle"></use>
        </svg>
      </a>
    </li>
      </ul>
</nav>
    </div>
  </header>
    <section class="main">
      <div class="faceted-search-top-wrapper">
        <div class="container">
          <div class="row">
            <div class="col col-lg-12 faceted-search-component-wrapper">
              <div class="librarian-search-bar">
    <div class="librarian-search-bar__header">
        <div class="librarian-search-bar__sitename">
            <a href="https://developer.nvidia.com/blog" data-wpel-link="internal">Technical Blog</a>
        </div>
        <div class="librarian-search-bar__input">
            <div class="glass">
    <svg width="13" height="13" viewBox="0 0 13 13" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path
            d="M12.0001 12.0001L7.32849 7.32842M8.5 4.5C8.5 6.70914 6.70914 8.5 4.5 8.5C2.29086 8.5 0.5 6.70914 0.5 4.5C0.5 2.29086 2.29086 0.5 4.5 0.5C6.70914 0.5 8.5 2.29086 8.5 4.5Z"
            stroke="black">
        </path>
    </svg>
</div>
            <form action="https://developer.nvidia.com/search" method="GET">
    <input type="text" placeholder="Search blog" name="q" value="">
    <input type="hidden" name="page" value="1">
    <input type="hidden" name="filters" value="techblogs">
</form>
        </div>
    </div>
    <div class="librarian-search-bar__subscribe">
        <a href="https://developer.nvidia.com/email-signup" data-wpel-link="internal">
            Subscribe
            <svg width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 612">
    <path
        d="M305 239c9.4 9.4 9.4 24.6 0 33.9L113 465c-9.4 9.4-24.6 9.4-33.9 0s-9.4-24.6 0-33.9l175-175L79 81c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0L305 239z">
    </path>
</svg>
        </a>
    </div>
</div>

            </div>
          </div>
        </div>
      </div>

              <div class="search-filters-component-wrapper--inner-page position-fixed w-100">
          <div class="container">
            <div class="row">
              <faceted-search-filters endpoint="https://developer.nvidia.com/blog/wp-json/faceted-search/v1/select/" redirectUrl="https://developer.nvidia.com/blog/search-posts/" data-expanded="false" data-with-redirect="true" data-with-overlay="false" sortBy="post_date" locale="en-US" handleURls=""></faceted-search-filters>
            </div>
          </div>
        </div>
        <div class="container single-page">
          <div id="main-content" class="row">
                       <script>
  sessionStorage.removeItem('facets.search.text');
  sessionStorage.removeItem('facets.search.text-copy');
  sessionStorage.removeItem('facets.search.filters');
</script>
      <div class="col-sm-12 d-none text-right sidebar-toggle-link-wrapper">
  <a class="sidebar-toggle sidebar-toggle-link" href="#main-content-end">
    Related Resources <i class="fa fa-angle-right" aria-hidden="true"></i>
  </a>
</div>
<div class="main-content col-lg-9 col-md-9 mt-0 mb-0">
  <div class="post-card--single">
    
    <div class="row">
      <div class="col-lg-12 mb-0">
        <div class="card--post-attributes">
        <span class="category-name content-s">
                    <a href="" data-wpel-link="internal">AI / Deep Learning</a>
        </span>

          
          <span class="post-rate-widget content-s"></span>
          <span class="post-lang-switcher">
                        
                    </span>
        </div>

        <h1 class="h--large txt-clr--blck mt-2 mb-0">Scaling Language Model Training to a Trillion Parameters Using Megatron</h1>

        
        <img width="1024" height="563" src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Achieved_petaFLOPs-1024x563.png" class="attachment-full-page-width size-full-page-width wp-post-image" alt="" decoding="async" fetchpriority="high" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Achieved_petaFLOPs-1024x563.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Achieved_petaFLOPs-300x165.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Achieved_petaFLOPs-625x343.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Achieved_petaFLOPs-179x98.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Achieved_petaFLOPs-768x422.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Achieved_petaFLOPs-1536x844.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Achieved_petaFLOPs-500x275.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Achieved_petaFLOPs-160x88.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Achieved_petaFLOPs-362x199.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Achieved_petaFLOPs-200x110.png 200w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Achieved_petaFLOPs.png 2002w" sizes="(max-width: 1024px) 100vw, 1024px" />
        <div class="post-info">
          <div class="post-published-date">
            Apr 12, 2021
          </div>

          <div class="post-authors">
            By <a href="https://developer.nvidia.com/blog/author/dnarayanan/" title="Posts by Deepak Narayanan" class="author url fn" rel="author" data-wpel-link="internal">Deepak Narayanan</a>, <a href="https://developer.nvidia.com/blog/author/mshoeybi/" title="Posts by Mohammad Shoeybi" class="author url fn" rel="author" data-wpel-link="internal">Mohammad Shoeybi</a>, <a href="https://developer.nvidia.com/blog/author/jcasper/" title="Posts by Jared Casper" class="author url fn" rel="author" data-wpel-link="internal">Jared Casper</a>, <a href="https://developer.nvidia.com/blog/author/plegresley/" title="Posts by Patrick LeGresley" class="author url fn" rel="author" data-wpel-link="internal">Patrick LeGresley</a>, <a href="https://developer.nvidia.com/blog/author/mpatwary/" title="Posts by Mostofa Patwary" class="author url fn" rel="author" data-wpel-link="internal">Mostofa Patwary</a>, <a href="https://developer.nvidia.com/blog/author/vkorthikanti/" title="Posts by Vijay Korthikanti" class="author url fn" rel="author" data-wpel-link="internal">Vijay Korthikanti</a>, <a href="https://developer.nvidia.com/blog/author/dvainbrand/" title="Posts by Dmitri Vainbrand" class="author url fn" rel="author" data-wpel-link="internal">Dmitri Vainbrand</a> and <a href="https://developer.nvidia.com/blog/author/bcatanzaro/" title="Posts by Bryan Catanzaro" class="author url fn" rel="author" data-wpel-link="internal">Bryan Catanzaro</a>          </div>

          <div class="card--post-attributes-secondary card--post-attributes-header">
            <div class="post--rate secondary--attribute">
              		<div class="wpulike wpulike-heart " ><div class="wp_ulike_general_class wp_ulike_is_not_liked"><button type="button"
					aria-label="Like Button"
					data-ulike-id="24760"
					data-ulike-nonce="6045284b9c"
					data-ulike-type="post"
					data-ulike-template="wpulike-heart"
					data-ulike-display-likers=""
					data-ulike-likers-style="popover"
					class="wp_ulike_btn wp_ulike_put_text wp_post_btn_24760"><span><i class="far fa-thumbs-up"></i></span>				</button><span class="count-box wp_ulike_counter_up" data-ulike-counter-value="+10"></span>			</div></div>
	
              <span class="js-like-click like-click">
                Like              </span>
            </div>

                                      <div class="post--comments-count secondary--attribute">
                <a href="#entry-content-comments">
                  <i class="fad fa-comment-alt-lines"></i> Discuss (1)
                </a>
              </div>
                      </div>
        </div>

      </div>
    </div>
  </div>
</div>
<div class="col-lg-3 col-md-3 mt-0 mb-0"></div>

<div class="main-content col-lg-9 col-md-9 mt-0">
  <div class="entry-meta-social">
    <ul class="entry-meta-social-links-list">
                     <li><a data-wpel-link="external" href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fdeveloper.nvidia.com%2Fblog%2Fscaling-language-model-training-to-a-trillion-parameters-using-megatron%2F" class="for-linkedin" target="_blank" rel="follow">L</a></li>
			         <li><a data-wpel-link="external" href="https://twitter.com/intent/tweet?text=Scaling+Language+Model+Training+to+a+Trillion+Parameters+Using+Megatron+%7C+NVIDIA+Technical+Blog+https%3A%2F%2Fdeveloper.nvidia.com%2Fblog%2Fscaling-language-model-training-to-a-trillion-parameters-using-megatron%2F" class="for-twitter" target="_blank" rel="follow">T</a></li>
			         <li><a data-wpel-link="external" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fdeveloper.nvidia.com%2Fblog%2Fscaling-language-model-training-to-a-trillion-parameters-using-megatron%2F" class="for-facebook" target="_blank" rel="follow">F</a></li>
                     <li><a data-wpel-link="external" href="https://www.reddit.com/submit?url=https%3A%2F%2Fdeveloper.nvidia.com%2Fblog%2Fscaling-language-model-training-to-a-trillion-parameters-using-megatron%2F&amp;title=Scaling+Language+Model+Training+to+a+Trillion+Parameters+Using+Megatron+%7C+NVIDIA+Technical+Blog" class="for-reddit" target="_blank" rel="follow">R</a></li>
			         <li><a href="mailto:?subject=I'd like to share a link with you&body=https%3A%2F%2Fdeveloper.nvidia.com%2Fblog%2Fscaling-language-model-training-to-a-trillion-parameters-using-megatron%2F" class="for-mail">E</a></li>
			       </ul>  </div>

      <div id="genai-summary" class="collapsed">
    <div class="genai-summary-title">
      <p class="genai-summary-title-content">
        <span>
          <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" viewBox="0 0 25 25" fill="none">
            <path fill-rule="evenodd" clip-rule="evenodd" d="M22.4915 15.3019C22.294 15.3047 22.0976 15.3316 21.9066 15.3819L20.254 12.9019L21.905 10.4219C22.0967 10.4731 22.2933 10.4987 22.4915 10.5019C22.8844 10.5032 23.2716 10.4078 23.619 10.2241C23.9665 10.0404 24.2635 9.77405 24.4839 9.44845C24.7044 9.12285 24.8415 8.74799 24.8832 8.35687C24.925 7.96575 24.8701 7.57035 24.7233 7.20547C24.5766 6.84059 24.3425 6.51741 24.0417 6.26437C23.7409 6.01134 23.3825 5.8362 22.9982 5.75437C22.6139 5.67255 22.2154 5.68654 21.8378 5.79512C21.4601 5.9037 21.1149 6.10354 20.8326 6.37706L15.2709 3.59305C15.2868 3.49705 15.2964 3.39946 15.2996 3.30186C15.2996 2.66534 15.0471 2.05489 14.5975 1.6048C14.1479 1.15471 13.5381 0.901855 12.9023 0.901855C12.2665 0.901855 11.6568 1.15471 11.2072 1.6048C10.7576 2.05489 10.5051 2.66534 10.5051 3.30186C10.5083 3.39946 10.5178 3.49705 10.5338 3.59305L4.97211 6.37706C4.68976 6.10267 4.34433 5.90202 3.96626 5.79281C3.58818 5.6836 3.18908 5.66918 2.80412 5.75082C2.41916 5.83245 2.06018 6.00764 1.7588 6.26093C1.45743 6.51423 1.22292 6.83786 1.07595 7.20329C0.928981 7.56872 0.874058 7.96474 0.916028 8.35644C0.957998 8.74813 1.09557 9.12348 1.31662 9.44939C1.53767 9.7753 1.8354 10.0418 2.18358 10.2253C2.53176 10.4088 2.9197 10.5038 3.31319 10.5019C3.51136 10.4987 3.70794 10.4715 3.89813 10.4219L5.55066 12.9019L3.89973 15.3819C3.70818 15.3314 3.51122 15.3046 3.31319 15.3019C2.92029 15.3005 2.53308 15.3959 2.18565 15.5796C1.83822 15.7633 1.54122 16.0297 1.32077 16.3553C1.10032 16.6809 0.963189 17.0557 0.921442 17.4468C0.879695 17.838 0.934613 18.2334 1.08136 18.5982C1.22811 18.9631 1.46219 19.2863 1.76301 19.5393C2.06382 19.7924 2.42215 19.9675 2.80646 20.0493C3.19077 20.1312 3.58928 20.1172 3.96691 20.0086C4.34455 19.9 4.68974 19.7002 4.97211 19.4267L10.5338 22.2107C10.5178 22.3067 10.5083 22.4043 10.5051 22.5019C10.5051 23.1384 10.7576 23.7488 11.2072 24.1989C11.6568 24.649 12.2665 24.9019 12.9023 24.9019C13.5381 24.9019 14.1479 24.649 14.5975 24.1989C15.0471 23.7488 15.2996 23.1384 15.2996 22.5019C15.2958 22.4043 15.2862 22.3071 15.2709 22.2107L20.8326 19.4267C21.1149 19.701 21.4604 19.9017 21.8384 20.0109C22.2165 20.1201 22.6156 20.1345 23.0006 20.0529C23.3855 19.9713 23.7445 19.7961 24.0459 19.5428C24.3473 19.2895 24.5818 18.9659 24.7287 18.6004C24.8757 18.235 24.9306 17.839 24.8887 17.4473C24.8467 17.0556 24.7091 16.6802 24.4881 16.3543C24.267 16.0284 23.9693 15.7619 23.6211 15.5784C23.2729 15.3949 22.885 15.2999 22.4915 15.3019ZM12.8884 2.50274C13.0185 2.50324 13.1465 2.53552 13.2613 2.59679C13.3761 2.65805 13.4742 2.74644 13.5471 2.85429C13.62 2.96214 13.6655 3.08617 13.6797 3.21563C13.6939 3.34509 13.6763 3.47605 13.6284 3.59714L13.606 3.64194C13.5429 3.77981 13.4416 3.89664 13.3141 3.97855C13.1866 4.06045 13.0383 4.10399 12.8868 4.10399C12.7353 4.10399 12.587 4.06045 12.4596 3.97855C12.3321 3.89664 12.2307 3.77981 12.1676 3.64194L12.1453 3.59874C12.097 3.47731 12.0791 3.34589 12.0933 3.21596C12.1074 3.08603 12.1532 2.96156 12.2265 2.85342C12.2998 2.74528 12.3985 2.65678 12.5139 2.59564C12.6293 2.53451 12.7579 2.50261 12.8884 2.50274ZM23.2767 8.10274C23.2767 8.31491 23.1925 8.5184 23.0426 8.66843C22.8928 8.81845 22.6895 8.90274 22.4776 8.90274C22.2656 8.90274 22.0624 8.81845 21.9125 8.66843C21.7627 8.5184 21.6785 8.31491 21.6785 8.10274C21.6785 7.89057 21.7627 7.68708 21.9125 7.53705C22.0624 7.38702 22.2656 7.30274 22.4776 7.30274C22.6895 7.30274 22.8928 7.38702 23.0426 7.53705C23.1925 7.68708 23.2767 7.89057 23.2767 8.10274ZM2.50017 8.10274C2.503 7.92305 2.56617 7.74956 2.67951 7.6102C2.79285 7.47085 2.94976 7.37376 3.12495 7.33458C3.30014 7.2954 3.4834 7.31641 3.6452 7.39423C3.807 7.47205 3.93792 7.60214 4.01685 7.76354L4.03923 7.80834C4.09871 7.95306 4.11376 8.11225 4.08244 8.26558C4.05113 8.4189 3.97488 8.55941 3.86343 8.66914C3.75158 8.78076 3.60921 8.8567 3.45428 8.88737C3.29936 8.91805 3.13883 8.90207 2.99297 8.84147C2.8471 8.78086 2.72245 8.67835 2.63474 8.54687C2.54703 8.41539 2.5002 8.26084 2.50017 8.10274ZM2.50017 17.7027C2.50017 17.4906 2.58436 17.2871 2.73422 17.1371C2.88408 16.987 3.08733 16.9027 3.29927 16.9027C3.5112 16.9027 3.71445 16.987 3.86431 17.1371C4.01417 17.2871 4.09836 17.4906 4.09836 17.7027C4.09836 17.9149 4.01417 18.1184 3.86431 18.2684C3.71445 18.4185 3.5112 18.5027 3.29927 18.5027C3.08733 18.5027 2.88408 18.4185 2.73422 18.2684C2.58436 18.1184 2.50017 17.9149 2.50017 17.7027ZM12.8884 23.3027C12.7566 23.3028 12.6268 23.2702 12.5106 23.2078C12.3944 23.1455 12.2955 23.0553 12.2225 22.9454C12.1496 22.8355 12.1049 22.7092 12.0926 22.5778C12.0802 22.4464 12.1005 22.314 12.1517 22.1923C12.2128 22.0519 12.3129 21.9319 12.4401 21.8468C12.5673 21.7616 12.7163 21.7148 12.8693 21.712C13.0223 21.7091 13.1729 21.7503 13.3032 21.8306C13.4336 21.911 13.5381 22.0271 13.6044 22.1651L13.6268 22.2099C13.6868 22.3541 13.7024 22.5129 13.6716 22.6659C13.6409 22.819 13.5651 22.9594 13.4542 23.0691C13.3798 23.1434 13.2916 23.2022 13.1945 23.2423C13.0974 23.2824 12.9934 23.3029 12.8884 23.3027ZM22.4776 18.5027C22.3267 18.5016 22.1793 18.4577 22.0523 18.3761C21.9253 18.2946 21.824 18.1787 21.76 18.0419L21.7376 17.9971C21.6981 17.9029 21.6777 17.8017 21.6777 17.6995C21.6777 17.5973 21.6981 17.4962 21.7376 17.4019L21.752 17.3747C21.8098 17.2422 21.9023 17.1279 22.0199 17.0438C22.1374 16.9598 22.2755 16.9092 22.4194 16.8974C22.5633 16.8857 22.7078 16.9132 22.8373 16.9771C22.9669 17.0409 23.0768 17.1388 23.1552 17.2601C23.2337 17.3815 23.2778 17.5219 23.283 17.6664C23.2881 17.8109 23.254 17.9541 23.1843 18.0808C23.1146 18.2074 23.012 18.3128 22.8872 18.3857C22.7625 18.4586 22.6204 18.4963 22.476 18.4947L22.4776 18.5027ZM18.0186 9.80834L20.1714 8.73154C20.1554 8.63554 20.1458 8.53794 20.1426 8.44034C20.1458 8.34274 20.1554 8.24514 20.1714 8.14914L15.2841 5.70274L18.0186 9.80834ZM10.6158 5.70434L5.73012 8.14914C5.74545 8.24555 5.75505 8.34279 5.75888 8.44034C5.75569 8.53794 5.7461 8.63554 5.73012 8.73154L7.88288 9.80834L10.6158 5.70434ZM5.73012 17.7491L7.88288 16.6723L10.6174 20.7779L5.73012 18.3315C5.7461 18.2355 5.75569 18.1379 5.75888 18.0403C5.75505 17.9428 5.74545 17.8456 5.73012 17.7491ZM12.2108 13.5363L12.2332 13.5795H12.2364C12.3 13.7175 12.4021 13.8341 12.5303 13.9155C12.6585 13.9968 12.8074 14.0395 12.9592 14.0383C13.1109 14.0371 13.2592 13.9921 13.3861 13.9088C13.513 13.8255 13.6132 13.7072 13.6747 13.5683L13.6891 13.5411C13.7292 13.444 13.7498 13.3398 13.7497 13.2347C13.7496 13.1296 13.7288 13.0255 13.6885 12.9284C13.6482 12.8313 13.5892 12.7431 13.5148 12.6688C13.4405 12.5946 13.3523 12.5357 13.2552 12.4955C13.1581 12.4554 13.0541 12.4348 12.9491 12.4349C12.8441 12.435 12.7401 12.4559 12.6431 12.4962C12.5461 12.5365 12.4581 12.5956 12.3839 12.67C12.3097 12.7444 12.2509 12.8328 12.2108 12.9299C12.1706 13.026 12.1499 13.129 12.1499 13.2331C12.1499 13.3373 12.1706 13.4403 12.2108 13.5363ZM14.6097 14.9715C14.3637 15.2066 14.0706 15.3866 13.7498 15.4995V20.1987L16.5786 15.9571L14.6097 14.9715ZM15.348 13.2403C15.3448 13.3395 15.3353 13.4387 15.3193 13.5379L17.4736 14.6083L18.3846 13.2403L17.472 11.8723L15.3193 12.9491C15.3346 13.0456 15.3442 13.1428 15.348 13.2403ZM13.7498 10.9939C14.0706 11.1069 14.3637 11.2869 14.6097 11.5219L16.5786 10.5299L13.7498 6.28194V10.9939ZM12.1517 10.9875V6.28194L9.32285 10.5299L11.2918 11.5155C11.5378 11.2805 11.8309 11.1005 12.1517 10.9875ZM10.5535 13.2403C10.5567 13.1427 10.5662 13.0451 10.5822 12.9491L8.42787 11.8723L7.5169 13.2403L8.42946 14.6083L10.5822 13.5315C10.5662 13.4355 10.5567 13.3379 10.5535 13.2403ZM12.1517 15.4931C11.8309 15.3802 11.5378 15.2002 11.2918 14.9651L9.32285 15.9507L12.1517 20.1987V15.4931ZM20.1714 17.7491L18.0186 16.6723L15.2841 20.7779L20.1714 18.3315C20.1554 18.2355 20.1458 18.1379 20.1426 18.0403C20.1458 17.9427 20.1554 17.8451 20.1714 17.7491ZM18.912 15.3299L20.2049 15.9779L19.3435 14.6803L18.912 15.3299ZM20.2049 10.5027L18.912 11.1507L19.3435 11.8003L20.2049 10.5027ZM6.98949 11.1443L5.69656 10.5043L6.55798 11.8003L6.98949 11.1443ZM5.69656 15.9779L6.98949 15.3299L6.55798 14.6803L5.69656 15.9779Z" fill="#cccccc"></path>
          </svg>
        </span>
        <span style="padding-left:10px; font-weight: bold">AI-Generated Summary</span>
      </p>
      <div class="title-content-right">
        <div class="feedback-btn-container">
          <div class="feedback-thumbs-up">
            <div>
              <svg width="21" height="20" viewBox="0 0 21 20" fill="none" xmlns="http://www.w3.org/2000/svg" class="svg-empty">
                <path fill-rule="evenodd" clip-rule="evenodd" d="M10.9928 2.5C10.7975 2.5 10.6172 2.60415 10.5195 2.77322L7.92981 7.25876L7.42969 7.75888V14.353L9.8445 15H15.7209L17.1116 9.81011L16.4926 7.5H10.3652L11.5206 3.18788C11.6136 2.84082 11.3521 2.5 10.9928 2.5ZM6.17969 15V7.5L4.30469 7.5V15L6.17969 15ZM7.06885 6.25L9.43701 2.14822C9.75791 1.5924 10.351 1.25 10.9928 1.25C12.174 1.25 13.0337 2.37044 12.728 3.5114L11.9942 6.25H17.4517L18.4057 9.81011L16.6801 16.25H9.67994L7.42969 15.6471V16.25H3.05469V6.25001L7.06885 6.25Z" fill="#5E5E5E"></path>
              </svg>
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 20" fill="none" class="svg-fill">
                <path d="M5.62502 6.25L2.5 6.25001V16.25H5.62503L5.62502 6.25Z" fill="#5E5E5E"></path>
                <path d="M6.87502 15.6471L9.12525 16.25H16.1254L17.851 9.81011L16.897 6.25H11.4395L12.1733 3.5114C12.479 2.37044 11.6193 1.25 10.4381 1.25C9.79628 1.25 9.20322 1.5924 8.88232 2.14822L6.87502 5.62496L6.87502 15.6471Z" fill="#5E5E5E"></path>
              </svg>
            </div>
            <span class="feedback-thumbsuptext">Like</span>
          </div>
          <div class="feedback-thumbs-down">
            <div>
              <svg width="21" height="20" viewBox="0 0 21 20" fill="none" xmlns="http://www.w3.org/2000/svg" class="svg-empty">
                <path fill-rule="evenodd" clip-rule="evenodd" d="M13.2357 3.75H17.6107V13.75L13.5966 13.75L11.2284 17.8518C10.9075 18.4076 10.3145 18.75 9.67266 18.75C8.49144 18.75 7.6317 17.6296 7.93742 16.4886L8.67123 13.75H3.21369L2.25977 10.1899L3.98533 3.75H10.9855L13.2357 4.35296V3.75ZM14.4857 12.5L16.3607 12.5V5L14.4857 5V12.5ZM13.2357 5.64705V12.2411L12.7356 12.7412L10.1459 17.2268C10.0483 17.3959 9.86788 17.5 9.67266 17.5C9.31335 17.5 9.05183 17.1592 9.14483 16.8121L10.3003 12.5H4.17285L3.55386 10.1899L4.94449 5H10.8209L13.2357 5.64705Z" fill="#5E5E5E"></path>
              </svg>
              <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 20" fill="none" class="svg-fill">
                <path d="M14.3744 13.75L17.4994 13.75V3.75H14.3744L14.3744 13.75Z" fill="#5E5E5E"></path>
                <path d="M13.1244 4.35295L10.8742 3.75H3.874L2.14844 10.1899L3.10237 13.75H8.5599L7.82609 16.4886C7.52037 17.6296 8.38011 18.75 9.56133 18.75C10.2031 18.75 10.7962 18.4076 11.1171 17.8518L13.1244 14.375L13.1244 4.35295Z" fill="#5E5E5E"></path>
              </svg>
            </div>
            <span class="feedback-thumbsdowntext">Dislike</span>
          </div>
        </div>
        <div class="summary-collapse-icon">
          <svg width="14" height="9" viewBox="0 0 14 9" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M12.5742 2L7.44923 7L2.32425 2" stroke="#1a1a1a" stroke-width="2" stroke-linecap="square"></path>
          </svg>
        </div>
      </div>
    </div>
    <div class="genai-summary-container">
      <ul><li>The training of large NLP models is challenging due to memory constraints and high computational requirements, but techniques like tensor and pipeline model parallelism can help.</li><li>By combining tensor model parallelism within a node and pipeline model parallelism across nodes with data parallelism, it&#039;s possible to scale up to models with a trillion parameters on NVIDIA&#039;s Selene supercomputer.</li><li>Using 8-way tensor parallelism and 8-way pipeline parallelism on 1024 A100 GPUs, a GPT-3 model with 175 billion parameters can be trained in just over a month, achieving an end-to-end per GPU throughput of 163 teraFLOPs.</li></ul>
      <div class="genai-summary-disclaimer">
        <p>AI-generated content may summarize information incompletely. Verify important information. <span><a href="https://www.nvidia.com/en-us/agreements/trustworthy-ai/terms/" target="_blank" rel="noopener noreferrer" data-wpel-link="internal">Learn more</a></span></p>
      </div>
    </div>
  </div>
  
  <div class="entry-content">
<p>Natural Language Processing (NLP) has seen rapid progress in recent years as computation at scale has become more available and datasets have become larger. At the same time, <a href="https://arxiv.org/abs/2005.14165" data-wpel-link="exclude">recent work</a> has shown large language models to be effective few-shot learners, with high accuracy on many NLP datasets without additional finetuning. As a result, state-of-the-art NLP models have grown at an exponential rate (Figure 1). Training such models, however, is challenging for two reasons:</p>



<ul class="wp-block-list"><li>It is no longer possible to fit model parameters in the main memory of even the largest GPU.</li><li>Even if the model can be fitted in a single GPU (for example, by swapping parameters between host and device memory), the high number of compute operations required can result in unrealistically long training times without parallelization. For example, training a GPT-3 model with 175 billion parameters would take 36 years on eight V100 GPUs, or seven months with 512 V100 GPUs.</li></ul>



<div class="wp-block-image is-style-default"><figure class="aligncenter size-large"><noscript><img decoding="async" width="625" height="266" src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-625x266.png" alt="Sizes of state-of-the-art NLP models have increased by more than three orders of magnitude from 2018 to 2021." class="wp-image-25379" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-625x266.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-300x128.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-179x76.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-768x326.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-1536x653.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-2048x871.png 2048w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-500x213.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-160x68.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-362x154.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-259x110.png 259w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-1024x435.png 1024w" sizes="(max-width: 625px) 100vw, 625px" /></noscript><img decoding="async" width="625" height="266" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20625%20266%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-625x266.png" alt="Sizes of state-of-the-art NLP models have increased by more than three orders of magnitude from 2018 to 2021." class="lazyload wp-image-25379" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-625x266.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-300x128.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-179x76.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-768x326.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-1536x653.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-2048x871.png 2048w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-500x213.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-160x68.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-362x154.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-259x110.png 259w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/NLP_model_size-1-1024x435.png 1024w" data-sizes="(max-width: 625px) 100vw, 625px" /><figcaption><em>Figure 1. Trend of state-of-the-art NLP model sizes with time.</em></figcaption></figure></div>



<p>In our previous <a href="https://nv-adlr.github.io/MegatronLM" data-wpel-link="external" target="_blank" rel="follow">post on Megatron</a>, we showed how tensor (intralayer) model parallelism can be used to overcome these limitations. Although this approach works well for models of sizes up to 20 billion parameters on <a href="https://www.nvidia.com/en-us/data-center/dgx-a100/" data-wpel-link="internal">DGX A100 servers</a> (with eight A100 GPUs), it breaks down for larger models. Larger models need to be split across multiple DGX A100 servers, which leads to two problems: </p>



<ul class="wp-block-list"><li>The all-reduce communication required for tensor model parallelism needs to go through inter-server links, which are slower than the high-bandwidth <a href="https://www.nvidia.com/en-us/data-center/nvlink/" data-wpel-link="internal">NVLink</a> links available within a DGX A100 server</li><li>A high degree of model parallelism can lead to small GEMMs, potentially decreasing GPU utilization.</li></ul>



<div class="wp-block-image is-style-default"><figure class="aligncenter size-large"><noscript><img decoding="async" width="625" height="172" src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-625x172.png" alt="A model with two transformer layers can be split over 4 GPUs using both tensor and pipeline model parallelism." class="wp-image-25381" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-625x172.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-300x83.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-179x49.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-768x211.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-1536x423.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-500x138.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-160x44.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-362x100.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-400x110.png 400w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-1024x282.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1.png 1914w" sizes="(max-width: 625px) 100vw, 625px" /></noscript><img decoding="async" width="625" height="172" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20625%20172%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-625x172.png" alt="A model with two transformer layers can be split over 4 GPUs using both tensor and pipeline model parallelism." class="lazyload wp-image-25381" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-625x172.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-300x83.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-179x49.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-768x211.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-1536x423.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-500x138.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-160x44.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-362x100.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-400x110.png 400w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1-1024x282.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_MP-1.png 1914w" data-sizes="(max-width: 625px) 100vw, 625px" /><figcaption><em>Figure 2. Model parallelism for model with two transformer layers. Transformer layers are partitioned over pipeline stages (pipeline parallelism); each transformer layer is also split over 2 GPUs using tensor model parallelism.</em></figcaption></figure></div>



<p>To overcome these limitations, we combined tensor model parallelism with pipeline (interlayer) (model) parallelism. Pipeline parallelism was initially used in <a href="https://dl.acm.org/doi/10.1145/3341301.3359646" data-wpel-link="external" target="_blank" rel="follow">PipeDream</a> and <a href="https://arxiv.org/abs/1811.06965" data-wpel-link="exclude">GPipe</a>, and is now also available in systems such as <a href="https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/" data-wpel-link="external" target="_blank" rel="follow">DeepSpeed</a>. We used tensor model parallelism inside a DGX A100 server and pipeline parallelism across DGX A100 servers. Figure 2 shows this combination of tensor and pipeline model parallelism. By combining these two forms of model parallelism with data parallelism, we can scale up to models with a trillion parameters on the NVIDIA <a href="https://www.top500.org/system/179842/" data-wpel-link="external" target="_blank" rel="follow">Selene supercomputer</a> (Figure 3). Models in this post are not trained to convergence. We only performed a few hundred iterations to measure time per iteration.</p>



<p>We saw an aggregate throughput improvement of 114x when moving from a ~1-billion-parameter model on 32 GPUs to a ~1-trillion-parameter model on 3072 A100 GPUs. Using 8-way tensor parallelism and 8-way pipeline parallelism on 1024 A100 GPUs, the GPT-3 model with 175 billion parameters can be trained in just over a month. On a GPT model with a trillion parameters, we achieved an end-to-end per GPU throughput of 163 teraFLOPs (including communication), which is 52% of peak device throughput (312 teraFLOPs), and an aggregate throughput of 502 petaFLOPs on 3072 A100 GPUs.</p>



<div class="wp-block-image is-style-default"><figure class="aligncenter size-large"><noscript><img decoding="async" width="625" height="343" src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-625x343.png" alt="Aggregate achieved throughput increases by more than 100x when moving from a 1.7-billion-parameter model on 32 A100 GPUs, to a 1-trillion-parameter model on 3072 A100 GPUs." class="wp-image-25384" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-625x343.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-300x165.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-179x98.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-768x422.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-1536x844.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-500x275.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-160x88.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-362x199.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-200x110.png 200w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-1024x563.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1.png 2002w" sizes="(max-width: 625px) 100vw, 625px" /></noscript><img decoding="async" width="625" height="343" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20625%20343%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-625x343.png" alt="Aggregate achieved throughput increases by more than 100x when moving from a 1.7-billion-parameter model on 32 A100 GPUs, to a 1-trillion-parameter model on 3072 A100 GPUs." class="lazyload wp-image-25384" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-625x343.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-300x165.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-179x98.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-768x422.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-1536x844.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-500x275.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-160x88.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-362x199.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-200x110.png 200w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1-1024x563.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/petaFLOPS_GPUs-1.png 2002w" data-sizes="(max-width: 625px) 100vw, 625px" /><figcaption><em>Figure 3. Achieved total petaFLOPs as a function of number of GPUs and model size. For model configuration details, see the End-to-End Performance section in this post.</em></figcaption></figure></div>



<p>Our implementation is open source on the <a href="https://github.com/NVIDIA/Megatron-LM" data-wpel-link="external" target="_blank" rel="follow">NVIDIA/Megatron-LM</a> GitHub repository, and we encourage you to check it out! In this post, we describe the techniques that allowed us to achieve these results. For more information, see our paper, <a href="https://arxiv.org/abs/2104.04473" data-wpel-link="exclude">Efficient Large-Scale Language Model Training on GPU Clusters</a>.</p>



<h2 id="pipeline_parallelism"  class="wp-block-heading"><strong>Pipeline parallelism</strong><a href="#pipeline_parallelism" class="heading-anchor-link"><i class="fas fa-link"></i></a></h2>



<p>With pipeline parallelism, the layers of a model are partitioned across multiple devices. When used on repetitive transformer-based models, each device can be assigned an equal number of transformer layers. A batch is split into smaller microbatches; execution is then pipelined across microbatches. To retain vanilla optimizer semantics, we introduce periodic pipeline flushes so that optimizer steps are synchronized across devices. At the start and end of every batch, devices are idle. We call this idle time the <em>pipeline bubble</em> and want to make it as small as possible.</p>



<p>There are several possible ways of scheduling forward and backward microbatches across devices, and each approach offers different tradeoffs between pipeline bubble size, amount of communication, and memory footprint. We discuss two such approaches in this post.</p>



<h3 id="default_schedule"  class="wp-block-heading"><strong>Default schedule</strong><a href="#default_schedule" class="heading-anchor-link"><i class="fas fa-link"></i></a></h3>



<p><a href="https://arxiv.org/abs/1811.06965" data-wpel-link="exclude">GPipe</a> proposes a schedule where the forward passes for all microbatches in a batch are first executed, followed by backward passes for all microbatches. Figure 4 shows a picture of this schedule. This approach has a high memory footprint as it requires stashed intermediate activations (or just input activations for each pipeline stage when using activation recomputation) for all microbatches in a batch. For the large batch sizes that are typically required to amortize away the cost of the pipeline bubble, this schedule is impractical due to its high memory footprint.</p>



<div class="wp-block-image is-style-default"><figure class="aligncenter size-large"><noscript><img decoding="async" width="625" height="185" src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-625x185.png" alt="GPipe first schedules forward passes for all microbatches in a batch, followed by backward passes for all microbatches in a batch between pipeline flushes." class="wp-image-25386" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-625x185.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-300x89.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-179x53.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-768x227.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-1536x454.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-500x148.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-160x47.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-362x107.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-372x110.png 372w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-1024x303.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1.png 1893w" sizes="(max-width: 625px) 100vw, 625px" /></noscript><img decoding="async" width="625" height="185" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20625%20185%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-625x185.png" alt="GPipe first schedules forward passes for all microbatches in a batch, followed by backward passes for all microbatches in a batch between pipeline flushes." class="lazyload wp-image-25386" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-625x185.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-300x89.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-179x53.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-768x227.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-1536x454.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-500x148.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-160x47.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-362x107.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-372x110.png 372w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1-1024x303.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule-1.png 1893w" data-sizes="(max-width: 625px) 100vw, 625px" /><figcaption><em>Figure 4. Pipeline schedule with forward passes (blue) for all microbatches (represented by numbers) followed by backward passes (green). The gray area represents the pipeline bubble time. </em></figcaption></figure></div>



<p>In Figure 4, for simplicity, we assumed that the backward pass takes twice as long as forward pass (<code>wgrad</code>, <code>dgrad</code>). The efficiency of the pipeline schedule is independent of this ratio. Each batch in this example consists of eight microbatches, and the number in each box is a unique identifier given to a microbatch. The optimizer is stepped, and weight parameters updated at the pipeline flush.</p>



<p>Instead, we used the <a href="https://arxiv.org/abs/2006.09503" data-wpel-link="exclude">PipeDream-Flush schedule</a>. In this schedule, workers first enter a warm-up phase (Figure 5). This schedule limits the number of in-flight microbatches (the number of microbatches for which the backward pass is outstanding and activations need to be maintained) to the depth of the pipeline, instead of the number of microbatches in a batch. After the warm-up phase, each worker then enters steady state, where workers perform one forward pass followed by one backward pass (1F1B for short). Finally, at the end of a batch, workers complete backward passes for all remaining in-flight microbatches.</p>



<div class="wp-block-image is-style-default"><figure class="aligncenter size-large"><noscript><img decoding="async" width="625" height="185" src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-625x185.png" alt="With the 1F1B schedule, workers can alternate between performing forward and backward passes for different microbatches in steady state." class="wp-image-25390" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-625x185.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-300x89.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-179x53.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-768x227.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-1536x454.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-500x148.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-160x47.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-362x107.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-372x110.png 372w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-1024x303.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1.png 1893w" sizes="(max-width: 625px) 100vw, 625px" /></noscript><img decoding="async" width="625" height="185" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20625%20185%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-625x185.png" alt="With the 1F1B schedule, workers can alternate between performing forward and backward passes for different microbatches in steady state." class="lazyload wp-image-25390" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-625x185.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-300x89.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-179x53.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-768x227.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-1536x454.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-500x148.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-160x47.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-362x107.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-372x110.png 372w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1-1024x303.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Pipeline_schedule_1F1B-1.png 1893w" data-sizes="(max-width: 625px) 100vw, 625px" /><figcaption><em>Figure 5. Pipeline schedule with 1F1B schedule (initial warm-up followed by a forward plus a backward pass for some microbatch in steady state).</em></figcaption></figure></div>



<p>You can quantify the pipeline bubble size (<noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=t_%7Bpb%7D&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="t_{pb}" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=t_%7Bpb%7D&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="t_{pb}" class="lazyload latex" />). Denote the number of microbatches in a batch as <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=m&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="m" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=m&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="m" class="lazyload latex" />, the number of pipeline stages (equal to the number of devices used for pipeline model parallelism) as <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=p&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="p" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=p&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="p" class="lazyload latex" />, the ideal time per iteration as <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=t_%7Bid%7D&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="t_{id}" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=t_%7Bid%7D&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="t_{id}" class="lazyload latex" />, and the time to execute a single microbatchs forward and backward pass as <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=t_f&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="t_f" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=t_f&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="t_f" class="lazyload latex" /> and <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=t_b&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="t_b" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=t_b&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="t_b" class="lazyload latex" />. For the schedules in Figures 4 and 5,&nbsp; the pipeline bubble consists of <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=p-1&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="p-1" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=p-1&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="p-1" class="lazyload latex" /> forward passes at the start of a batch, and <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=p-1&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="p-1" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=p-1&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="p-1" class="lazyload latex" /> backward passes at the end. The total amount of time spent in the pipeline bubble is then:</p>



<p class="has-text-align-center"><noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=t_%7Bpb%7D+%3D+%28p-1%29+%5Ccdot+%28t_f+%2B+t_b%29&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="t_{pb} = (p-1) &#92;cdot (t_f + t_b)" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=t_%7Bpb%7D+%3D+%28p-1%29+%5Ccdot+%28t_f+%2B+t_b%29&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="t_{pb} = (p-1) &#92;cdot (t_f + t_b)" class="lazyload latex" /></p>



<p>The ideal processing time for a batch is:</p>



<p class="has-text-align-center"><noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=t_%7Bid%7D+%3D+m+%5Ccdot+%28t_f+%2B+t_b%29&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="t_{id} = m &#92;cdot (t_f + t_b)" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=t_%7Bid%7D+%3D+m+%5Ccdot+%28t_f+%2B+t_b%29&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="t_{id} = m &#92;cdot (t_f + t_b)" class="lazyload latex" /></p>



<p>Therefore, the fraction of total time spent in the pipeline bubble can be computed as:  </p>



<p class="has-text-align-center"><noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bbubble+time+fraction%7D+%3D+%5Cdfrac%7Bt_%7Bpb%7D%7D%7Bt_%7Bid%7D%7D+%3D+%5Cdfrac%7Bp-1%7D%7Bm%7D&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="&#92;text{bubble time fraction} = &#92;dfrac{t_{pb}}{t_{id}} = &#92;dfrac{p-1}{m}" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bbubble+time+fraction%7D+%3D+%5Cdfrac%7Bt_%7Bpb%7D%7D%7Bt_%7Bid%7D%7D+%3D+%5Cdfrac%7Bp-1%7D%7Bm%7D&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="&#92;text{bubble time fraction} = &#92;dfrac{t_{pb}}{t_{id}} = &#92;dfrac{p-1}{m}" class="lazyload latex" /></p>



<p>For the bubble time fraction to be small, <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=m&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="m" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=m&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="m" class="lazyload latex" /> must be much larger than <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=p&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="p" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=p&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="p" class="lazyload latex" />. The number of outstanding forward passes in this schedule is at most the number of pipeline stages. As a result, this schedule requires activations to be stashed for <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=p&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="p" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=p&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="p" class="lazyload latex" /> or fewer microbatches (compared to <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=m&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="m" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=m&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="m" class="lazyload latex" /> microbatches for the schedule in Figure 4). When <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=m+%5Cgg+p&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="m &#92;gg p" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=m+%5Cgg+p&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="m &#92;gg p" class="lazyload latex" />, the schedule in Figure 5 is consequently much more memory-efficient than the one in Figure 4. Both schedules have the same pipeline bubble size.</p>



<h3 id="interleaved_schedule"  class="wp-block-heading"><strong>Interleaved schedule</strong><a href="#interleaved_schedule" class="heading-anchor-link"><i class="fas fa-link"></i></a></h3>



<p>To reduce the size of the pipeline bubble, each device can perform computation for multiple subsets of layers (called a model chunk), instead of a single contiguous set of layers. For example, four layers of computation on each device can be split into two model chunks, each with two layers, instead of each device having a contiguous set of layers (device 1 has layers 1-4, device 2 has layers 5-8, and so on). With this scheme, each device in the pipeline is assigned multiple stages.</p>



<p>As before, you can use an <em>all-forward, all-backward</em> version of this schedule, but this has a high memory footprint. Instead, we developed a more memory-efficient, 1F1B version of this interleaved schedule. This new schedule is shown in Figure 6 and requires the number of microbatches in a batch to be an integer multiple of the degree of pipeline parallelism (number of devices in the pipeline). For example, with four devices, the number of microbatches in a batch must be a multiple of 4.</p>



<p>As shown in Figure 6, the pipeline flush for the same batch size happens sooner in the new schedule. If each device has <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=v&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="v" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=v&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="v" class="lazyload latex" /> stages (or model chunks), then the forward and backward time for a microbatch for each stage will now be <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=t_f+%2F+v&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="t_f / v" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=t_f+%2F+v&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="t_f / v" class="lazyload latex" /> and <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=t_b+%2F+v&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="t_b / v" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=t_b+%2F+v&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="t_b / v" class="lazyload latex" />, respectively. Thus, the pipeline bubble time reduces to:</p>



<p class="has-text-align-center"><noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bbubble+time%7D+%3D+%5Cdfrac%7B%28p-1%29%5Ccdot%28t_f+%2B+t_b%29%7D%7Bv%7D&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="&#92;text{bubble time} = &#92;dfrac{(p-1)&#92;cdot(t_f + t_b)}{v}" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bbubble+time%7D+%3D+%5Cdfrac%7B%28p-1%29%5Ccdot%28t_f+%2B+t_b%29%7D%7Bv%7D&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="&#92;text{bubble time} = &#92;dfrac{(p-1)&#92;cdot(t_f + t_b)}{v}" class="lazyload latex" /></p>



<div class="wp-block-image is-style-default"><figure class="aligncenter size-large"><noscript><img decoding="async" width="625" height="288" src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-625x288.png" alt="Each device can be assigned multiple stages, reducing the total amount of time the last device needs to wait for the first forward pass in a batch to start, and the last backward pass in a batch to complete." class="wp-image-25392" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-625x288.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-300x138.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-179x82.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-768x353.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-1536x707.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-500x230.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-160x74.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-362x167.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-239x110.png 239w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-1024x471.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1.png 1891w" sizes="(max-width: 625px) 100vw, 625px" /></noscript><img decoding="async" width="625" height="288" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20625%20288%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-625x288.png" alt="Each device can be assigned multiple stages, reducing the total amount of time the last device needs to wait for the first forward pass in a batch to start, and the last backward pass in a batch to complete." class="lazyload wp-image-25392" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-625x288.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-300x138.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-179x82.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-768x353.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-1536x707.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-500x230.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-160x74.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-362x167.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-239x110.png 239w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1-1024x471.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/interleaved_1F1B_schedule-1.png 1891w" data-sizes="(max-width: 625px) 100vw, 625px" /><figcaption><em>Figure 6: Interleaved 1F1B schedule, where each device is assigned multiple stages (in this case, 2). Dark colors show the first stage and light colors show the second stage. Additional communication is required since the number of stages is doubled, but the size of the pipeline bubble is decreased (the pipeline flush happens sooner in the interleaved timeline assuming communication is free).</em></figcaption></figure></div>



<p>This reduced pipeline bubble size, however, does not come for free: this schedule requires extra communication. Quantitatively, the amount of communication increases by <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=v&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="v" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=v&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="v" class="lazyload latex" /> since the total number of stages also increases by <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=v&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="v" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=v&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="v" class="lazyload latex" />. In the next section, we discuss how to use the eight InfiniBand networking cards in a DGX A100 node to reduce the impact of this extra communication.</p>



<h2 id="optimized_internode_communication_using_dgx_a100_8_infiniband_networking_cards"  class="wp-block-heading"><strong>Optimized internode communication using DGX A100 8 InfiniBand networking cards</strong><a href="#optimized_internode_communication_using_dgx_a100_8_infiniband_networking_cards" class="heading-anchor-link"><i class="fas fa-link"></i></a></h2>



<p>In a pipelined setup, tensors must be sent and received in the forward and backward direction in parallel. Each DGX A100 is equipped with eight InfiniBand (IB) networking cards. Unfortunately, sends and receives are point-to-point, and only happen between a pair of GPUs on two servers. This makes it hard to leverage all eight cards in a single communication call.</p>



<p>However, you can make use of the fact that you want to use both tensor model parallelism and pipeline model parallelism to reduce the overhead of cross-node communication. The output of each transformer layer is replicated across the tensor-parallel ranks (Figure 4 from <a href="https://arxiv.org/abs/1909.08053" data-wpel-link="exclude">the Megatron paper</a>). As a result, ranks in two consecutive pipeline stages that are performing tensor model parallelism send and receive the exact same set of tensors.</p>



<div class="wp-block-image is-style-default"><figure class="aligncenter size-large"><noscript><img decoding="async" width="625" height="183" src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-625x183.png" alt="Without the scatter/gather optimization, the same tensor is sent redundantly over internode IB links. Instead, at the sender, you can scatter the tensor into smaller chunks, reducing the sizes of tensors sent over IB links. The final tensor can then be rematerialized at the receiver using all-gather over NVLink." class="wp-image-25394" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-625x183.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-300x88.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-179x52.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-768x225.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-1536x450.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-500x147.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-160x47.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-362x106.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-375x110.png 375w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-1024x300.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1.png 1747w" sizes="(max-width: 625px) 100vw, 625px" /></noscript><img decoding="async" width="625" height="183" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20625%20183%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-625x183.png" alt="Without the scatter/gather optimization, the same tensor is sent redundantly over internode IB links. Instead, at the sender, you can scatter the tensor into smaller chunks, reducing the sizes of tensors sent over IB links. The final tensor can then be rematerialized at the receiver using all-gather over NVLink." class="lazyload wp-image-25394" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-625x183.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-300x88.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-179x52.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-768x225.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-1536x450.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-500x147.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-160x47.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-362x106.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-375x110.png 375w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1-1024x300.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Scatter-gather_comm_optimization-1.png 1747w" data-sizes="(max-width: 625px) 100vw, 625px" /><figcaption><em>Figure 7. Scatter/gather communication optimization to reduce the total number of bytes sent between GPUs on different multi-GPU servers.</em></figcaption></figure></div>



<p>For large enough models, we used a tensor-model-parallel size of 8. This means that the same set of tensors are sent eight times between corresponding GPUs on adjacent multi-GPU servers. To reduce this redundancy, we instead split the tensor on the send side into equal-sized chunks and then only sent the chunk to the corresponding rank on the next node, using the ranks dedicated IB card. With eight tensor-model-parallel ranks, each chunk is 8x smaller.</p>



<p>On the receiver side, to re-materialize the full tensor, we performed an all-gather over NVLink, which is much faster than the IB interconnect (Figure 7). We call this the scatter/gather communication optimization. This optimization helps better leverage the multiple IB cards on the DGX A100 servers and makes more communication-intensive schedules feasible, such as the interleaved one. The chunking optimization used here is like the activation partitioning technique to reduce memory footprint and pipeline-parallel communication from <a href="https://arxiv.org/abs/1910.02054" data-wpel-link="exclude">ZeRO</a> and <a href="https://www.deepspeed.ai/" data-wpel-link="external" target="_blank" rel="follow">DeepSpeed</a>.</p>



<h2 id="performance_microbenchmarks_for_pipeline_parallelism"  class="wp-block-heading"><strong>Performance microbenchmarks for pipeline parallelism</strong><a href="#performance_microbenchmarks_for_pipeline_parallelism" class="heading-anchor-link"><i class="fas fa-link"></i></a></h2>



<p>In this section, we evaluated the computational performance of these pipeline-parallel schemes. This section does not use data parallelism, but we show results with both data and model parallelism later in this post.</p>



<h3 id="weak-scaling_of_pipeline_parallelism"  class="wp-block-heading">Weak-scaling of pipeline parallelism<a href="#weak-scaling_of_pipeline_parallelism" class="heading-anchor-link"><i class="fas fa-link"></i></a></h3>



<p>We first evaluated the weak-scaling performance of the default non-interleaved pipeline-parallel schedule using a GPT model with 128 attention heads, a hidden size of 20480, and a microbatch size of 1. As we increased the number of pipeline stages, we also increased the size of the model by proportionally increasing the number of layers in the model. For example, with a pipeline-parallel size of 1, we used a model with three transformer layers and ~15 billion parameters. With a pipeline-parallel size of 8, we used a model with 24 transformer layers and ~121 billion parameters. We used a tensor-parallel size of 8 for all configurations and varied the total number of A100 GPUs used from 8 to 64.</p>



<p>Figure 8 shows throughput per GPU for two different batch sizes. The peak device throughput of an A100 GPU is <a href="https://www.nvidia.com/en-us/data-center/a100/" data-wpel-link="internal">312 teraFLOPs</a>. As expected, the higher batch size scales better because the pipeline bubble is amortized over more microbatches (equal to batch size).</p>



<div class="wp-block-image is-style-default"><figure class="aligncenter size-large"><noscript><img decoding="async" width="625" height="364" src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-625x364.png" alt="Throughput per GPU when using pipeline parallelism decreases with the increase in pipeline-parallel size. Smaller batch sizes see larger decreases." class="wp-image-25396" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-625x364.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-300x175.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-179x104.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-768x447.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-1536x894.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-500x291.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-155x90.png 155w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-362x211.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-189x110.png 189w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-1024x596.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1.png 1933w" sizes="(max-width: 625px) 100vw, 625px" /></noscript><img decoding="async" width="625" height="364" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20625%20364%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-625x364.png" alt="Throughput per GPU when using pipeline parallelism decreases with the increase in pipeline-parallel size. Smaller batch sizes see larger decreases." class="lazyload wp-image-25396" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-625x364.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-300x175.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-179x104.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-768x447.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-1536x894.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-500x291.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-155x90.png 155w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-362x211.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-189x110.png 189w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1-1024x596.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU-1.png 1933w" data-sizes="(max-width: 625px) 100vw, 625px" /><figcaption><em>Figure 8. Throughput per GPU of pipeline parallelism using two different batch sizes in a weak-scaling experiment setup. Model size increases with the pipeline-parallel size.</em></figcaption></figure></div>



<p>The number of floating point operations (numerator of throughput) is computed analytically based on the model architecture, taking activation recomputation into account.</p>



<h3 id="tensor_vs_pipeline_parallelism"  class="wp-block-heading">Tensor vs. pipeline parallelism<a href="#tensor_vs_pipeline_parallelism" class="heading-anchor-link"><i class="fas fa-link"></i></a></h3>



<p>We also evaluated the impact of parallelization configuration on performance for a given model and batch size. The empirical results in Figure 9 show the importance of using both tensor and pipeline model parallelism in conjunction to train a 161-billion-parameter GPT model (32 transformer layers, 128 attention heads, hidden size of 20480) with low communication overhead and high compute resource utilization. Tensor model parallelism is best within a node (DGX A100 server) due to its expensive all-reduce communication.</p>



<p>Pipeline model parallelism, on the other hand, uses much cheaper point-to-point communication that can be performed across nodes without bottlenecking the entire computation. However, pipeline parallelism can spend significant time in the pipeline bubble. The total number of pipeline stages should thus be limited so that the number of microbatches in the pipeline is a reasonable multiple of the number of pipeline stages. Consequently, we saw peak performance when the tensor-parallel size was equal to the number of GPUs in a single node (8 on Selene with DGX A100 nodes).</p>



<div class="wp-block-image is-style-default"><figure class="aligncenter size-large"><noscript><img decoding="async" width="625" height="364" src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-625x364.png" alt="When using both pipeline and tensor model parallelism, throughput per GPU depends on both the size of the pipeline bubble, and the amount of expensive cross-node communication. Across batch sizes, you see highest throughput for pipeline-parallel size = 8, tensor-parallel size = 8." class="wp-image-25401" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-625x364.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-300x175.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-179x104.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-768x447.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-1536x894.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-500x291.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-155x90.png 155w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-362x211.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-189x110.png 189w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-1024x596.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1.png 1933w" sizes="(max-width: 625px) 100vw, 625px" /></noscript><img decoding="async" width="625" height="364" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20625%20364%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-625x364.png" alt="When using both pipeline and tensor model parallelism, throughput per GPU depends on both the size of the pipeline bubble, and the amount of expensive cross-node communication. Across batch sizes, you see highest throughput for pipeline-parallel size = 8, tensor-parallel size = 8." class="lazyload wp-image-25401" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-625x364.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-300x175.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-179x104.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-768x447.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-1536x894.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-500x291.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-155x90.png 155w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-362x211.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-189x110.png 189w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1-1024x596.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_1-1.png 1933w" data-sizes="(max-width: 625px) 100vw, 625px" /><figcaption><em>Figure 9. Throughput per GPU of various parallel configurations that combine pipeline and tensor model parallelism using a GPT model with 162.2 billion parameters, two different batch sizes, and 64 A100 GPUs.</em></figcaption></figure></div>



<h3 id="scatter-gather_optimization_for_communication"  class="wp-block-heading">Scatter-gather optimization for communication<a href="#scatter-gather_optimization_for_communication" class="heading-anchor-link"><i class="fas fa-link"></i></a></h3>



<p>Figure 10 shows per-GPU throughput with and without (unoptimized) the scatter/gather communication optimization for a GPT model with 175 billion parameters (96 attention heads, hidden size of 12288, and 96 transformer layers). End-to-end throughput improves by up to 11% for communication-intensive schedules (large batch size with interleaving). This highlights the importance of the DGX A100 eight IB cards in achieving high training throughput for large models.</p>



<div class="wp-block-image is-style-default"><figure class="aligncenter size-large"><noscript><img decoding="async" width="625" height="364" src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-625x364.png" alt="The scatter/gather optimization improves throughput by up to 11% across a range of batch sizes with the interleaved schedule." class="wp-image-25402" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-625x364.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-300x175.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-179x104.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-768x447.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-1536x894.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-500x291.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-155x90.png 155w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-362x211.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-189x110.png 189w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-1024x596.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1.png 1933w" sizes="(max-width: 625px) 100vw, 625px" /></noscript><img decoding="async" width="625" height="364" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20625%20364%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-625x364.png" alt="The scatter/gather optimization improves throughput by up to 11% across a range of batch sizes with the interleaved schedule." class="lazyload wp-image-25402" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-625x364.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-300x175.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-179x104.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-768x447.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-1536x894.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-500x291.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-155x90.png 155w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-362x211.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-189x110.png 189w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1-1024x596.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_2-1.png 1933w" data-sizes="(max-width: 625px) 100vw, 625px" /><figcaption><em>Figure 10. Throughput per GPU with and without the scatter/gather optimization for a GPT model with 175 billion parameters using 96 A100 GPUs and the interleaved schedule.</em></figcaption></figure></div>



<h3 id="interleaved_vs_non-interleaved_schedule"  class="wp-block-heading">Interleaved vs. non-interleaved schedule<a href="#interleaved_vs_non-interleaved_schedule" class="heading-anchor-link"><i class="fas fa-link"></i></a></h3>



<p>Figure 11 shows the per-GPU throughput for interleaved and non-interleaved schedules on the same GPT model with 175 billion parameters. The interleaved schedule with the scatter/gather communication optimization has higher computational performance than the non-interleaved (default) schedule. This gap closes as the batch size increases, due to two reasons:</p>



<ul class="wp-block-list"><li>As the batch size increases, the bubble size in the default schedule decreases.</li><li>The amount of point-to-point communication within the pipeline is proportional to the batch size. Consequently, the non-interleaved schedule catches up as the amount of communication increases.</li></ul>



<p>Without the scatter/gather optimization, the default schedule performs better than the interleaved schedule at larger batch sizes (not shown).</p>



<div class="wp-block-image is-style-default"><figure class="aligncenter size-large"><noscript><img decoding="async" width="625" height="364" src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-625x364.png" alt="For a GPT model with 175 billion parameters, the interleaved schedule has higher per-GPU throughput than the non-interleaved schedule across batch sizes. The gap between the two schedules decreases as the batch size increases." class="wp-image-25403" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-625x364.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-300x175.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-179x104.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-768x447.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-1536x894.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-500x291.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-155x90.png 155w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-362x211.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-189x110.png 189w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-1024x596.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1.png 1933w" sizes="(max-width: 625px) 100vw, 625px" /></noscript><img decoding="async" width="625" height="364" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20625%20364%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-625x364.png" alt="For a GPT model with 175 billion parameters, the interleaved schedule has higher per-GPU throughput than the non-interleaved schedule across batch sizes. The gap between the two schedules decreases as the batch size increases." class="lazyload wp-image-25403" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-625x364.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-300x175.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-179x104.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-768x447.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-1536x894.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-500x291.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-155x90.png 155w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-362x211.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-189x110.png 189w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1-1024x596.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Throughput_GPU_3-1.png 1933w" data-sizes="(max-width: 625px) 100vw, 625px" /><figcaption><em>Figure 11. Throughput per GPU of interleaved and non-interleaved schedules for a GPT model with 175 billion parameters using 96 A100 GPUs.</em></figcaption></figure></div>



<h2 id="end-to-end_scaling_using_model_and_data_parallelism"  class="wp-block-heading"><strong>End-to-end scaling using model and data parallelism</strong><a href="#end-to-end_scaling_using_model_and_data_parallelism" class="heading-anchor-link"><i class="fas fa-link"></i></a></h2>



<p>Consider the weak-scaling performance of Megatron on GPT models ranging from a billion to a trillion parameters. We used tensor, pipeline, data parallelism, and the interleaved pipeline schedule with the scatter/gather optimization enabled. All models used a vocabulary size of 51,200 (multiple of 1024) and a sequence length of 2048. We varied the hidden size, number of attention heads, and number of layers to arrive at a specific model size. As the model size increased, we also increased the batch size and the number of GPUs.</p>



<p>Table 1 shows the model configurations along with the achieved FLOPs per second (both per GPU and aggregate over all GPUs). We saw almost-perfect linear scaling to 3072 A100 GPUs (384 DGX A100 nodes), as shown in Figure 1. Throughput is measured for end-to-end training: all operations including data loading, optimization, and logging. The largest case achieves 52% of the theoretical peak FLOPs.</p>



<figure class="wp-block-table aligncenter is-style-stripes"><table><thead><tr><td class="has-text-align-right" data-align="right">Model <br>size</td><td class="has-text-align-center" data-align="center">Hidden <br>size</td><td class="has-text-align-center" data-align="center">Number of <br>layers</td><td class="has-text-align-center" data-align="center">Model-parallel <br>size</td><td class="has-text-align-center" data-align="center">Number of <br>GPUs</td><td class="has-text-align-center" data-align="center">Batch <br>size</td><td class="has-text-align-center" data-align="center">Achieved teraFlOPs <br>per GPU</td></tr></thead><tbody><tr><td class="has-text-align-right" data-align="right">1.7B</td><td class="has-text-align-center" data-align="center">2304</td><td class="has-text-align-center" data-align="center">24</td><td class="has-text-align-center" data-align="center">1</td><td class="has-text-align-center" data-align="center">32</td><td class="has-text-align-center" data-align="center">512</td><td class="has-text-align-center" data-align="center">137</td></tr><tr><td class="has-text-align-right" data-align="right">3.6B</td><td class="has-text-align-center" data-align="center">3072</td><td class="has-text-align-center" data-align="center">30</td><td class="has-text-align-center" data-align="center">2</td><td class="has-text-align-center" data-align="center">64</td><td class="has-text-align-center" data-align="center">512</td><td class="has-text-align-center" data-align="center">138</td></tr><tr><td class="has-text-align-right" data-align="right">7.5B</td><td class="has-text-align-center" data-align="center">4096</td><td class="has-text-align-center" data-align="center">36</td><td class="has-text-align-center" data-align="center">4</td><td class="has-text-align-center" data-align="center">128</td><td class="has-text-align-center" data-align="center">512</td><td class="has-text-align-center" data-align="center">142</td></tr><tr><td class="has-text-align-right" data-align="right">18B</td><td class="has-text-align-center" data-align="center">6144</td><td class="has-text-align-center" data-align="center">40</td><td class="has-text-align-center" data-align="center">8</td><td class="has-text-align-center" data-align="center">256</td><td class="has-text-align-center" data-align="center">1024</td><td class="has-text-align-center" data-align="center">135</td></tr><tr><td class="has-text-align-right" data-align="right">39B</td><td class="has-text-align-center" data-align="center">8192</td><td class="has-text-align-center" data-align="center">48</td><td class="has-text-align-center" data-align="center">16</td><td class="has-text-align-center" data-align="center">512</td><td class="has-text-align-center" data-align="center">1536</td><td class="has-text-align-center" data-align="center">138</td></tr><tr><td class="has-text-align-right" data-align="right">76B</td><td class="has-text-align-center" data-align="center">10240</td><td class="has-text-align-center" data-align="center">60</td><td class="has-text-align-center" data-align="center">32</td><td class="has-text-align-center" data-align="center">1024</td><td class="has-text-align-center" data-align="center">1792</td><td class="has-text-align-center" data-align="center">140</td></tr><tr><td class="has-text-align-right" data-align="right">145B</td><td class="has-text-align-center" data-align="center">12288</td><td class="has-text-align-center" data-align="center">80</td><td class="has-text-align-center" data-align="center">64</td><td class="has-text-align-center" data-align="center">1536</td><td class="has-text-align-center" data-align="center">2304</td><td class="has-text-align-center" data-align="center">148</td></tr><tr><td class="has-text-align-right" data-align="right">310B</td><td class="has-text-align-center" data-align="center">16384</td><td class="has-text-align-center" data-align="center">96</td><td class="has-text-align-center" data-align="center">128</td><td class="has-text-align-center" data-align="center">1920</td><td class="has-text-align-center" data-align="center">2160</td><td class="has-text-align-center" data-align="center">155</td></tr><tr><td class="has-text-align-right" data-align="right">530B</td><td class="has-text-align-center" data-align="center">20480</td><td class="has-text-align-center" data-align="center">105</td><td class="has-text-align-center" data-align="center">280</td><td class="has-text-align-center" data-align="center">2520</td><td class="has-text-align-center" data-align="center">2520</td><td class="has-text-align-center" data-align="center">163</td></tr><tr><td class="has-text-align-right" data-align="right">1T</td><td class="has-text-align-center" data-align="center">25600</td><td class="has-text-align-center" data-align="center">128</td><td class="has-text-align-center" data-align="center">512</td><td class="has-text-align-center" data-align="center">3072</td><td class="has-text-align-center" data-align="center">3072</td><td class="has-text-align-center" data-align="center">163</td></tr></tbody></table><figcaption><em>Table 1. Weak-scaling throughput for GPT-3 models ranging from 1 billion to 1 trillion parameters.</em></figcaption></figure>



<p>Finally, based on the measured throughputs from Table 1, you can estimate the training time. The time required to train a GPT-based language model with <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=P&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="P" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=P&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="P" class="lazyload latex" /> parameters using <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=T&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="T" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=T&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="T" class="lazyload latex" /> tokens on <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=N&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="N" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=N&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="N" class="lazyload latex" /> GPUs with per-GPU throughput of <noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=X&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="X" class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=X&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="X" class="lazyload latex" /> can be estimated as follows:</p>



<p class="has-text-align-center"><noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTraining+time+%28seconds%29%7D+%5Capprox+8+%5Ccdot+%5Cdfrac%7BTP%7D%7BNX%7D.&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="&#92;text{Training time (seconds)} &#92;approx 8 &#92;cdot &#92;dfrac{TP}{NX}." class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=%5Ctext%7BTraining+time+%28seconds%29%7D+%5Capprox+8+%5Ccdot+%5Cdfrac%7BTP%7D%7BNX%7D.&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="&#92;text{Training time (seconds)} &#92;approx 8 &#92;cdot &#92;dfrac{TP}{NX}." class="lazyload latex" /></p>



<p>For the 1 trillion parameter model, assume that you need about 450 billion tokens to train the model. Using 3072 A100 GPUs with 163 teraFLOPs / GPU, you require:</p>



<p class="has-text-align-center"><noscript><img decoding="async" src="https://s0.wp.com/latex.php?latex=%5Ctext%7B1T+model+training+time%7D+%5Capprox+8+%5Ccdot+%5Cdfrac%7B450+%5Ctimes+10%5E9+%5Ctimes+1008+%5Ctimes+10%5E9%7D%7B3072+%5Ctimes+163+%5Ctimes+10%5E%7B12%7D%7D+%5Capprox+84+%5Ctext%7B+days%7D%2C&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="&#92;text{1T model training time} &#92;approx 8 &#92;cdot &#92;dfrac{450 &#92;times 10^9 &#92;times 1008 &#92;times 10^9}{3072 &#92;times 163 &#92;times 10^{12}} &#92;approx 84 &#92;text{ days}," class="latex" /></noscript><img decoding="async" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E' data-src="https://s0.wp.com/latex.php?latex=%5Ctext%7B1T+model+training+time%7D+%5Capprox+8+%5Ccdot+%5Cdfrac%7B450+%5Ctimes+10%5E9+%5Ctimes+1008+%5Ctimes+10%5E9%7D%7B3072+%5Ctimes+163+%5Ctimes+10%5E%7B12%7D%7D+%5Capprox+84+%5Ctext%7B+days%7D%2C&#038;bg=transparent&#038;fg=000&#038;s=0&#038;c=20201002" alt="&#92;text{1T model training time} &#92;approx 8 &#92;cdot &#92;dfrac{450 &#92;times 10^9 &#92;times 1008 &#92;times 10^9}{3072 &#92;times 163 &#92;times 10^{12}} &#92;approx 84 &#92;text{ days}," class="lazyload latex" /></p>



<p>This is less than three months. The GPT-3 model with 175 billion parameters requires just over a month to train using 1024 A100 GPUs. These results indicate that it is feasible to train such large models in a reasonable amount of time with this system. For more information, see <a href="https://arxiv.org/abs/2104.04473" data-wpel-link="exclude">Efficient Large-Scale Language Model Training on GPU Clusters</a>.</p>



<h2 id="summary"  class="wp-block-heading"><strong>Summary</strong><a href="#summary" class="heading-anchor-link"><i class="fas fa-link"></i></a></h2>



<p>In this post, we outlined various techniques that facilitate the training of NLP models with up to a trillion parameters, using a smart combination of different parallelization strategies:</p>



<ul class="wp-block-list"><li>Intranode tensor model parallelism</li><li>Internode pipeline model parallelism</li><li>Data parallelism</li></ul>



<p>Going forward, we want to further optimize our pipelining schedules. For example, we expect a throughput improvement if we can compute data gradients before weight gradients, as tensors can be sent upstream earlier, leading to a cheaper pipeline flush. We also want to explore the tradeoffs associated with hyperparameters such as microbatch size, global batch size, and the degree of activation recomputation on throughput. Finally, we want to train models to convergence, and better understand the implications of using schedules without pipeline flushes, such as <a href="https://arxiv.org/abs/2006.09503" data-wpel-link="exclude">PipeDream-2BW</a>, which has relaxed weight update semantics.</p>
</div>

  <div class="card--post-attributes-secondary">
              <div class="post--comments-count secondary--attribute">
        <a href="#entry-content-comments">
          <i class="fad fa-comment-alt-lines"></i> Discuss (1)
        </a>
      </div>
    
    <div class="post--rate secondary--attribute">
      		<div class="wpulike wpulike-heart " ><div class="wp_ulike_general_class wp_ulike_is_not_liked"><button type="button"
					aria-label="Like Button"
					data-ulike-id="24760"
					data-ulike-nonce="6045284b9c"
					data-ulike-type="post"
					data-ulike-template="wpulike-heart"
					data-ulike-display-likers=""
					data-ulike-likers-style="popover"
					class="wp_ulike_btn wp_ulike_put_text wp_post_btn_24760"><span><i class="far fa-thumbs-up"></i></span>				</button><span class="count-box wp_ulike_counter_up" data-ulike-counter-value="+10"></span>			</div></div>
	
      <span class="js-like-click like-click">
      Like    </span>
    </div>
  </div>

  <div class="card--post-attributes-secondary tags">
    <div class="caption">
      <h2 class="h--smaller txt-clr--blck">Tags</h2>
    </div>
    <div class="content-s post-tags--list mt-0">
             <a href="https://developer.nvidia.com/blog/category/data-center-cloud/" data-wpel-link="internal">Data Center / Cloud</a> | <a href="https://developer.nvidia.com/blog/recent-posts/?products=DGX" data-wpel-link="internal">DGX</a> | <a href="https://developer.nvidia.com/blog/recent-posts/?products=NeMo+Framework" data-wpel-link="internal">NeMo Framework</a> | <a href="https://developer.nvidia.com/blog/tag/gtc-digital-2021/" data-wpel-link="internal">GTC Digital 2021</a> | <a href="https://developer.nvidia.com/blog/tag/nemo/" data-wpel-link="internal">NeMo</a> | <a href="https://developer.nvidia.com/blog/tag/pipelines/" data-wpel-link="internal">pipelines</a>     </div>
  </div>

  <div class="post-authors-list">
  <div class="entry-content-author">
  <div class="caption">
    <h2 class="h--smaller txt-clr--blck">
                About the Authors
          </h2>
  </div>
                          <div class="media author-info">
          <div class="author-media-left media-left">
            <noscript><img alt='Avatar photo' src='https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/deepak_narayanan-scaled-131x131.jpg' srcset='https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/deepak_narayanan-scaled-262x262.jpg 2x' class='avatar avatar-131 photo' height='131' width='131' decoding='async'/></noscript><img alt='Avatar photo' src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20131%20131%22%3E%3C/svg%3E' data-src='https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/deepak_narayanan-scaled-131x131.jpg' data-srcset='https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/deepak_narayanan-scaled-262x262.jpg 2x' class='lazyload avatar avatar-131 photo' height='131' width='131' decoding='async'/>
          </div>
          <div class="author-media-body media-body">

                                          <b>
                  About Deepak Narayanan
                </b>
                <br/>
                
                          Deepak Narayanan is a senior applied deep learning research scientist in the ADLR group at NVIDIA, where he looks at making the training and inference of LLMs faster and more reliable. He holds a PhD in Computer Science from Stanford University.
            
                                                    
                          <div id="author-link">
                <a href="https://developer.nvidia.com/blog/author/dnarayanan/" rel="author" data-wpel-link="internal">
                                            View all posts by Deepak Narayanan<svg width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 612"><path d="M305 239c9.4 9.4 9.4 24.6 0 33.9L113 465c-9.4 9.4-24.6 9.4-33.9 0s-9.4-24.6 0-33.9l175-175L79 81c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0L305 239z"/></svg>
                                    </a>
              </div>
                      </div>
        </div>
              <div class="media author-info">
          <div class="author-media-left media-left">
            <noscript><img alt='Avatar photo' src='https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/mohammed-131x131.jpg' srcset='https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/mohammed-262x262.jpg 2x' class='avatar avatar-131 photo' height='131' width='131' decoding='async'/></noscript><img alt='Avatar photo' src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20131%20131%22%3E%3C/svg%3E' data-src='https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/mohammed-131x131.jpg' data-srcset='https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/mohammed-262x262.jpg 2x' class='lazyload avatar avatar-131 photo' height='131' width='131' decoding='async'/>
          </div>
          <div class="author-media-body media-body">

                                          <b>
                  About Mohammad Shoeybi
                </b>
                <br/>
                
                          Mohammad Shoeybi is a senior research scientist and manages the NLP team within the Applied Deep Learning Research group at NVIDIA. His team focuses on language modeling, NLP applications such as question answering and dialogue systems, and large-scale training. He received his PhD. from Stanford University in 2010. Prior to NVIDIA, he worked at DeepMind and Baidu USA leading efforts on bringing deep learning and reinforcement learning to applications.
            
                                                    
                          <div id="author-link">
                <a href="https://developer.nvidia.com/blog/author/mshoeybi/" rel="author" data-wpel-link="internal">
                                            View all posts by Mohammad Shoeybi<svg width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 612"><path d="M305 239c9.4 9.4 9.4 24.6 0 33.9L113 465c-9.4 9.4-24.6 9.4-33.9 0s-9.4-24.6 0-33.9l175-175L79 81c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0L305 239z"/></svg>
                                    </a>
              </div>
                      </div>
        </div>
              <div class="media author-info">
          <div class="author-media-left media-left">
            <noscript><img alt='Avatar photo' src='https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/JaredCasper-131x131.jpg' srcset='https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/JaredCasper-262x262.jpg 2x' class='avatar avatar-131 photo' height='131' width='131' decoding='async'/></noscript><img alt='Avatar photo' src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20131%20131%22%3E%3C/svg%3E' data-src='https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/JaredCasper-131x131.jpg' data-srcset='https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/JaredCasper-262x262.jpg 2x' class='lazyload avatar avatar-131 photo' height='131' width='131' decoding='async'/>
          </div>
          <div class="author-media-body media-body">

                                          <b>
                  About Jared Casper
                </b>
                <br/>
                
                          Jared works as a Senior Deep Learning Scientist in the Applied Deep Learning Research team at NVIDIA.  Prior to joining NVIDIA in 2017, Jared worked on systems for deep learning at Baidus Silicon Valley AI Lab and on domain-specific hardware accelerators at Oracle Labs.  Jared received his Ph.D. from Stanford in 2015 focusing on Computer Architecture.
            
                                                    
                          <div id="author-link">
                <a href="https://developer.nvidia.com/blog/author/jcasper/" rel="author" data-wpel-link="internal">
                                            View all posts by Jared Casper<svg width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 612"><path d="M305 239c9.4 9.4 9.4 24.6 0 33.9L113 465c-9.4 9.4-24.6 9.4-33.9 0s-9.4-24.6 0-33.9l175-175L79 81c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0L305 239z"/></svg>
                                    </a>
              </div>
                      </div>
        </div>
              <div class="media author-info">
          <div class="author-media-left media-left">
            <noscript><img alt='Avatar photo' src='https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/patrick-131x131.jpg' srcset='https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/patrick-262x262.jpg 2x' class='avatar avatar-131 photo' height='131' width='131' decoding='async'/></noscript><img alt='Avatar photo' src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20131%20131%22%3E%3C/svg%3E' data-src='https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/patrick-131x131.jpg' data-srcset='https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/patrick-262x262.jpg 2x' class='lazyload avatar avatar-131 photo' height='131' width='131' decoding='async'/>
          </div>
          <div class="author-media-body media-body">

                                          <b>
                  About Patrick LeGresley
                </b>
                <br/>
                
                          Patrick LeGresley is a researcher in the NLP group within Applied Deep Learning Research at NVIDIA, where he focuses on system aspects of training large language models. He received his PhD in Aeronautics and Astronautics from Stanford University. In the past, he also worked at the Baidu Silicon Valley AI Lab, working on systems research and deep learning for speech recognition.
            
                                                    
                          <div id="author-link">
                <a href="https://developer.nvidia.com/blog/author/plegresley/" rel="author" data-wpel-link="internal">
                                            View all posts by Patrick LeGresley<svg width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 612"><path d="M305 239c9.4 9.4 9.4 24.6 0 33.9L113 465c-9.4 9.4-24.6 9.4-33.9 0s-9.4-24.6 0-33.9l175-175L79 81c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0L305 239z"/></svg>
                                    </a>
              </div>
                      </div>
        </div>
              <div class="media author-info">
          <div class="author-media-left media-left">
            <noscript><img alt='Avatar photo' src='https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/mostofa-4-131x131.jpg' srcset='https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/mostofa-4-262x262.jpg 2x' class='avatar avatar-131 photo' height='131' width='131' decoding='async'/></noscript><img alt='Avatar photo' src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20131%20131%22%3E%3C/svg%3E' data-src='https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/mostofa-4-131x131.jpg' data-srcset='https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/mostofa-4-262x262.jpg 2x' class='lazyload avatar avatar-131 photo' height='131' width='131' decoding='async'/>
          </div>
          <div class="author-media-body media-body">

                                          <b>
                  About Mostofa Patwary
                </b>
                <br/>
                
                          Mostofa Patwary is a senior deep learning research scientist at the Applied Deep Learning Research team at NVIDIA. Mostofa's research interests span in the areas of natural language processing, scalable deep learning, HPC, and algorithm engineering. Prior to joining NVIDIA, Mostofa worked on scaling large language models and the predictability of scaling deep learning applications at Baidu's Silicon Valley AI Lab. Mostofa also made significant contributions in developing large-scale code for several core kernels in machine learning capable of running on supercomputers.
            
                                                    
                          <div id="author-link">
                <a href="https://developer.nvidia.com/blog/author/mpatwary/" rel="author" data-wpel-link="internal">
                                            View all posts by Mostofa Patwary<svg width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 612"><path d="M305 239c9.4 9.4 9.4 24.6 0 33.9L113 465c-9.4 9.4-24.6 9.4-33.9 0s-9.4-24.6 0-33.9l175-175L79 81c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0L305 239z"/></svg>
                                    </a>
              </div>
                      </div>
        </div>
              <div class="media author-info">
          <div class="author-media-left media-left">
            <noscript><img alt='Avatar photo' src='https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Vijay-Korthikanti-131x131.jpg' srcset='https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Vijay-Korthikanti.jpg 2x' class='avatar avatar-131 photo' height='131' width='131' decoding='async'/></noscript><img alt='Avatar photo' src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20131%20131%22%3E%3C/svg%3E' data-src='https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Vijay-Korthikanti-131x131.jpg' data-srcset='https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Vijay-Korthikanti.jpg 2x' class='lazyload avatar avatar-131 photo' height='131' width='131' decoding='async'/>
          </div>
          <div class="author-media-body media-body">

                                          <b>
                  About Vijay Korthikanti
                </b>
                <br/>
                
                          Vijay Korthikanti is a senior research scientist in the Applied Deep Learning Research group at NVIDIA. Vijay's research interests are in areas of scalable deep learning, HW-SW codesign, parallel algorithms, and formal verification. Prior to joining NVIDIA, Vijay worked at two HW startups, Nervana Systems and Cerebras Systems, focusing on parallel algorithm development, HW-SW codesign, and end-to-end deep learning acceleration. Earlier in his career, he spent a few years at Synopsys on their formal verification team. Vijay received his Ph. D from UIUC in 2011 focusing on energy-performance tradeoffs of parallel applications.
            
                                                    
                          <div id="author-link">
                <a href="https://developer.nvidia.com/blog/author/vkorthikanti/" rel="author" data-wpel-link="internal">
                                            View all posts by Vijay Korthikanti<svg width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 612"><path d="M305 239c9.4 9.4 9.4 24.6 0 33.9L113 465c-9.4 9.4-24.6 9.4-33.9 0s-9.4-24.6 0-33.9l175-175L79 81c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0L305 239z"/></svg>
                                    </a>
              </div>
                      </div>
        </div>
              <div class="media author-info">
          <div class="author-media-left media-left">
            <noscript><img alt='Avatar photo' src='https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Dmitri-Vainbrand-131x131.jpg' srcset='https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Dmitri-Vainbrand-262x262.jpg 2x' class='avatar avatar-131 photo' height='131' width='131' decoding='async'/></noscript><img alt='Avatar photo' src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20131%20131%22%3E%3C/svg%3E' data-src='https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Dmitri-Vainbrand-131x131.jpg' data-srcset='https://developer-blogs.nvidia.com/wp-content/uploads/2021/03/Dmitri-Vainbrand-262x262.jpg 2x' class='lazyload avatar avatar-131 photo' height='131' width='131' decoding='async'/>
          </div>
          <div class="author-media-body media-body">

                                          <b>
                  About Dmitri Vainbrand
                </b>
                <br/>
                
                          Dmitri Vainbrand is a senior deep learning architect at GPU DL Architecture group at NVIDIA. Dmitri is working on GPU HW and system architecture, focusing on large deep learning networks, systems, and scale-out. Dmitri received his MSc from Technion in 2011 in the field of network-on-chip architectures for neural networks. Prior to NVIDIA, he worked at Intel, where he took part in the development of five generations of CPU Core processors and Intels first AI accelerator.
            
                                                    
                          <div id="author-link">
                <a href="https://developer.nvidia.com/blog/author/dvainbrand/" rel="author" data-wpel-link="internal">
                                            View all posts by Dmitri Vainbrand<svg width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 612"><path d="M305 239c9.4 9.4 9.4 24.6 0 33.9L113 465c-9.4 9.4-24.6 9.4-33.9 0s-9.4-24.6 0-33.9l175-175L79 81c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0L305 239z"/></svg>
                                    </a>
              </div>
                      </div>
        </div>
              <div class="media author-info">
          <div class="author-media-left media-left">
            <noscript><img alt='Avatar photo' src='https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/bryan-131x131.jpg' srcset='https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/bryan-262x262.jpg 2x' class='avatar avatar-131 photo' height='131' width='131' decoding='async'/></noscript><img alt='Avatar photo' src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20131%20131%22%3E%3C/svg%3E' data-src='https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/bryan-131x131.jpg' data-srcset='https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/bryan-262x262.jpg 2x' class='lazyload avatar avatar-131 photo' height='131' width='131' decoding='async'/>
          </div>
          <div class="author-media-body media-body">

                                          <b>
                  About Bryan Catanzaro
                </b>
                <br/>
                
                          Bryan Catanzaro is vice president of Applied Deep Learning Research at NVIDIA, where he leads a team finding new ways to use AI to improve projects ranging from language understanding to computer graphics and chip design. Bryan's research at NVIDIA led to the creation of CUDNN, and more recently, he helped lead the team that invented DLSS 2.0. Prior to NVIDIA, he worked at Baidu to create next-generation systems for training and deploying end-to-end, deep learning-based speech recognition. Bryan received his PhD in Electrical Engineering and Computer Sciences from the University of California, Berkeley.
            
                                                    
                          <div id="author-link">
                <a href="https://developer.nvidia.com/blog/author/bcatanzaro/" rel="author" data-wpel-link="internal">
                                            View all posts by Bryan Catanzaro<svg width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 612"><path d="M305 239c9.4 9.4 9.4 24.6 0 33.9L113 465c-9.4 9.4-24.6 9.4-33.9 0s-9.4-24.6 0-33.9l175-175L79 81c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0L305 239z"/></svg>
                                    </a>
              </div>
                      </div>
        </div>
            </div>
  </div>

      <div class="entry-content-comments" id="entry-content-comments">
      <div class="container" id="pf-disqus-thread">
        <div class="row" id="respond">
          <div class="col-md-12 related-posts-comments mb-0"><h2 class="h--smaller txt-clr--blck mb-0">Comments</h2></div>
        </div>
        <div class="row">
          <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12">
                                                                <div class="wpdc-comments-loading" id="wpdc-comments" data-post-id="24760"></div>
                      </div>
        </div>
      </div>
    </div>
    <div id="main-content-end"></div>
</div>

<div id="sidebar" class="sidebar col-lg-3 col-md-3 mt-0">
  <div class="sticky-top-pre"></div>
  <div class="sidebar-item not-sticky-top">
    <div id="sidebar-content" class="sidebar__inner">
      <script>
    window.is_post_page = true;
    window.nv_homepage_url = 'https://developer.nvidia.com/blog';
  </script>

  <div class="block--related-posts prspr-related" data-source="nv">
      <h2 class="h--smaller txt-clr--blck">Related posts</h2>
      <div class="carousel-row__slide js-post-card related-post--row" data-post-id="84749" data-post-title="Achieving High Mixtral 8x7B Performance with NVIDIA H100 Tensor Core GPUs and NVIDIA TensorRT-LLM">
  <div class="carousel-row-slide__inner">
    <div class="carousel-row-slide__thumbnail">
      <noscript><img width="624" height="351" src="https://developer-blogs.nvidia.com/wp-content/uploads/2024/06/Achieving-High-Mixtral-8x7B-Performance-with-NVIDIA-H100-Tensor-Core-GPUs-and-TensorRT-LLM.png" class="attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="" decoding="async" /></noscript><img width="624" height="351" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20624%20351%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2024/06/Achieving-High-Mixtral-8x7B-Performance-with-NVIDIA-H100-Tensor-Core-GPUs-and-TensorRT-LLM.png" class="lazyload attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="" decoding="async" />
    </div>
    <div class="carousel-row-slide__content">
      <div class="carousel-row-slide__title">
        <h3 class="h--smallest carousel-row-slide__heading">
          Achieving High Mixtral 8x7B Performance with NVIDIA H100 Tensor Core GPUs and NVIDIA TensorRT-LLM
        </h3>
      </div>
    </div>
    <a href="https://developer.nvidia.com/blog/achieving-high-mixtral-8x7b-performance-with-nvidia-h100-tensor-core-gpus-and-tensorrt-llm/" class="carousel-row-slide__link" data-wpel-link="internal">
      <span class="visually-hidden">Achieving High Mixtral 8x7B Performance with NVIDIA H100 Tensor Core GPUs and NVIDIA TensorRT-LLM</span>
    </a>
  </div>
</div>
<div class="carousel-row__slide js-post-card related-post--row" data-post-id="74771" data-post-title="NVIDIA TensorRT-LLM Enhancements Deliver Massive Large Language Model Speedups on NVIDIA H200">
  <div class="carousel-row-slide__inner">
    <div class="carousel-row-slide__thumbnail">
      <noscript><img width="658" height="370" src="https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--960x540.png" class="attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="An illustration showing the steps &quot;LLM&quot; then &quot;Optimize&quot; then &quot;Deploy.&quot;" decoding="async" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--960x540.png 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--300x169.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--625x352.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--179x101.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--768x432.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--1536x864.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--645x363.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--500x281.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--160x90.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--362x204.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--196x110.png 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--1024x576.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements-.png 1920w" sizes="(max-width: 658px) 100vw, 658px" /></noscript><img width="658" height="370" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20658%20370%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--960x540.png" class="lazyload attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="An illustration showing the steps &quot;LLM&quot; then &quot;Optimize&quot; then &quot;Deploy.&quot;" decoding="async" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--960x540.png 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--300x169.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--625x352.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--179x101.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--768x432.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--1536x864.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--645x363.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--500x281.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--160x90.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--362x204.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--196x110.png 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements--1024x576.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/12/TensorRT-LLM-Enhancements-.png 1920w" data-sizes="(max-width: 658px) 100vw, 658px" />
    </div>
    <div class="carousel-row-slide__content">
      <div class="carousel-row-slide__title">
        <h3 class="h--smallest carousel-row-slide__heading">
          NVIDIA TensorRT-LLM Enhancements Deliver Massive Large Language Model Speedups on NVIDIA H200
        </h3>
      </div>
    </div>
    <a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-enhancements-deliver-massive-large-language-model-speedups-on-nvidia-h200/" class="carousel-row-slide__link" data-wpel-link="internal">
      <span class="visually-hidden">NVIDIA TensorRT-LLM Enhancements Deliver Massive Large Language Model Speedups on NVIDIA H200</span>
    </a>
  </div>
</div>
<div class="carousel-row__slide js-post-card related-post--row" data-post-id="70549" data-post-title="NVIDIA TensorRT-LLM Supercharges Large Language Model Inference on NVIDIA H100 GPUs">
  <div class="carousel-row-slide__inner">
    <div class="carousel-row-slide__thumbnail">
      <noscript><img width="658" height="370" src="https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-960x540.png" class="attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="TensorRTLLM illustration." decoding="async" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-960x540.png 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-300x169.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-625x352.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-179x101.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-768x432.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-1536x864.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-2048x1152.png 2048w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-645x363.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-500x281.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-160x90.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-362x204.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-196x110.png 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-1024x576.png 1024w" sizes="(max-width: 658px) 100vw, 658px" /></noscript><img width="658" height="370" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20658%20370%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-960x540.png" class="lazyload attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="TensorRTLLM illustration." decoding="async" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-960x540.png 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-300x169.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-625x352.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-179x101.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-768x432.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-1536x864.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-2048x1152.png 2048w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-645x363.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-500x281.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-160x90.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-362x204.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-196x110.png 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/inference-visual-tensor-rt-llm-1024x576.png 1024w" data-sizes="(max-width: 658px) 100vw, 658px" />
    </div>
    <div class="carousel-row-slide__content">
      <div class="carousel-row-slide__title">
        <h3 class="h--smallest carousel-row-slide__heading">
          NVIDIA TensorRT-LLM Supercharges Large Language Model Inference on NVIDIA H100 GPUs
        </h3>
      </div>
    </div>
    <a href="https://developer.nvidia.com/blog/nvidia-tensorrt-llm-supercharges-large-language-model-inference-on-nvidia-h100-gpus/" class="carousel-row-slide__link" data-wpel-link="internal">
      <span class="visually-hidden">NVIDIA TensorRT-LLM Supercharges Large Language Model Inference on NVIDIA H100 GPUs</span>
    </a>
  </div>
</div>
<div class="carousel-row__slide js-post-card related-post--row" data-post-id="64352" data-post-title="Efficiently Scale LLM Training Across a Large GPU Cluster with Alpa and Ray">
  <div class="carousel-row-slide__inner">
    <div class="carousel-row-slide__thumbnail">
      <noscript><img width="658" height="370" src="https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-960x540.png" class="attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="LLM graphic" decoding="async" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-960x540.png 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-300x169.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-625x352.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-179x101.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-768x432.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-1536x864.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-2048x1152.png 2048w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-645x363.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-500x281.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-160x90.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-362x204.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-196x110.png 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-1024x576.png 1024w" sizes="(max-width: 658px) 100vw, 658px" /></noscript><img width="658" height="370" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20658%20370%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-960x540.png" class="lazyload attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="LLM graphic" decoding="async" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-960x540.png 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-300x169.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-625x352.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-179x101.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-768x432.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-1536x864.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-2048x1152.png 2048w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-645x363.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-500x281.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-160x90.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-362x204.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-196x110.png 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/llm-graphic-1024x576.png 1024w" data-sizes="(max-width: 658px) 100vw, 658px" />
    </div>
    <div class="carousel-row-slide__content">
      <div class="carousel-row-slide__title">
        <h3 class="h--smallest carousel-row-slide__heading">
          Efficiently Scale LLM Training Across a Large GPU Cluster with Alpa and Ray
        </h3>
      </div>
    </div>
    <a href="https://developer.nvidia.com/blog/efficiently-scale-llm-training-across-a-large-gpu-cluster-with-alpa-and-ray/" class="carousel-row-slide__link" data-wpel-link="internal">
      <span class="visually-hidden">Efficiently Scale LLM Training Across a Large GPU Cluster with Alpa and Ray</span>
    </a>
  </div>
</div>
<div class="carousel-row__slide js-post-card related-post--row" data-post-id="56807" data-post-title="Deploying a 1.3B GPT-3 Model with NVIDIA NeMo Framework">
  <div class="carousel-row-slide__inner">
    <div class="carousel-row-slide__thumbnail">
      <noscript><img width="624" height="351" src="https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/nemo-deploy-public-llms-featured.jpg" class="attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="" decoding="async" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/nemo-deploy-public-llms-featured.jpg 624w, https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/nemo-deploy-public-llms-featured-300x169.jpg 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/nemo-deploy-public-llms-featured-179x101.jpg 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/nemo-deploy-public-llms-featured-500x281.jpg 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/nemo-deploy-public-llms-featured-160x90.jpg 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/nemo-deploy-public-llms-featured-362x204.jpg 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/nemo-deploy-public-llms-featured-196x110.jpg 196w" sizes="(max-width: 624px) 100vw, 624px" /></noscript><img width="624" height="351" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20624%20351%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/nemo-deploy-public-llms-featured.jpg" class="lazyload attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="" decoding="async" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/nemo-deploy-public-llms-featured.jpg 624w, https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/nemo-deploy-public-llms-featured-300x169.jpg 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/nemo-deploy-public-llms-featured-179x101.jpg 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/nemo-deploy-public-llms-featured-500x281.jpg 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/nemo-deploy-public-llms-featured-160x90.jpg 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/nemo-deploy-public-llms-featured-362x204.jpg 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2022/11/nemo-deploy-public-llms-featured-196x110.jpg 196w" data-sizes="(max-width: 624px) 100vw, 624px" />
    </div>
    <div class="carousel-row-slide__content">
      <div class="carousel-row-slide__title">
        <h3 class="h--smallest carousel-row-slide__heading">
          Deploying a 1.3B GPT-3 Model with NVIDIA NeMo Framework
        </h3>
      </div>
    </div>
    <a href="https://developer.nvidia.com/blog/deploying-a-1-3b-gpt-3-model-with-nvidia-nemo-megatron/" class="carousel-row-slide__link" data-wpel-link="internal">
      <span class="visually-hidden">Deploying a 1.3B GPT-3 Model with NVIDIA NeMo Framework</span>
    </a>
  </div>
</div>
    </div>
        <div class="block--related-posts hide" data-source="wp">
      <h2 class="h--smaller txt-clr--blck">Related posts</h2>
      <div class="carousel-row__slide js-post-card related-post--row" data-post-id="110397" data-post-title="How to Build Privacy-Preserving Evaluation Benchmarks with Synthetic Data">
  <div class="carousel-row-slide__inner">
    <div class="carousel-row-slide__thumbnail">
      <noscript><img width="660" height="370" src="https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-660x370-jpg.webp" class="attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="" decoding="async" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-1536x864-jpg.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-jpg.webp 1920w" sizes="(max-width: 660px) 100vw, 660px" /></noscript><img width="660" height="370" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20660%20370%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-660x370-jpg.webp" class="lazyload attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="" decoding="async" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-1536x864-jpg.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/image2-2-jpg.webp 1920w" data-sizes="(max-width: 660px) 100vw, 660px" />
    </div>
    <div class="carousel-row-slide__content">
      <div class="carousel-row-slide__title">
        <h3 class="h--smallest carousel-row-slide__heading">
          How to Build Privacy-Preserving Evaluation Benchmarks with Synthetic Data
        </h3>
      </div>
    </div>
    <a href="https://developer.nvidia.com/blog/how-to-build-privacy-preserving-evaluation-benchmarks-with-synthetic-data/" class="carousel-row-slide__link" data-wpel-link="internal">
      <span class="visually-hidden">How to Build Privacy-Preserving Evaluation Benchmarks with Synthetic Data</span>
    </a>
  </div>
</div>
<div class="carousel-row__slide js-post-card related-post--row" data-post-id="108599" data-post-title="Pioneering AI Co-Scientists for Fusion Research and Cancer Treatment">
  <div class="carousel-row-slide__inner">
    <div class="carousel-row-slide__thumbnail">
      <noscript><img width="660" height="370" src="https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-660x370-png.webp" class="attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="" decoding="async" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-png.webp 1920w" sizes="(max-width: 660px) 100vw, 660px" /></noscript><img width="660" height="370" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20660%20370%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-660x370-png.webp" class="lazyload attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="" decoding="async" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-png.webp 1920w" data-sizes="(max-width: 660px) 100vw, 660px" />
    </div>
    <div class="carousel-row-slide__content">
      <div class="carousel-row-slide__title">
        <h3 class="h--smallest carousel-row-slide__heading">
          Pioneering AI Co-Scientists for Fusion Research and Cancer Treatment
        </h3>
      </div>
    </div>
    <a href="https://developer.nvidia.com/blog/pioneering-ai-co-scientists-for-fusion-research-and-cancer-treatment/" class="carousel-row-slide__link" data-wpel-link="internal">
      <span class="visually-hidden">Pioneering AI Co-Scientists for Fusion Research and Cancer Treatment</span>
    </a>
  </div>
</div>
<div class="carousel-row__slide js-post-card related-post--row" data-post-id="108259" data-post-title="Democratizing Large-Scale Mixture-of-Experts Training with NVIDIA PyTorch Parallelism">
  <div class="carousel-row-slide__inner">
    <div class="carousel-row-slide__thumbnail">
      <noscript><img width="660" height="370" src="https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-660x370-jpg.webp" class="attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="" decoding="async" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-195x110-jpg.webp 195w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-960x540-jpg.webp 960w" sizes="(max-width: 660px) 100vw, 660px" /></noscript><img width="660" height="370" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20660%20370%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-660x370-jpg.webp" class="lazyload attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="" decoding="async" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-195x110-jpg.webp 195w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-960x540-jpg.webp 960w" data-sizes="(max-width: 660px) 100vw, 660px" />
    </div>
    <div class="carousel-row-slide__content">
      <div class="carousel-row-slide__title">
        <h3 class="h--smallest carousel-row-slide__heading">
          Democratizing Large-Scale Mixture-of-Experts Training with NVIDIA PyTorch Parallelism
        </h3>
      </div>
    </div>
    <a href="https://developer.nvidia.com/blog/accelerating-large-scale-mixture-of-experts-training-in-pytorch/" class="carousel-row-slide__link" data-wpel-link="internal">
      <span class="visually-hidden">Democratizing Large-Scale Mixture-of-Experts Training with NVIDIA PyTorch Parallelism</span>
    </a>
  </div>
</div>
<div class="carousel-row__slide js-post-card related-post--row" data-post-id="107403" data-post-title="Agentic AI Unleashed: Join the AWS &amp; NVIDIA Hackathon">
  <div class="carousel-row-slide__inner">
    <div class="carousel-row-slide__thumbnail">
      <noscript><img width="660" height="370" src="https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-660x370-jpeg.webp" class="attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="" decoding="async" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-660x370-jpeg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-300x168-jpeg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-625x351-jpeg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-179x100-jpeg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-768x431-jpeg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-645x362-jpeg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-500x280-jpeg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-160x90-jpeg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-362x203-jpeg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-196x110-jpeg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-1024x574-jpeg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-960x540-jpeg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-jpeg.webp 1280w" sizes="(max-width: 660px) 100vw, 660px" /></noscript><img width="660" height="370" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20660%20370%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-660x370-jpeg.webp" class="lazyload attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="" decoding="async" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-660x370-jpeg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-300x168-jpeg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-625x351-jpeg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-179x100-jpeg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-768x431-jpeg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-645x362-jpeg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-500x280-jpeg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-160x90-jpeg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-362x203-jpeg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-196x110-jpeg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-1024x574-jpeg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-960x540-jpeg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/1760026502108-jpeg.webp 1280w" data-sizes="(max-width: 660px) 100vw, 660px" />
    </div>
    <div class="carousel-row-slide__content">
      <div class="carousel-row-slide__title">
        <h3 class="h--smallest carousel-row-slide__heading">
          Agentic AI Unleashed: Join the AWS &amp; NVIDIA Hackathon
        </h3>
      </div>
    </div>
    <a href="https://nvidia-aws.devpost.com/?utm_source=devpost&#038;utm_medium=linkedin&#038;utm_campaign=agenticaiunleashed25" class="carousel-row-slide__link" data-wpel-link="external" target="_blank" rel="follow">
      <span class="visually-hidden">Agentic AI Unleashed: Join the AWS &amp; NVIDIA Hackathon</span>
    </a>
  </div>
</div>
<div class="carousel-row__slide js-post-card related-post--row" data-post-id="106293" data-post-title="Faster Training Throughput in FP8 Precision with NVIDIA NeMo">
  <div class="carousel-row-slide__inner">
    <div class="carousel-row-slide__thumbnail">
      <noscript><img width="600" height="338" src="https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/llm-optimize-deploy-graphic-png.webp" class="attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="" decoding="async" srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/llm-optimize-deploy-graphic-png.webp 600w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/llm-optimize-deploy-graphic-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/llm-optimize-deploy-graphic-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/llm-optimize-deploy-graphic-500x282-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/llm-optimize-deploy-graphic-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/llm-optimize-deploy-graphic-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/llm-optimize-deploy-graphic-195x110-png.webp 195w" sizes="(max-width: 600px) 100vw, 600px" /></noscript><img width="600" height="338" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20600%20338%22%3E%3C/svg%3E' data-src="https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/llm-optimize-deploy-graphic-png.webp" class="lazyload attachment-post-card-thumbnail size-post-card-thumbnail wp-post-image" alt="" decoding="async" data-srcset="https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/llm-optimize-deploy-graphic-png.webp 600w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/llm-optimize-deploy-graphic-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/llm-optimize-deploy-graphic-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/llm-optimize-deploy-graphic-500x282-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/llm-optimize-deploy-graphic-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/llm-optimize-deploy-graphic-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/09/llm-optimize-deploy-graphic-195x110-png.webp 195w" data-sizes="(max-width: 600px) 100vw, 600px" />
    </div>
    <div class="carousel-row-slide__content">
      <div class="carousel-row-slide__title">
        <h3 class="h--smallest carousel-row-slide__heading">
          Faster Training Throughput in FP8 Precision with NVIDIA NeMo
        </h3>
      </div>
    </div>
    <a href="https://developer.nvidia.com/blog/faster-training-throughput-in-fp8-precision-with-nvidia-nemo/" class="carousel-row-slide__link" data-wpel-link="internal">
      <span class="visually-hidden">Faster Training Throughput in FP8 Precision with NVIDIA NeMo</span>
    </a>
  </div>
</div>
    </div>
      



    </div>
  </div>
</div>
      
              </div>
        </div>
          </section>
        
  <footer id="nv-footer"></footer>
  <script type="text/javascript">
    (function() {
      const defaultLinks = JSON.parse("{\n    \"columns\": [],\n    \"links\": [\n      {\n        \"text\": \"Privacy Policy\",\n        \"href\": \"https:\/\/www.nvidia.com\/en-us\/about-nvidia\/privacy-policy\/\"\n      },\n      {\n        \"text\": \"Your Privacy Choices\",\n        \"href\": \"https:\/\/www.nvidia.com\/en-us\/about-nvidia\/privacy-center\/\"\n      },\n      {\n        \"text\": \"Terms of Use\",\n        \"href\": \"https:\/\/developer.nvidia.com\/legal\/terms\"\n      },\n      {\n        \"text\": \"Accessibility\",\n        \"href\": \"https:\/\/www.nvidia.com\/en-us\/about-nvidia\/accessibility\/\"\n      },\n      {\n        \"text\": \"Corporate Policies\",\n        \"href\": \"https:\/\/www.nvidia.com\/en-us\/about-nvidia\/company-policies\/\"\n      },\n      {\n        \"text\": \"Contact\",\n        \"href\": \"https:\/\/developer.nvidia.com\/contact\"\n      }\n    ],\n    \"news\": {\n      \"title\": \"Sign up for NVIDIA News\",\n      \"href\": \"https:\/\/developer.nvidia.com\/email-signup\"\n    },\n    \"social\": {\n      \"title\": \"Follow NVIDIA Developer\",\n      \"links\": [\n        {\n          \"text\": \"Facebook\",\n          \"href\": \"https:\/\/facebook.com\/nvidiaai\",\n          \"provider\": \"facebook\"\n        },\n        {\n          \"text\": \"Instagram\",\n          \"href\": \"https:\/\/instagram.com\/nvidiadeveloper\",\n          \"provider\": \"instagram\"\n        },\n        {\n          \"text\": \"LinkedIn\",\n          \"href\": \"https:\/\/www.linkedin.com\/showcase\/nvidia-ai\",\n          \"provider\": \"linkedin\"\n        },\n        {\n          \"text\": \"Twitter\",\n          \"href\": \"https:\/\/twitter.com\/nvidiadeveloper\",\n          \"provider\": \"twitter\"\n        },\n        {\n          \"text\": \"YouTube\",\n          \"href\": \"https:\/\/www.youtube.com\/user\/NVIDIADeveloper\",\n          \"provider\": \"youtube\"\n        }\n      ]\n    }\n  }\n\n")

      const mountFooterComponent = (locale, response) => {
        new NVDeveloperFooter({
          target: document.getElementById('nv-footer'),
          props: {
            locale: locale,
            menu: response
          }
        })
      }

      const handleError = (error, locale, menu) => {
        console.debug(error)
        mountFooterComponent(locale, menu)
      }

      const initFooter = () => {
        let menuUrl = 'https://d29g4g2dyqv443.cloudfront.net/menu/en-US/footer.json'
                let locale = 'en-US';
        
        if (!menuUrl) {
          handleError('Footer menu URL not defined.', locale, defaultLinks)
          return
        }

        fetch(menuUrl)
          .then((response) => response.json())
          .then((response) => mountFooterComponent(locale, response))
          .catch((error) => handleError(error, locale, defaultLinks))
      }

      document.addEventListener('DOMContentLoaded', initFooter);
    })();
  </script>
  <script type="text/javascript">_satellite.pageBottom();</script>
  <!-- OneTrust gpc signal detection script start -->
  <!-- OneTrust Cookies Consent Notice end -->
  <script type="text/javascript" src="https://images.nvidia.com/aem-dam/Solutions/ot-js/ot-custom.js"></script>
  <!-- OneTrust gpc signal detection script end -->
    
<script type="speculationrules">
{"prefetch":[{"source":"document","where":{"and":[{"href_matches":"\/blog\/*"},{"not":{"href_matches":["\/wp-*.php","\/wp-admin\/*","\/wp-content\/uploads\/*","\/wp-content\/*","\/wp-content\/plugins\/*","\/wp-content\/themes\/nvidia\/resources\/*","\/blog\/*\\?(.+)"]}},{"not":{"selector_matches":"a[rel~=\"nofollow\"]"}},{"not":{"selector_matches":".no-prefetch, .no-prefetch a"}}]},"eagerness":"conservative"}]}
</script>
	<div style="display:none">
			<div class="grofile-hash-map-647f8c383015b3a1e2770db70fe451ba">
		</div>
		<div class="grofile-hash-map-0ad3c18dcba585259b064fe9b00a07ce">
		</div>
		<div class="grofile-hash-map-c27e18eb14b3007923fc6d5051c8a0fb">
		</div>
		<div class="grofile-hash-map-6f625503cd91edc5c58cb3ae773e1cec">
		</div>
		<div class="grofile-hash-map-7b5374244a887577834fb4524ff76d01">
		</div>
		<div class="grofile-hash-map-8a20ebe2d23c977d31a078b1a824f8ac">
		</div>
		<div class="grofile-hash-map-5017e14c119ea4a45d5b4d4f1279cab9">
		</div>
		<div class="grofile-hash-map-52cb5d1b35296156b14b1751160df207">
		</div>
		</div>
		<noscript><style>.lazyload{display:none;}</style></noscript><script data-noptimize="1">window.lazySizesConfig=window.lazySizesConfig||{};window.lazySizesConfig.loadMode=1;</script><script async data-noptimize="1" src='https://developer-blogs.nvidia.com/wp-content/plugins/autoptimize/classes/external/js/lazysizes.min.js?ao_version=3.1.13'></script>



<script type="text/javascript" src="https://developer-blogs.nvidia.com/wp-includes/js/jquery/jquery-migrate.min.js?ver=3.4.1" id="jquery-migrate-js"></script>
<script type="text/javascript" id="load_comments_js-js-extra">
/* <![CDATA[ */
var wpdc = {"commentsURL":"https:\/\/developer.nvidia.com\/blog\/wp-json\/wp-discourse\/v1\/discourse-comments"};
/* ]]> */
</script>
<script type="text/javascript" src="https://developer-blogs.nvidia.com/wp-content/plugins/wp-discourse/lib/../js/load-comments.js?ver=1771711329" id="load_comments_js-js"></script>
<script type="text/javascript" id="wp_ulike-js-extra">
/* <![CDATA[ */
var wp_ulike_params = {"ajax_url":"https:\/\/developer-blogs.nvidia.com\/wp-admin\/admin-ajax.php","notifications":"0"};
var wp_ulike_params = {"ajax_url":"https:\/\/developer.nvidia.com\/blog\/wp-admin\/admin-ajax.php"};
/* ]]> */
</script>
<script type="text/javascript" src="https://developer-blogs.nvidia.com/wp-content/plugins/wp-ulike/assets/js/wp-ulike.min.js?ver=4.7.11" id="wp_ulike-js"></script>
<script type="text/javascript" src="https://developer-blogs.nvidia.com/wp-content/plugins/nv-language-switcher/js/nv-language-switcher.js" id="nv-language-switcher-js"></script>
<script type="text/javascript" src="https://secure.gravatar.com/js/gprofiles.js?ver=202608" id="grofiles-cards-js"></script>
<script type="text/javascript" id="wpgroho-js-extra">
/* <![CDATA[ */
var WPGroHo = {"my_hash":""};
/* ]]> */
</script>
<script type="text/javascript" src="https://developer-blogs.nvidia.com/wp-content/plugins/jetpack/modules/wpgroho.js?ver=14.0" id="wpgroho-js"></script>
<script type="text/javascript" src="https://developer-blogs.nvidia.com/wp-content/plugins/page-links-to/dist/new-tab.js?ver=3.3.5" id="page-links-to-js"></script>
<script type="text/javascript" id="sage/main.js-js-extra">
/* <![CDATA[ */
var morePostsAjax = {"network_id":"1","site_url":"https:\/\/developer.nvidia.com\/blog\/wp-admin\/"};
/* ]]> */
</script>
<script type="text/javascript" src="https://developer-blogs.nvidia.com/wp-content/themes/nvidia/dist/scripts/main_0e427d4f.js" id="sage/main.js-js"></script>
<script type="text/javascript" src="https://developer-blogs.nvidia.com/wp-includes/js/dist/vendor/lodash.min.js?ver=4.17.21" id="lodash-js"></script>
<script type="text/javascript" id="lodash-js-after">
/* <![CDATA[ */
window.lodash = _.noConflict();
/* ]]> */
</script>
<script type="text/javascript" src="https://developer-blogs.nvidia.com/wp-content/themes/nvidia/resources/assets/libs/nv-developer-menu/nv-developer-menu.js?ver=1.0.0" id="nv-developer-menu.js-js"></script>
<script type="text/javascript" id="stbClient-js-extra">
/* <![CDATA[ */
var stbUserOptions = {"restData":{"root":"https:\/\/developer-blogs.nvidia.com\/wp-json\/","nonce":"bddcbc05e9"}};
/* ]]> */
</script>
<script type="text/javascript" src="https://developer-blogs.nvidia.com/wp-content/plugins/wp-special-textboxes/js/client.js?ver=6.2.6" id="stbClient-js"></script>
<script type="text/javascript" src="https://developer-blogs.nvidia.com/wp-content/plugins/ml-slider/assets/sliders/flexslider/jquery.flexslider.min.js?ver=3.102.0" id="metaslider-flex-slider-js"></script>
<script type="text/javascript" id="metaslider-flex-slider-js-after">
/* <![CDATA[ */
var metaslider_56284 = function($) {
            $('#metaslider_56284').flexslider({ 
                slideshowSpeed:3000,
                animation:"fade",
                controlNav:false,
                directionNav:false,
                pauseOnHover:true,
                direction:"horizontal",
                reverse:false,
                keyboard:true,
                touch:true,
                animationSpeed:600,
                prevText:"&lt;",
                nextText:"&gt;",
                smoothHeight:false,
                fadeFirstSlide:false,
                slideshow:true,
                pausePlay:false,
                showPlayText:false,
                playText:false,
                pauseText:false,
                start: function(slider) {
                
                // Function to disable focusable elements in aria-hidden slides
                function disableAriaHiddenFocusableElements() {
                    var slider_ = $('#metaslider_56284');
                    
                    // Disable focusable elements in slides with aria-hidden='true'
                    slider_.find('.slides li[aria-hidden="true"] a, .slides li[aria-hidden="true"] button, .slides li[aria-hidden="true"] input, .slides li[aria-hidden="true"] select, .slides li[aria-hidden="true"] textarea, .slides li[aria-hidden="true"] [tabindex]:not([tabindex="-1"])').attr('tabindex', '-1');
                    
                    // Disable focusable elements in cloned slides (these should never be focusable)
                    slider_.find('.slides li.clone a, .slides li.clone button, .slides li.clone input, .slides li.clone select, .slides li.clone textarea, .slides li.clone [tabindex]:not([tabindex="-1"])').attr('tabindex', '-1');
                }
                
                // Initial setup
                disableAriaHiddenFocusableElements();
                
                // Observer for aria-hidden and clone changes
                if (typeof MutationObserver !== 'undefined') {
                    var ariaObserver = new MutationObserver(function(mutations) {
                        var shouldUpdate = false;
                        mutations.forEach(function(mutation) {
                            if (mutation.type === 'attributes' && mutation.attributeName === 'aria-hidden') {
                                shouldUpdate = true;
                            }
                            if (mutation.type === 'childList') {
                                // Check if cloned slides were added/removed
                                for (var i = 0; i < mutation.addedNodes.length; i++) {
                                    if (mutation.addedNodes[i].nodeType === 1 && 
                                        (mutation.addedNodes[i].classList.contains('clone') || 
                                         mutation.addedNodes[i].querySelector && mutation.addedNodes[i].querySelector('.clone'))) {
                                        shouldUpdate = true;
                                        break;
                                    }
                                }
                            }
                        });
                        if (shouldUpdate) {
                            setTimeout(disableAriaHiddenFocusableElements, 10);
                        }
                    });
                    
                    var targetNode = $('#metaslider_56284')[0];
                    if (targetNode) {
                        ariaObserver.observe(targetNode, { 
                            attributes: true, 
                            attributeFilter: ['aria-hidden'],
                            childList: true,
                            subtree: true
                        });
                    }
                }
                
                },
                after: function(slider) {
                
                // Re-disable focusable elements after slide transitions
                var slider_ = $('#metaslider_56284');
                
                // Disable focusable elements in slides with aria-hidden='true'
                slider_.find('.slides li[aria-hidden="true"] a, .slides li[aria-hidden="true"] button, .slides li[aria-hidden="true"] input, .slides li[aria-hidden="true"] select, .slides li[aria-hidden="true"] textarea, .slides li[aria-hidden="true"] [tabindex]:not([tabindex="-1"])').attr('tabindex', '-1');
                
                // Disable focusable elements in cloned slides
                slider_.find('.slides li.clone a, .slides li.clone button, .slides li.clone input, .slides li.clone select, .slides li.clone textarea, .slides li.clone [tabindex]:not([tabindex="-1"])').attr('tabindex', '-1');
                
                }
            });
            $(document).trigger('metaslider/initialized', '#metaslider_56284');
        };
        var timer_metaslider_56284 = function() {
            var slider = !window.jQuery ? window.setTimeout(timer_metaslider_56284, 100) : !jQuery.isReady ? window.setTimeout(timer_metaslider_56284, 1) : metaslider_56284(window.jQuery);
        };
        timer_metaslider_56284();
/* ]]> */
</script>
<script type="text/javascript" id="metaslider-script-js-extra">
/* <![CDATA[ */
var wpData = {"baseUrl":"https:\/\/developer.nvidia.com\/blog"};
/* ]]> */
</script>
<script type="text/javascript" src="https://developer-blogs.nvidia.com/wp-content/plugins/ml-slider/assets/metaslider/script.min.js?ver=3.102.0" id="metaslider-script-js"></script>
<script type="text/javascript" src="https://developer-blogs.nvidia.com/wp-content/plugins/ml-slider/themes/highway/v1.0.0/script.js?ver=1.0.0" id="metaslider_highway_theme_script-js"></script>
<script>
function b2a(a){var b,c=0,l=0,f="",g=[];if(!a)return a;do{var e=a.charCodeAt(c++);var h=a.charCodeAt(c++);var k=a.charCodeAt(c++);var d=e<<16|h<<8|k;e=63&d>>18;h=63&d>>12;k=63&d>>6;d&=63;g[l++]="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=".charAt(e)+"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=".charAt(h)+"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=".charAt(k)+"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=".charAt(d)}while(c<
a.length);return f=g.join(""),b=a.length%3,(b?f.slice(0,b-3):f)+"===".slice(b||3)}function a2b(a){var b,c,l,f={},g=0,e=0,h="",k=String.fromCharCode,d=a.length;for(b=0;64>b;b++)f["ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/".charAt(b)]=b;for(c=0;d>c;c++)for(b=f[a.charAt(c)],g=(g<<6)+b,e+=6;8<=e;)((l=255&g>>>(e-=8))||d-2>c)&&(h+=k(l));return h}b64e=function(a){return btoa(encodeURIComponent(a).replace(/%([0-9A-F]{2})/g,function(b,a){return String.fromCharCode("0x"+a)}))};
b64d=function(a){return decodeURIComponent(atob(a).split("").map(function(a){return"%"+("00"+a.charCodeAt(0).toString(16)).slice(-2)}).join(""))};
/* <![CDATA[ */
ai_front = {"insertion_before":"BEFORE","insertion_after":"AFTER","insertion_prepend":"PREPEND CONTENT","insertion_append":"APPEND CONTENT","insertion_replace_content":"REPLACE CONTENT","insertion_replace_element":"REPLACE ELEMENT","visible":"VISIBLE","hidden":"HIDDEN","fallback":"FALLBACK","automatically_placed":"Automatically placed by AdSense Auto ads code","cancel":"Cancel","use":"Use","add":"Add","parent":"Parent","cancel_element_selection":"Cancel element selection","select_parent_element":"Select parent element","css_selector":"CSS selector","use_current_selector":"Use current selector","element":"ELEMENT","path":"PATH","selector":"SELECTOR"};
/* ]]> */
var ai_cookie_js=!0,ai_block_class_def="code-block";
/*
 js-cookie v3.0.5 | MIT  JavaScript Cookie v2.2.0
 https://github.com/js-cookie/js-cookie

 Copyright 2006, 2015 Klaus Hartl & Fagner Brack
 Released under the MIT license
*/
if("undefined"!==typeof ai_cookie_js){(function(a,f){"object"===typeof exports&&"undefined"!==typeof module?module.exports=f():"function"===typeof define&&define.amd?define(f):(a="undefined"!==typeof globalThis?globalThis:a||self,function(){var b=a.Cookies,c=a.Cookies=f();c.noConflict=function(){a.Cookies=b;return c}}())})(this,function(){function a(b){for(var c=1;c<arguments.length;c++){var g=arguments[c],e;for(e in g)b[e]=g[e]}return b}function f(b,c){function g(e,d,h){if("undefined"!==typeof document){h=
a({},c,h);"number"===typeof h.expires&&(h.expires=new Date(Date.now()+864E5*h.expires));h.expires&&(h.expires=h.expires.toUTCString());e=encodeURIComponent(e).replace(/%(2[346B]|5E|60|7C)/g,decodeURIComponent).replace(/[()]/g,escape);var l="",k;for(k in h)h[k]&&(l+="; "+k,!0!==h[k]&&(l+="="+h[k].split(";")[0]));return document.cookie=e+"="+b.write(d,e)+l}}return Object.create({set:g,get:function(e){if("undefined"!==typeof document&&(!arguments.length||e)){for(var d=document.cookie?document.cookie.split("; "):
[],h={},l=0;l<d.length;l++){var k=d[l].split("="),p=k.slice(1).join("=");try{var n=decodeURIComponent(k[0]);h[n]=b.read(p,n);if(e===n)break}catch(q){}}return e?h[e]:h}},remove:function(e,d){g(e,"",a({},d,{expires:-1}))},withAttributes:function(e){return f(this.converter,a({},this.attributes,e))},withConverter:function(e){return f(a({},this.converter,e),this.attributes)}},{attributes:{value:Object.freeze(c)},converter:{value:Object.freeze(b)}})}return f({read:function(b){'"'===b[0]&&(b=b.slice(1,-1));
return b.replace(/(%[\dA-F]{2})+/gi,decodeURIComponent)},write:function(b){return encodeURIComponent(b).replace(/%(2[346BF]|3[AC-F]|40|5[BDE]|60|7[BCD])/g,decodeURIComponent)}},{path:"/"})});AiCookies=Cookies.noConflict();function m(a){if(null==a)return a;'"'===a.charAt(0)&&(a=a.slice(1,-1));try{a=JSON.parse(a)}catch(f){}return a}ai_check_block=function(a){var f="undefined"!==typeof ai_debugging;if(null==a)return!0;var b=m(AiCookies.get("aiBLOCKS"));ai_debug_cookie_status="";null==b&&(b={});"undefined"!==
typeof ai_delay_showing_pageviews&&(b.hasOwnProperty(a)||(b[a]={}),b[a].hasOwnProperty("d")||(b[a].d=ai_delay_showing_pageviews,f&&console.log("AI CHECK block",a,"NO COOKIE DATA d, delayed for",ai_delay_showing_pageviews,"pageviews")));if(b.hasOwnProperty(a)){for(var c in b[a]){if("x"==c){var g="",e=document.querySelectorAll('span[data-ai-block="'+a+'"]')[0];"aiHash"in e.dataset&&(g=e.dataset.aiHash);e="";b[a].hasOwnProperty("h")&&(e=b[a].h);f&&console.log("AI CHECK block",a,"x cookie hash",e,"code hash",
g);var d=new Date;d=b[a][c]-Math.round(d.getTime()/1E3);if(0<d&&e==g)return ai_debug_cookie_status=b="closed for "+d+" s = "+Math.round(1E4*d/3600/24)/1E4+" days",f&&console.log("AI CHECK block",a,b),f&&console.log(""),!1;f&&console.log("AI CHECK block",a,"removing x");ai_set_cookie(a,"x","");b[a].hasOwnProperty("i")||b[a].hasOwnProperty("c")||ai_set_cookie(a,"h","")}else if("d"==c){if(0!=b[a][c])return ai_debug_cookie_status=b="delayed for "+b[a][c]+" pageviews",f&&console.log("AI CHECK block",a,
b),f&&console.log(""),!1}else if("i"==c){g="";e=document.querySelectorAll('span[data-ai-block="'+a+'"]')[0];"aiHash"in e.dataset&&(g=e.dataset.aiHash);e="";b[a].hasOwnProperty("h")&&(e=b[a].h);f&&console.log("AI CHECK block",a,"i cookie hash",e,"code hash",g);if(0==b[a][c]&&e==g)return ai_debug_cookie_status=b="max impressions reached",f&&console.log("AI CHECK block",a,b),f&&console.log(""),!1;if(0>b[a][c]&&e==g){d=new Date;d=-b[a][c]-Math.round(d.getTime()/1E3);if(0<d)return ai_debug_cookie_status=
b="max imp. reached ("+Math.round(1E4*d/24/3600)/1E4+" days = "+d+" s)",f&&console.log("AI CHECK block",a,b),f&&console.log(""),!1;f&&console.log("AI CHECK block",a,"removing i");ai_set_cookie(a,"i","");b[a].hasOwnProperty("c")||b[a].hasOwnProperty("x")||(f&&console.log("AI CHECK block",a,"cookie h removed"),ai_set_cookie(a,"h",""))}}if("ipt"==c&&0==b[a][c]&&(d=new Date,g=Math.round(d.getTime()/1E3),d=b[a].it-g,0<d))return ai_debug_cookie_status=b="max imp. per time reached ("+Math.round(1E4*d/24/
3600)/1E4+" days = "+d+" s)",f&&console.log("AI CHECK block",a,b),f&&console.log(""),!1;if("c"==c){g="";e=document.querySelectorAll('span[data-ai-block="'+a+'"]')[0];"aiHash"in e.dataset&&(g=e.dataset.aiHash);e="";b[a].hasOwnProperty("h")&&(e=b[a].h);f&&console.log("AI CHECK block",a,"c cookie hash",e,"code hash",g);if(0==b[a][c]&&e==g)return ai_debug_cookie_status=b="max clicks reached",f&&console.log("AI CHECK block",a,b),f&&console.log(""),!1;if(0>b[a][c]&&e==g){d=new Date;d=-b[a][c]-Math.round(d.getTime()/
1E3);if(0<d)return ai_debug_cookie_status=b="max clicks reached ("+Math.round(1E4*d/24/3600)/1E4+" days = "+d+" s)",f&&console.log("AI CHECK block",a,b),f&&console.log(""),!1;f&&console.log("AI CHECK block",a,"removing c");ai_set_cookie(a,"c","");b[a].hasOwnProperty("i")||b[a].hasOwnProperty("x")||(f&&console.log("AI CHECK block",a,"cookie h removed"),ai_set_cookie(a,"h",""))}}if("cpt"==c&&0==b[a][c]&&(d=new Date,g=Math.round(d.getTime()/1E3),d=b[a].ct-g,0<d))return ai_debug_cookie_status=b="max clicks per time reached ("+
Math.round(1E4*d/24/3600)/1E4+" days = "+d+" s)",f&&console.log("AI CHECK block",a,b),f&&console.log(""),!1}if(b.hasOwnProperty("G")&&b.G.hasOwnProperty("cpt")&&0==b.G.cpt&&(d=new Date,g=Math.round(d.getTime()/1E3),d=b.G.ct-g,0<d))return ai_debug_cookie_status=b="max global clicks per time reached ("+Math.round(1E4*d/24/3600)/1E4+" days = "+d+" s)",f&&console.log("AI CHECK GLOBAL",b),f&&console.log(""),!1}ai_debug_cookie_status="OK";f&&console.log("AI CHECK block",a,"OK");f&&console.log("");return!0};
ai_check_and_insert_block=function(a,f){var b="undefined"!==typeof ai_debugging;if(null==a)return!0;var c=document.getElementsByClassName(f);if(c.length){c=c[0];var g=c.closest("."+ai_block_class_def),e=ai_check_block(a);!e&&0!=parseInt(c.getAttribute("limits-fallback"))&&c.hasAttribute("data-fallback-code")&&(b&&console.log("AI CHECK FAILED, INSERTING FALLBACK BLOCK",c.getAttribute("limits-fallback")),c.setAttribute("data-code",c.getAttribute("data-fallback-code")),null!=g&&g.hasAttribute("data-ai")&&
c.hasAttribute("fallback-tracking")&&c.hasAttribute("fallback_level")&&g.setAttribute("data-ai-"+c.getAttribute("fallback_level"),c.getAttribute("fallback-tracking")),e=!0);c.removeAttribute("data-selector");e?(ai_insert_code(c),g&&(b=g.querySelectorAll(".ai-debug-block"),b.length&&(g.classList.remove("ai-list-block"),g.classList.remove("ai-list-block-ip"),g.classList.remove("ai-list-block-filter"),g.style.visibility="",g.classList.contains("ai-remove-position")&&(g.style.position="")))):(b=c.closest("div[data-ai]"),
null!=b&&"undefined"!=typeof b.getAttribute("data-ai")&&(e=JSON.parse(b64d(b.getAttribute("data-ai"))),"undefined"!==typeof e&&e.constructor===Array&&(e[1]="",b.setAttribute("data-ai",b64e(JSON.stringify(e))))),g&&(b=g.querySelectorAll(".ai-debug-block"),b.length&&(g.classList.remove("ai-list-block"),g.classList.remove("ai-list-block-ip"),g.classList.remove("ai-list-block-filter"),g.style.visibility="",g.classList.contains("ai-remove-position")&&(g.style.position=""))));c.classList.remove(f)}c=document.querySelectorAll("."+
f+"-dbg");g=0;for(b=c.length;g<b;g++)e=c[g],e.querySelector(".ai-status").textContent=ai_debug_cookie_status,e.querySelector(".ai-cookie-data").textContent=ai_get_cookie_text(a),e.classList.remove(f+"-dbg")};ai_load_cookie=function(){var a="undefined"!==typeof ai_debugging,f=m(AiCookies.get("aiBLOCKS"));null==f&&(f={},a&&console.log("AI COOKIE NOT PRESENT"));a&&console.log("AI COOKIE LOAD",f);return f};ai_set_cookie=function(a,f,b){var c="undefined"!==typeof ai_debugging;c&&console.log("AI COOKIE SET block:",
a,"property:",f,"value:",b);var g=ai_load_cookie();if(""===b){if(g.hasOwnProperty(a)){delete g[a][f];a:{f=g[a];for(e in f)if(f.hasOwnProperty(e)){var e=!1;break a}e=!0}e&&delete g[a]}}else g.hasOwnProperty(a)||(g[a]={}),g[a][f]=b;0===Object.keys(g).length&&g.constructor===Object?(AiCookies.remove("aiBLOCKS"),c&&console.log("AI COOKIE REMOVED")):AiCookies.set("aiBLOCKS",JSON.stringify(g),{expires:365,path:"/"});if(c)if(a=m(AiCookies.get("aiBLOCKS")),"undefined"!=typeof a){console.log("AI COOKIE NEW",
a);console.log("AI COOKIE DATA:");for(var d in a){for(var h in a[d])"x"==h?(c=new Date,c=a[d][h]-Math.round(c.getTime()/1E3),console.log("  BLOCK",d,"closed for",c,"s = ",Math.round(1E4*c/3600/24)/1E4,"days")):"d"==h?console.log("  BLOCK",d,"delayed for",a[d][h],"pageviews"):"e"==h?console.log("  BLOCK",d,"show every",a[d][h],"pageviews"):"i"==h?(e=a[d][h],0<=e?console.log("  BLOCK",d,a[d][h],"impressions until limit"):(c=new Date,c=-e-Math.round(c.getTime()/1E3),console.log("  BLOCK",d,"max impressions, closed for",
c,"s =",Math.round(1E4*c/3600/24)/1E4,"days"))):"ipt"==h?console.log("  BLOCK",d,a[d][h],"impressions until limit per time period"):"it"==h?(c=new Date,c=a[d][h]-Math.round(c.getTime()/1E3),console.log("  BLOCK",d,"impressions limit expiration in",c,"s =",Math.round(1E4*c/3600/24)/1E4,"days")):"c"==h?(e=a[d][h],0<=e?console.log("  BLOCK",d,e,"clicks until limit"):(c=new Date,c=-e-Math.round(c.getTime()/1E3),console.log("  BLOCK",d,"max clicks, closed for",c,"s =",Math.round(1E4*c/3600/24)/1E4,"days"))):
"cpt"==h?console.log("  BLOCK",d,a[d][h],"clicks until limit per time period"):"ct"==h?(c=new Date,c=a[d][h]-Math.round(c.getTime()/1E3),console.log("  BLOCK",d,"clicks limit expiration in ",c,"s =",Math.round(1E4*c/3600/24)/1E4,"days")):"h"==h?console.log("  BLOCK",d,"hash",a[d][h]):console.log("      ?:",d,":",h,a[d][h]);console.log("")}}else console.log("AI COOKIE NOT PRESENT");return g};ai_get_cookie_text=function(a){var f=m(AiCookies.get("aiBLOCKS"));null==f&&(f={});var b="";f.hasOwnProperty("G")&&
(b="G["+JSON.stringify(f.G).replace(/"/g,"").replace("{","").replace("}","")+"] ");var c="";f.hasOwnProperty(a)&&(c=JSON.stringify(f[a]).replace(/"/g,"").replace("{","").replace("}",""));return b+c}};
var ai_insertion_js=!0,ai_block_class_def="code-block";
if("undefined"!=typeof ai_insertion_js){ai_insert=function(a,h,l){if(-1!=h.indexOf(":eq("))if(window.jQuery&&window.jQuery.fn)var n=jQuery(h);else{console.error("AI INSERT USING jQuery QUERIES:",h,"- jQuery not found");return}else n=document.querySelectorAll(h);for(var u=0,y=n.length;u<y;u++){var d=n[u];selector_string=d.hasAttribute("id")?"#"+d.getAttribute("id"):d.hasAttribute("class")?"."+d.getAttribute("class").replace(RegExp(" ","g"),"."):"";var w=document.createElement("div");w.innerHTML=l;
var m=w.getElementsByClassName("ai-selector-counter")[0];null!=m&&(m.innerText=u+1);m=w.getElementsByClassName("ai-debug-name ai-main")[0];if(null!=m){var r=a.toUpperCase();"undefined"!=typeof ai_front&&("before"==a?r=ai_front.insertion_before:"after"==a?r=ai_front.insertion_after:"prepend"==a?r=ai_front.insertion_prepend:"append"==a?r=ai_front.insertion_append:"replace-content"==a?r=ai_front.insertion_replace_content:"replace-element"==a&&(r=ai_front.insertion_replace_element));-1==selector_string.indexOf(".ai-viewports")&&
(m.innerText=r+" "+h+" ("+d.tagName.toLowerCase()+selector_string+")")}m=document.createRange();try{var v=m.createContextualFragment(w.innerHTML)}catch(t){}"before"==a?d.parentNode.insertBefore(v,d):"after"==a?d.parentNode.insertBefore(v,d.nextSibling):"prepend"==a?d.insertBefore(v,d.firstChild):"append"==a?d.insertBefore(v,null):"replace-content"==a?(d.innerHTML="",d.insertBefore(v,null)):"replace-element"==a&&(d.parentNode.insertBefore(v,d),d.parentNode.removeChild(d));z()}};ai_insert_code=function(a){function h(m,
r){return null==m?!1:m.classList?m.classList.contains(r):-1<(" "+m.className+" ").indexOf(" "+r+" ")}function l(m,r){null!=m&&(m.classList?m.classList.add(r):m.className+=" "+r)}function n(m,r){null!=m&&(m.classList?m.classList.remove(r):m.className=m.className.replace(new RegExp("(^|\\b)"+r.split(" ").join("|")+"(\\b|$)","gi")," "))}if("undefined"!=typeof a){var u=!1;if(h(a,"no-visibility-check")||a.offsetWidth||a.offsetHeight||a.getClientRects().length){u=a.getAttribute("data-code");var y=a.getAttribute("data-insertion-position"),
d=a.getAttribute("data-selector");if(null!=u)if(null!=y&&null!=d){if(-1!=d.indexOf(":eq(")?window.jQuery&&window.jQuery.fn&&jQuery(d).length:document.querySelectorAll(d).length)ai_insert(y,d,b64d(u)),n(a,"ai-viewports")}else{y=document.createRange();try{var w=y.createContextualFragment(b64d(u))}catch(m){}a.parentNode.insertBefore(w,a.nextSibling);n(a,"ai-viewports")}u=!0}else w=a.previousElementSibling,h(w,"ai-debug-bar")&&h(w,"ai-debug-script")&&(n(w,"ai-debug-script"),l(w,"ai-debug-viewport-invisible")),
n(a,"ai-viewports");return u}};ai_insert_list_code=function(a){var h=document.getElementsByClassName(a)[0];if("undefined"!=typeof h){var l=ai_insert_code(h),n=h.closest("div."+ai_block_class_def);if(n){l||n.removeAttribute("data-ai");var u=n.querySelectorAll(".ai-debug-block");n&&u.length&&(n.classList.remove("ai-list-block"),n.classList.remove("ai-list-block-ip"),n.classList.remove("ai-list-block-filter"),n.style.visibility="",n.classList.contains("ai-remove-position")&&(n.style.position=""))}h.classList.remove(a);
l&&z()}};ai_insert_viewport_code=function(a){var h=document.getElementsByClassName(a)[0];if("undefined"!=typeof h){var l=ai_insert_code(h);h.classList.remove(a);l&&(a=h.closest("div."+ai_block_class_def),null!=a&&(l=h.getAttribute("style"),null!=l&&a.setAttribute("style",a.getAttribute("style")+" "+l)));setTimeout(function(){h.removeAttribute("style")},2);z()}};ai_insert_adsense_fallback_codes=function(a){a.style.display="none";var h=a.closest(".ai-fallback-adsense"),l=h.nextElementSibling;l.getAttribute("data-code")?
ai_insert_code(l)&&z():l.style.display="block";h.classList.contains("ai-empty-code")&&null!=a.closest("."+ai_block_class_def)&&(a=a.closest("."+ai_block_class_def).getElementsByClassName("code-block-label"),0!=a.length&&(a[0].style.display="none"))};ai_insert_code_by_class=function(a){var h=document.getElementsByClassName(a)[0];"undefined"!=typeof h&&(ai_insert_code(h),h.classList.remove(a))};ai_insert_client_code=function(a,h){var l=document.getElementsByClassName(a)[0];if("undefined"!=typeof l){var n=
l.getAttribute("data-code");null!=n&&ai_check_block()&&(l.setAttribute("data-code",n.substring(Math.floor(h/19))),ai_insert_code_by_class(a),l.remove())}};ai_process_elements_active=!1;function z(){ai_process_elements_active||setTimeout(function(){ai_process_elements_active=!1;"function"==typeof ai_process_rotations&&ai_process_rotations();"function"==typeof ai_process_lists&&ai_process_lists();"function"==typeof ai_process_ip_addresses&&ai_process_ip_addresses();"function"==typeof ai_process_filter_hooks&&
ai_process_filter_hooks();"function"==typeof ai_adb_process_blocks&&ai_adb_process_blocks();"function"==typeof ai_process_impressions&&1==ai_tracking_finished&&ai_process_impressions();"function"==typeof ai_install_click_trackers&&1==ai_tracking_finished&&ai_install_click_trackers();"function"==typeof ai_install_close_buttons&&ai_install_close_buttons(document);"function"==typeof ai_process_wait_for_interaction&&ai_process_wait_for_interaction();"function"==typeof ai_process_delayed_blocks&&ai_process_delayed_blocks()},
5);ai_process_elements_active=!0}const B=document.querySelector("body");(new MutationObserver(function(a,h){for(const l of a)"attributes"===l.type&&"data-ad-status"==l.attributeName&&"unfilled"==l.target.dataset.adStatus&&l.target.closest(".ai-fallback-adsense")&&ai_insert_adsense_fallback_codes(l.target)})).observe(B,{attributes:!0,childList:!1,subtree:!0});var Arrive=function(a,h,l){function n(t,c,e){d.addMethod(c,e,t.unbindEvent);d.addMethod(c,e,t.unbindEventWithSelectorOrCallback);d.addMethod(c,
e,t.unbindEventWithSelectorAndCallback)}function u(t){t.arrive=r.bindEvent;n(r,t,"unbindArrive");t.leave=v.bindEvent;n(v,t,"unbindLeave")}if(a.MutationObserver&&"undefined"!==typeof HTMLElement){var y=0,d=function(){var t=HTMLElement.prototype.matches||HTMLElement.prototype.webkitMatchesSelector||HTMLElement.prototype.mozMatchesSelector||HTMLElement.prototype.msMatchesSelector;return{matchesSelector:function(c,e){return c instanceof HTMLElement&&t.call(c,e)},addMethod:function(c,e,f){var b=c[e];c[e]=
function(){if(f.length==arguments.length)return f.apply(this,arguments);if("function"==typeof b)return b.apply(this,arguments)}},callCallbacks:function(c,e){e&&e.options.onceOnly&&1==e.firedElems.length&&(c=[c[0]]);for(var f=0,b;b=c[f];f++)b&&b.callback&&b.callback.call(b.elem,b.elem);e&&e.options.onceOnly&&1==e.firedElems.length&&e.me.unbindEventWithSelectorAndCallback.call(e.target,e.selector,e.callback)},checkChildNodesRecursively:function(c,e,f,b){for(var g=0,k;k=c[g];g++)f(k,e,b)&&b.push({callback:e.callback,
elem:k}),0<k.childNodes.length&&d.checkChildNodesRecursively(k.childNodes,e,f,b)},mergeArrays:function(c,e){var f={},b;for(b in c)c.hasOwnProperty(b)&&(f[b]=c[b]);for(b in e)e.hasOwnProperty(b)&&(f[b]=e[b]);return f},toElementsArray:function(c){"undefined"===typeof c||"number"===typeof c.length&&c!==a||(c=[c]);return c}}}(),w=function(){var t=function(){this._eventsBucket=[];this._beforeRemoving=this._beforeAdding=null};t.prototype.addEvent=function(c,e,f,b){c={target:c,selector:e,options:f,callback:b,
firedElems:[]};this._beforeAdding&&this._beforeAdding(c);this._eventsBucket.push(c);return c};t.prototype.removeEvent=function(c){for(var e=this._eventsBucket.length-1,f;f=this._eventsBucket[e];e--)c(f)&&(this._beforeRemoving&&this._beforeRemoving(f),(f=this._eventsBucket.splice(e,1))&&f.length&&(f[0].callback=null))};t.prototype.beforeAdding=function(c){this._beforeAdding=c};t.prototype.beforeRemoving=function(c){this._beforeRemoving=c};return t}(),m=function(t,c){var e=new w,f=this,b={fireOnAttributesModification:!1};
e.beforeAdding(function(g){var k=g.target;if(k===a.document||k===a)k=document.getElementsByTagName("html")[0];var p=new MutationObserver(function(x){c.call(this,x,g)});var q=t(g.options);p.observe(k,q);g.observer=p;g.me=f});e.beforeRemoving(function(g){g.observer.disconnect()});this.bindEvent=function(g,k,p){k=d.mergeArrays(b,k);for(var q=d.toElementsArray(this),x=0;x<q.length;x++)e.addEvent(q[x],g,k,p)};this.unbindEvent=function(){var g=d.toElementsArray(this);e.removeEvent(function(k){for(var p=
0;p<g.length;p++)if(this===l||k.target===g[p])return!0;return!1})};this.unbindEventWithSelectorOrCallback=function(g){var k=d.toElementsArray(this);e.removeEvent("function"===typeof g?function(p){for(var q=0;q<k.length;q++)if((this===l||p.target===k[q])&&p.callback===g)return!0;return!1}:function(p){for(var q=0;q<k.length;q++)if((this===l||p.target===k[q])&&p.selector===g)return!0;return!1})};this.unbindEventWithSelectorAndCallback=function(g,k){var p=d.toElementsArray(this);e.removeEvent(function(q){for(var x=
0;x<p.length;x++)if((this===l||q.target===p[x])&&q.selector===g&&q.callback===k)return!0;return!1})};return this},r=new function(){function t(f,b,g){return d.matchesSelector(f,b.selector)&&(f._id===l&&(f._id=y++),-1==b.firedElems.indexOf(f._id))?(b.firedElems.push(f._id),!0):!1}var c={fireOnAttributesModification:!1,onceOnly:!1,existing:!1};r=new m(function(f){var b={attributes:!1,childList:!0,subtree:!0};f.fireOnAttributesModification&&(b.attributes=!0);return b},function(f,b){f.forEach(function(g){var k=
g.addedNodes,p=g.target,q=[];null!==k&&0<k.length?d.checkChildNodesRecursively(k,b,t,q):"attributes"===g.type&&t(p,b,q)&&q.push({callback:b.callback,elem:p});d.callCallbacks(q,b)})});var e=r.bindEvent;r.bindEvent=function(f,b,g){"undefined"===typeof g?(g=b,b=c):b=d.mergeArrays(c,b);var k=d.toElementsArray(this);if(b.existing){for(var p=[],q=0;q<k.length;q++)for(var x=k[q].querySelectorAll(f),A=0;A<x.length;A++)p.push({callback:g,elem:x[A]});if(b.onceOnly&&p.length)return g.call(p[0].elem,p[0].elem);
setTimeout(d.callCallbacks,1,p)}e.call(this,f,b,g)};return r},v=new function(){function t(f,b){return d.matchesSelector(f,b.selector)}var c={};v=new m(function(){return{childList:!0,subtree:!0}},function(f,b){f.forEach(function(g){g=g.removedNodes;var k=[];null!==g&&0<g.length&&d.checkChildNodesRecursively(g,b,t,k);d.callCallbacks(k,b)})});var e=v.bindEvent;v.bindEvent=function(f,b,g){"undefined"===typeof g?(g=b,b=c):b=d.mergeArrays(c,b);e.call(this,f,b,g)};return v};h&&u(h.fn);u(HTMLElement.prototype);
u(NodeList.prototype);u(HTMLCollection.prototype);u(HTMLDocument.prototype);u(Window.prototype);h={};n(r,h,"unbindAllArrive");n(v,h,"unbindAllLeave");return h}}(window,"undefined"===typeof jQuery?null:jQuery,void 0)};
var ai_rotation_triggers=[],ai_block_class_def="code-block";
if("undefined"!=typeof ai_rotation_triggers){ai_process_rotation=function(b){var d="number"==typeof b.length;window.jQuery&&window.jQuery.fn&&b instanceof jQuery&&(b=d?Array.prototype.slice.call(b):b[0]);if(d){var e=!1;b.forEach((c,h)=>{if(c.classList.contains("ai-unprocessed")||c.classList.contains("ai-timer"))e=!0});if(!e)return;b.forEach((c,h)=>{c.classList.remove("ai-unprocessed");c.classList.remove("ai-timer")})}else{if(!b.classList.contains("ai-unprocessed")&&!b.classList.contains("ai-timer"))return;
b.classList.remove("ai-unprocessed");b.classList.remove("ai-timer")}var a=!1;if(d?b[0].hasAttribute("data-info"):b.hasAttribute("data-info")){var f="div.ai-rotate.ai-"+(d?JSON.parse(atob(b[0].dataset.info)):JSON.parse(atob(b.dataset.info)))[0];ai_rotation_triggers.includes(f)&&(ai_rotation_triggers.splice(ai_rotation_triggers.indexOf(f),1),a=!0)}if(d)for(d=0;d<b.length;d++)0==d?ai_process_single_rotation(b[d],!0):ai_process_single_rotation(b[d],!1);else ai_process_single_rotation(b,!a)};ai_process_single_rotation=
function(b,d){var e=[];Array.from(b.children).forEach((g,p)=>{g.matches(".ai-rotate-option")&&e.push(g)});if(0!=e.length){e.forEach((g,p)=>{g.style.display="none"});if(b.hasAttribute("data-next")){k=parseInt(b.getAttribute("data-next"));var a=e[k];if(a.hasAttribute("data-code")){var f=document.createRange(),c=!0;try{var h=f.createContextualFragment(b64d(a.dataset.code))}catch(g){c=!1}c&&(a=h)}0!=a.querySelectorAll("span[data-ai-groups]").length&&0!=document.querySelectorAll(".ai-rotation-groups").length&&
setTimeout(function(){B()},5)}else if(e[0].hasAttribute("data-group")){var k=-1,u=[];document.querySelectorAll("span[data-ai-groups]").forEach((g,p)=>{(g.offsetWidth||g.offsetHeight||g.getClientRects().length)&&u.push(g)});1<=u.length&&(timed_groups=[],groups=[],u.forEach(function(g,p){active_groups=JSON.parse(b64d(g.dataset.aiGroups));var r=!1;g=g.closest(".ai-rotate");null!=g&&g.classList.contains("ai-timed-rotation")&&(r=!0);active_groups.forEach(function(t,v){groups.push(t);r&&timed_groups.push(t)})}),
groups.forEach(function(g,p){-1==k&&e.forEach((r,t)=>{var v=b64d(r.dataset.group);option_group_items=v.split(",");option_group_items.forEach(function(C,E){-1==k&&C.trim()==g&&(k=t,timed_groups.includes(v)&&b.classList.add("ai-timed-rotation"))})})}))}else if(b.hasAttribute("data-shares"))for(f=JSON.parse(atob(b.dataset.shares)),a=Math.round(100*Math.random()),c=0;c<f.length&&(k=c,0>f[c]||!(a<=f[c]));c++);else f=b.classList.contains("ai-unique"),a=new Date,f?("number"!=typeof ai_rotation_seed&&(ai_rotation_seed=
(Math.floor(1E3*Math.random())+a.getMilliseconds())%e.length),f=ai_rotation_seed,f>e.length&&(f%=e.length),a=parseInt(b.dataset.counter),a<=e.length?(k=parseInt(f+a-1),k>=e.length&&(k-=e.length)):k=e.length):(k=Math.floor(Math.random()*e.length),a.getMilliseconds()%2&&(k=e.length-k-1));if(b.classList.contains("ai-rotation-scheduling"))for(k=-1,f=0;f<e.length;f++)if(a=e[f],a.hasAttribute("data-scheduling")){c=b64d(a.dataset.scheduling);a=!0;0==c.indexOf("^")&&(a=!1,c=c.substring(1));var q=c.split("="),
m=-1!=c.indexOf("%")?q[0].split("%"):[q[0]];c=m[0].trim().toLowerCase();m="undefined"!=typeof m[1]?m[1].trim():0;q=q[1].replace(" ","");var n=(new Date).getTime();n=new Date(n);var l=0;switch(c){case "s":l=n.getSeconds();break;case "i":l=n.getMinutes();break;case "h":l=n.getHours();break;case "d":l=n.getDate();break;case "m":l=n.getMonth();break;case "y":l=n.getFullYear();break;case "w":l=n.getDay(),l=0==l?6:l-1}c=0!=m?l%m:l;m=q.split(",");q=!a;for(n=0;n<m.length;n++)if(l=m[n],-1!=l.indexOf("-")){if(l=
l.split("-"),c>=l[0]&&c<=l[1]){q=a;break}}else if(c==l){q=a;break}if(q){k=f;break}}if(!(0>k||k>=e.length)){a=e[k];var z="",w=b.classList.contains("ai-timed-rotation");e.forEach((g,p)=>{g.hasAttribute("data-time")&&(w=!0)});if(a.hasAttribute("data-time")){f=atob(a.dataset.time);if(0==f&&1<e.length){c=k;do{c++;c>=e.length&&(c=0);m=e[c];if(!m.hasAttribute("data-time")){k=c;a=e[k];f=0;break}m=atob(m.dataset.time)}while(0==m&&c!=k);0!=f&&(k=c,a=e[k],f=atob(a.dataset.time))}if(0<f&&(c=k+1,c>=e.length&&
(c=0),b.hasAttribute("data-info"))){m=JSON.parse(atob(b.dataset.info))[0];b.setAttribute("data-next",c);var x="div.ai-rotate.ai-"+m;ai_rotation_triggers.includes(x)&&(d=!1);d&&(ai_rotation_triggers.push(x),setTimeout(function(){var g=document.querySelectorAll(x);g.forEach((p,r)=>{p.classList.add("ai-timer")});ai_process_rotation(g)},1E3*f));z=" ("+f+" s)"}}else a.hasAttribute("data-group")||e.forEach((g,p)=>{p!=k&&g.remove()});a.style.display="";a.style.visibility="";a.style.position="";a.style.width=
"";a.style.height="";a.style.top="";a.style.left="";a.classList.remove("ai-rotate-hidden");a.classList.remove("ai-rotate-hidden-2");b.style.position="";if(a.hasAttribute("data-code")){e.forEach((g,p)=>{g.innerText=""});d=b64d(a.dataset.code);f=document.createRange();c=!0;try{h=f.createContextualFragment(d)}catch(g){c=!1}a.append(h);D()}f=parseInt(a.dataset.index);var y=b64d(a.dataset.name);d=b.closest(".ai-debug-block");if(null!=d){h=d.querySelectorAll("kbd.ai-option-name");d=d.querySelectorAll(".ai-debug-block");
if(0!=d.length){var A=[];d.forEach((g,p)=>{g.querySelectorAll("kbd.ai-option-name").forEach((r,t)=>{A.push(r)})});h=Array.from(h);h=h.slice(0,h.length-A.length)}0!=h.length&&(separator=h[0].hasAttribute("data-separator")?h[0].dataset.separator:"",h.forEach((g,p)=>{g.innerText=separator+y+z}))}d=!1;a=b.closest(".ai-adb-show");null!=a&&a.hasAttribute("data-ai-tracking")&&(h=JSON.parse(b64d(a.getAttribute("data-ai-tracking"))),"undefined"!==typeof h&&h.constructor===Array&&(h[1]=f,h[3]=y,a.setAttribute("data-ai-tracking",
b64e(JSON.stringify(h))),a.classList.add("ai-track"),w&&ai_tracking_finished&&a.classList.add("ai-no-pageview"),d=!0));d||(d=b.closest("div[data-ai]"),null!=d&&d.hasAttribute("data-ai")&&(h=JSON.parse(b64d(d.getAttribute("data-ai"))),"undefined"!==typeof h&&h.constructor===Array&&(h[1]=f,h[3]=y,d.setAttribute("data-ai",b64e(JSON.stringify(h))),d.classList.add("ai-track"),w&&ai_tracking_finished&&d.classList.add("ai-no-pageview"))))}}};ai_process_rotations=function(){document.querySelectorAll("div.ai-rotate").forEach((b,
d)=>{ai_process_rotation(b)})};function B(){document.querySelectorAll("div.ai-rotate.ai-rotation-groups").forEach((b,d)=>{b.classList.add("ai-timer");ai_process_rotation(b)})}ai_process_rotations_in_element=function(b){null!=b&&b.querySelectorAll("div.ai-rotate").forEach((d,e)=>{ai_process_rotation(d)})};(function(b){"complete"===document.readyState||"loading"!==document.readyState&&!document.documentElement.doScroll?b():document.addEventListener("DOMContentLoaded",b)})(function(){setTimeout(function(){ai_process_rotations()},
10)});ai_process_elements_active=!1;function D(){ai_process_elements_active||setTimeout(function(){ai_process_elements_active=!1;"function"==typeof ai_process_rotations&&ai_process_rotations();"function"==typeof ai_process_lists&&ai_process_lists();"function"==typeof ai_process_ip_addresses&&ai_process_ip_addresses();"function"==typeof ai_process_filter_hooks&&ai_process_filter_hooks();"function"==typeof ai_adb_process_blocks&&ai_adb_process_blocks();"function"==typeof ai_process_impressions&&1==
ai_tracking_finished&&ai_process_impressions();"function"==typeof ai_install_click_trackers&&1==ai_tracking_finished&&ai_install_click_trackers();"function"==typeof ai_install_close_buttons&&ai_install_close_buttons(document)},5);ai_process_elements_active=!0}};
;!function(a,b){a(function(){"use strict";function a(a,b){return null!=a&&null!=b&&a.toLowerCase()===b.toLowerCase()}function c(a,b){var c,d,e=a.length;if(!e||!b)return!1;for(c=b.toLowerCase(),d=0;d<e;++d)if(c===a[d].toLowerCase())return!0;return!1}function d(a){for(var b in a)i.call(a,b)&&(a[b]=new RegExp(a[b],"i"))}function e(a){return(a||"").substr(0,500)}function f(a,b){this.ua=e(a),this._cache={},this.maxPhoneWidth=b||600}var g={};g.mobileDetectRules={phones:{iPhone:"\\biPhone\\b|\\biPod\\b",BlackBerry:"BlackBerry|\\bBB10\\b|rim[0-9]+|\\b(BBA100|BBB100|BBD100|BBE100|BBF100|STH100)\\b-[0-9]+",Pixel:"; \\bPixel\\b",HTC:"HTC|HTC.*(Sensation|Evo|Vision|Explorer|6800|8100|8900|A7272|S510e|C110e|Legend|Desire|T8282)|APX515CKT|Qtek9090|APA9292KT|HD_mini|Sensation.*Z710e|PG86100|Z715e|Desire.*(A8181|HD)|ADR6200|ADR6400L|ADR6425|001HT|Inspire 4G|Android.*\\bEVO\\b|T-Mobile G1|Z520m|Android [0-9.]+; Pixel",Nexus:"Nexus One|Nexus S|Galaxy.*Nexus|Android.*Nexus.*Mobile|Nexus 4|Nexus 5|Nexus 5X|Nexus 6",Dell:"Dell[;]? (Streak|Aero|Venue|Venue Pro|Flash|Smoke|Mini 3iX)|XCD28|XCD35|\\b001DL\\b|\\b101DL\\b|\\bGS01\\b",Motorola:"Motorola|DROIDX|DROID BIONIC|\\bDroid\\b.*Build|Android.*Xoom|HRI39|MOT-|A1260|A1680|A555|A853|A855|A953|A955|A956|Motorola.*ELECTRIFY|Motorola.*i1|i867|i940|MB200|MB300|MB501|MB502|MB508|MB511|MB520|MB525|MB526|MB611|MB612|MB632|MB810|MB855|MB860|MB861|MB865|MB870|ME501|ME502|ME511|ME525|ME600|ME632|ME722|ME811|ME860|ME863|ME865|MT620|MT710|MT716|MT720|MT810|MT870|MT917|Motorola.*TITANIUM|WX435|WX445|XT300|XT301|XT311|XT316|XT317|XT319|XT320|XT390|XT502|XT530|XT531|XT532|XT535|XT603|XT610|XT611|XT615|XT681|XT701|XT702|XT711|XT720|XT800|XT806|XT860|XT862|XT875|XT882|XT883|XT894|XT901|XT907|XT909|XT910|XT912|XT928|XT926|XT915|XT919|XT925|XT1021|\\bMoto E\\b|XT1068|XT1092|XT1052",Samsung:"\\bSamsung\\b|SM-G950F|SM-G955F|SM-G9250|GT-19300|SGH-I337|BGT-S5230|GT-B2100|GT-B2700|GT-B2710|GT-B3210|GT-B3310|GT-B3410|GT-B3730|GT-B3740|GT-B5510|GT-B5512|GT-B5722|GT-B6520|GT-B7300|GT-B7320|GT-B7330|GT-B7350|GT-B7510|GT-B7722|GT-B7800|GT-C3010|GT-C3011|GT-C3060|GT-C3200|GT-C3212|GT-C3212I|GT-C3262|GT-C3222|GT-C3300|GT-C3300K|GT-C3303|GT-C3303K|GT-C3310|GT-C3322|GT-C3330|GT-C3350|GT-C3500|GT-C3510|GT-C3530|GT-C3630|GT-C3780|GT-C5010|GT-C5212|GT-C6620|GT-C6625|GT-C6712|GT-E1050|GT-E1070|GT-E1075|GT-E1080|GT-E1081|GT-E1085|GT-E1087|GT-E1100|GT-E1107|GT-E1110|GT-E1120|GT-E1125|GT-E1130|GT-E1160|GT-E1170|GT-E1175|GT-E1180|GT-E1182|GT-E1200|GT-E1210|GT-E1225|GT-E1230|GT-E1390|GT-E2100|GT-E2120|GT-E2121|GT-E2152|GT-E2220|GT-E2222|GT-E2230|GT-E2232|GT-E2250|GT-E2370|GT-E2550|GT-E2652|GT-E3210|GT-E3213|GT-I5500|GT-I5503|GT-I5700|GT-I5800|GT-I5801|GT-I6410|GT-I6420|GT-I7110|GT-I7410|GT-I7500|GT-I8000|GT-I8150|GT-I8160|GT-I8190|GT-I8320|GT-I8330|GT-I8350|GT-I8530|GT-I8700|GT-I8703|GT-I8910|GT-I9000|GT-I9001|GT-I9003|GT-I9010|GT-I9020|GT-I9023|GT-I9070|GT-I9082|GT-I9100|GT-I9103|GT-I9220|GT-I9250|GT-I9300|GT-I9305|GT-I9500|GT-I9505|GT-M3510|GT-M5650|GT-M7500|GT-M7600|GT-M7603|GT-M8800|GT-M8910|GT-N7000|GT-S3110|GT-S3310|GT-S3350|GT-S3353|GT-S3370|GT-S3650|GT-S3653|GT-S3770|GT-S3850|GT-S5210|GT-S5220|GT-S5229|GT-S5230|GT-S5233|GT-S5250|GT-S5253|GT-S5260|GT-S5263|GT-S5270|GT-S5300|GT-S5330|GT-S5350|GT-S5360|GT-S5363|GT-S5369|GT-S5380|GT-S5380D|GT-S5560|GT-S5570|GT-S5600|GT-S5603|GT-S5610|GT-S5620|GT-S5660|GT-S5670|GT-S5690|GT-S5750|GT-S5780|GT-S5830|GT-S5839|GT-S6102|GT-S6500|GT-S7070|GT-S7200|GT-S7220|GT-S7230|GT-S7233|GT-S7250|GT-S7500|GT-S7530|GT-S7550|GT-S7562|GT-S7710|GT-S8000|GT-S8003|GT-S8500|GT-S8530|GT-S8600|SCH-A310|SCH-A530|SCH-A570|SCH-A610|SCH-A630|SCH-A650|SCH-A790|SCH-A795|SCH-A850|SCH-A870|SCH-A890|SCH-A930|SCH-A950|SCH-A970|SCH-A990|SCH-I100|SCH-I110|SCH-I400|SCH-I405|SCH-I500|SCH-I510|SCH-I515|SCH-I600|SCH-I730|SCH-I760|SCH-I770|SCH-I830|SCH-I910|SCH-I920|SCH-I959|SCH-LC11|SCH-N150|SCH-N300|SCH-R100|SCH-R300|SCH-R351|SCH-R400|SCH-R410|SCH-T300|SCH-U310|SCH-U320|SCH-U350|SCH-U360|SCH-U365|SCH-U370|SCH-U380|SCH-U410|SCH-U430|SCH-U450|SCH-U460|SCH-U470|SCH-U490|SCH-U540|SCH-U550|SCH-U620|SCH-U640|SCH-U650|SCH-U660|SCH-U700|SCH-U740|SCH-U750|SCH-U810|SCH-U820|SCH-U900|SCH-U940|SCH-U960|SCS-26UC|SGH-A107|SGH-A117|SGH-A127|SGH-A137|SGH-A157|SGH-A167|SGH-A177|SGH-A187|SGH-A197|SGH-A227|SGH-A237|SGH-A257|SGH-A437|SGH-A517|SGH-A597|SGH-A637|SGH-A657|SGH-A667|SGH-A687|SGH-A697|SGH-A707|SGH-A717|SGH-A727|SGH-A737|SGH-A747|SGH-A767|SGH-A777|SGH-A797|SGH-A817|SGH-A827|SGH-A837|SGH-A847|SGH-A867|SGH-A877|SGH-A887|SGH-A897|SGH-A927|SGH-B100|SGH-B130|SGH-B200|SGH-B220|SGH-C100|SGH-C110|SGH-C120|SGH-C130|SGH-C140|SGH-C160|SGH-C170|SGH-C180|SGH-C200|SGH-C207|SGH-C210|SGH-C225|SGH-C230|SGH-C417|SGH-C450|SGH-D307|SGH-D347|SGH-D357|SGH-D407|SGH-D415|SGH-D780|SGH-D807|SGH-D980|SGH-E105|SGH-E200|SGH-E315|SGH-E316|SGH-E317|SGH-E335|SGH-E590|SGH-E635|SGH-E715|SGH-E890|SGH-F300|SGH-F480|SGH-I200|SGH-I300|SGH-I320|SGH-I550|SGH-I577|SGH-I600|SGH-I607|SGH-I617|SGH-I627|SGH-I637|SGH-I677|SGH-I700|SGH-I717|SGH-I727|SGH-i747M|SGH-I777|SGH-I780|SGH-I827|SGH-I847|SGH-I857|SGH-I896|SGH-I897|SGH-I900|SGH-I907|SGH-I917|SGH-I927|SGH-I937|SGH-I997|SGH-J150|SGH-J200|SGH-L170|SGH-L700|SGH-M110|SGH-M150|SGH-M200|SGH-N105|SGH-N500|SGH-N600|SGH-N620|SGH-N625|SGH-N700|SGH-N710|SGH-P107|SGH-P207|SGH-P300|SGH-P310|SGH-P520|SGH-P735|SGH-P777|SGH-Q105|SGH-R210|SGH-R220|SGH-R225|SGH-S105|SGH-S307|SGH-T109|SGH-T119|SGH-T139|SGH-T209|SGH-T219|SGH-T229|SGH-T239|SGH-T249|SGH-T259|SGH-T309|SGH-T319|SGH-T329|SGH-T339|SGH-T349|SGH-T359|SGH-T369|SGH-T379|SGH-T409|SGH-T429|SGH-T439|SGH-T459|SGH-T469|SGH-T479|SGH-T499|SGH-T509|SGH-T519|SGH-T539|SGH-T559|SGH-T589|SGH-T609|SGH-T619|SGH-T629|SGH-T639|SGH-T659|SGH-T669|SGH-T679|SGH-T709|SGH-T719|SGH-T729|SGH-T739|SGH-T746|SGH-T749|SGH-T759|SGH-T769|SGH-T809|SGH-T819|SGH-T839|SGH-T919|SGH-T929|SGH-T939|SGH-T959|SGH-T989|SGH-U100|SGH-U200|SGH-U800|SGH-V205|SGH-V206|SGH-X100|SGH-X105|SGH-X120|SGH-X140|SGH-X426|SGH-X427|SGH-X475|SGH-X495|SGH-X497|SGH-X507|SGH-X600|SGH-X610|SGH-X620|SGH-X630|SGH-X700|SGH-X820|SGH-X890|SGH-Z130|SGH-Z150|SGH-Z170|SGH-ZX10|SGH-ZX20|SHW-M110|SPH-A120|SPH-A400|SPH-A420|SPH-A460|SPH-A500|SPH-A560|SPH-A600|SPH-A620|SPH-A660|SPH-A700|SPH-A740|SPH-A760|SPH-A790|SPH-A800|SPH-A820|SPH-A840|SPH-A880|SPH-A900|SPH-A940|SPH-A960|SPH-D600|SPH-D700|SPH-D710|SPH-D720|SPH-I300|SPH-I325|SPH-I330|SPH-I350|SPH-I500|SPH-I600|SPH-I700|SPH-L700|SPH-M100|SPH-M220|SPH-M240|SPH-M300|SPH-M305|SPH-M320|SPH-M330|SPH-M350|SPH-M360|SPH-M370|SPH-M380|SPH-M510|SPH-M540|SPH-M550|SPH-M560|SPH-M570|SPH-M580|SPH-M610|SPH-M620|SPH-M630|SPH-M800|SPH-M810|SPH-M850|SPH-M900|SPH-M910|SPH-M920|SPH-M930|SPH-N100|SPH-N200|SPH-N240|SPH-N300|SPH-N400|SPH-Z400|SWC-E100|SCH-i909|GT-N7100|GT-N7105|SCH-I535|SM-N900A|SGH-I317|SGH-T999L|GT-S5360B|GT-I8262|GT-S6802|GT-S6312|GT-S6310|GT-S5312|GT-S5310|GT-I9105|GT-I8510|GT-S6790N|SM-G7105|SM-N9005|GT-S5301|GT-I9295|GT-I9195|SM-C101|GT-S7392|GT-S7560|GT-B7610|GT-I5510|GT-S7582|GT-S7530E|GT-I8750|SM-G9006V|SM-G9008V|SM-G9009D|SM-G900A|SM-G900D|SM-G900F|SM-G900H|SM-G900I|SM-G900J|SM-G900K|SM-G900L|SM-G900M|SM-G900P|SM-G900R4|SM-G900S|SM-G900T|SM-G900V|SM-G900W8|SHV-E160K|SCH-P709|SCH-P729|SM-T2558|GT-I9205|SM-G9350|SM-J120F|SM-G920F|SM-G920V|SM-G930F|SM-N910C|SM-A310F|GT-I9190|SM-J500FN|SM-G903F|SM-J330F|SM-G610F|SM-G981B|SM-G892A|SM-A530F",LG:"\\bLG\\b;|LG[- ]?(C800|C900|E400|E610|E900|E-900|F160|F180K|F180L|F180S|730|855|L160|LS740|LS840|LS970|LU6200|MS690|MS695|MS770|MS840|MS870|MS910|P500|P700|P705|VM696|AS680|AS695|AX840|C729|E970|GS505|272|C395|E739BK|E960|L55C|L75C|LS696|LS860|P769BK|P350|P500|P509|P870|UN272|US730|VS840|VS950|LN272|LN510|LS670|LS855|LW690|MN270|MN510|P509|P769|P930|UN200|UN270|UN510|UN610|US670|US740|US760|UX265|UX840|VN271|VN530|VS660|VS700|VS740|VS750|VS910|VS920|VS930|VX9200|VX11000|AX840A|LW770|P506|P925|P999|E612|D955|D802|MS323|M257)|LM-G710",Sony:"SonyST|SonyLT|SonyEricsson|SonyEricssonLT15iv|LT18i|E10i|LT28h|LT26w|SonyEricssonMT27i|C5303|C6902|C6903|C6906|C6943|D2533|SOV34|601SO|F8332",Asus:"Asus.*Galaxy|PadFone.*Mobile",Xiaomi:"^(?!.*\\bx11\\b).*xiaomi.*$|POCOPHONE F1|MI 8|Redmi Note 9S|Redmi Note 5A Prime|N2G47H|M2001J2G|M2001J2I|M1805E10A|M2004J11G|M1902F1G|M2002J9G|M2004J19G|M2003J6A1G",NokiaLumia:"Lumia [0-9]{3,4}",Micromax:"Micromax.*\\b(A210|A92|A88|A72|A111|A110Q|A115|A116|A110|A90S|A26|A51|A35|A54|A25|A27|A89|A68|A65|A57|A90)\\b",Palm:"PalmSource|Palm",Vertu:"Vertu|Vertu.*Ltd|Vertu.*Ascent|Vertu.*Ayxta|Vertu.*Constellation(F|Quest)?|Vertu.*Monika|Vertu.*Signature",Pantech:"PANTECH|IM-A850S|IM-A840S|IM-A830L|IM-A830K|IM-A830S|IM-A820L|IM-A810K|IM-A810S|IM-A800S|IM-T100K|IM-A725L|IM-A780L|IM-A775C|IM-A770K|IM-A760S|IM-A750K|IM-A740S|IM-A730S|IM-A720L|IM-A710K|IM-A690L|IM-A690S|IM-A650S|IM-A630K|IM-A600S|VEGA PTL21|PT003|P8010|ADR910L|P6030|P6020|P9070|P4100|P9060|P5000|CDM8992|TXT8045|ADR8995|IS11PT|P2030|P6010|P8000|PT002|IS06|CDM8999|P9050|PT001|TXT8040|P2020|P9020|P2000|P7040|P7000|C790",Fly:"IQ230|IQ444|IQ450|IQ440|IQ442|IQ441|IQ245|IQ256|IQ236|IQ255|IQ235|IQ245|IQ275|IQ240|IQ285|IQ280|IQ270|IQ260|IQ250",Wiko:"KITE 4G|HIGHWAY|GETAWAY|STAIRWAY|DARKSIDE|DARKFULL|DARKNIGHT|DARKMOON|SLIDE|WAX 4G|RAINBOW|BLOOM|SUNSET|GOA(?!nna)|LENNY|BARRY|IGGY|OZZY|CINK FIVE|CINK PEAX|CINK PEAX 2|CINK SLIM|CINK SLIM 2|CINK +|CINK KING|CINK PEAX|CINK SLIM|SUBLIM",iMobile:"i-mobile (IQ|i-STYLE|idea|ZAA|Hitz)",SimValley:"\\b(SP-80|XT-930|SX-340|XT-930|SX-310|SP-360|SP60|SPT-800|SP-120|SPT-800|SP-140|SPX-5|SPX-8|SP-100|SPX-8|SPX-12)\\b",Wolfgang:"AT-B24D|AT-AS50HD|AT-AS40W|AT-AS55HD|AT-AS45q2|AT-B26D|AT-AS50Q",Alcatel:"Alcatel",Nintendo:"Nintendo (3DS|Switch)",Amoi:"Amoi",INQ:"INQ",OnePlus:"ONEPLUS",GenericPhone:"Tapatalk|PDA;|SAGEM|\\bmmp\\b|pocket|\\bpsp\\b|symbian|Smartphone|smartfon|treo|up.browser|up.link|vodafone|\\bwap\\b|nokia|Series40|Series60|S60|SonyEricsson|N900|MAUI.*WAP.*Browser"},tablets:{iPad:"iPad|iPad.*Mobile",NexusTablet:"Android.*Nexus[\\s]+(7|9|10)",GoogleTablet:"Android.*Pixel C",SamsungTablet:"SAMSUNG.*Tablet|Galaxy.*Tab|SC-01C|GT-P1000|GT-P1003|GT-P1010|GT-P3105|GT-P6210|GT-P6800|GT-P6810|GT-P7100|GT-P7300|GT-P7310|GT-P7500|GT-P7510|SCH-I800|SCH-I815|SCH-I905|SGH-I957|SGH-I987|SGH-T849|SGH-T859|SGH-T869|SPH-P100|GT-P3100|GT-P3108|GT-P3110|GT-P5100|GT-P5110|GT-P6200|GT-P7320|GT-P7511|GT-N8000|GT-P8510|SGH-I497|SPH-P500|SGH-T779|SCH-I705|SCH-I915|GT-N8013|GT-P3113|GT-P5113|GT-P8110|GT-N8010|GT-N8005|GT-N8020|GT-P1013|GT-P6201|GT-P7501|GT-N5100|GT-N5105|GT-N5110|SHV-E140K|SHV-E140L|SHV-E140S|SHV-E150S|SHV-E230K|SHV-E230L|SHV-E230S|SHW-M180K|SHW-M180L|SHW-M180S|SHW-M180W|SHW-M300W|SHW-M305W|SHW-M380K|SHW-M380S|SHW-M380W|SHW-M430W|SHW-M480K|SHW-M480S|SHW-M480W|SHW-M485W|SHW-M486W|SHW-M500W|GT-I9228|SCH-P739|SCH-I925|GT-I9200|GT-P5200|GT-P5210|GT-P5210X|SM-T311|SM-T310|SM-T310X|SM-T210|SM-T210R|SM-T211|SM-P600|SM-P601|SM-P605|SM-P900|SM-P901|SM-T217|SM-T217A|SM-T217S|SM-P6000|SM-T3100|SGH-I467|XE500|SM-T110|GT-P5220|GT-I9200X|GT-N5110X|GT-N5120|SM-P905|SM-T111|SM-T2105|SM-T315|SM-T320|SM-T320X|SM-T321|SM-T520|SM-T525|SM-T530NU|SM-T230NU|SM-T330NU|SM-T900|XE500T1C|SM-P605V|SM-P905V|SM-T337V|SM-T537V|SM-T707V|SM-T807V|SM-P600X|SM-P900X|SM-T210X|SM-T230|SM-T230X|SM-T325|GT-P7503|SM-T531|SM-T330|SM-T530|SM-T705|SM-T705C|SM-T535|SM-T331|SM-T800|SM-T700|SM-T537|SM-T807|SM-P907A|SM-T337A|SM-T537A|SM-T707A|SM-T807A|SM-T237|SM-T807P|SM-P607T|SM-T217T|SM-T337T|SM-T807T|SM-T116NQ|SM-T116BU|SM-P550|SM-T350|SM-T550|SM-T9000|SM-P9000|SM-T705Y|SM-T805|GT-P3113|SM-T710|SM-T810|SM-T815|SM-T360|SM-T533|SM-T113|SM-T335|SM-T715|SM-T560|SM-T670|SM-T677|SM-T377|SM-T567|SM-T357T|SM-T555|SM-T561|SM-T713|SM-T719|SM-T813|SM-T819|SM-T580|SM-T355Y?|SM-T280|SM-T817A|SM-T820|SM-W700|SM-P580|SM-T587|SM-P350|SM-P555M|SM-P355M|SM-T113NU|SM-T815Y|SM-T585|SM-T285|SM-T825|SM-W708|SM-T835|SM-T830|SM-T837V|SM-T720|SM-T510|SM-T387V|SM-P610|SM-T290|SM-T515|SM-T590|SM-T595|SM-T725|SM-T817P|SM-P585N0|SM-T395|SM-T295|SM-T865|SM-P610N|SM-P615|SM-T970|SM-T380|SM-T5950|SM-T905|SM-T231|SM-T500|SM-T860",Kindle:"Kindle|Silk.*Accelerated|Android.*\\b(KFOT|KFTT|KFJWI|KFJWA|KFOTE|KFSOWI|KFTHWI|KFTHWA|KFAPWI|KFAPWA|WFJWAE|KFSAWA|KFSAWI|KFASWI|KFARWI|KFFOWI|KFGIWI|KFMEWI)\\b|Android.*Silk/[0-9.]+ like Chrome/[0-9.]+ (?!Mobile)",SurfaceTablet:"Windows NT [0-9.]+; ARM;.*(Tablet|ARMBJS)",HPTablet:"HP Slate (7|8|10)|HP ElitePad 900|hp-tablet|EliteBook.*Touch|HP 8|Slate 21|HP SlateBook 10",AsusTablet:"^.*PadFone((?!Mobile).)*$|Transformer|TF101|TF101G|TF300T|TF300TG|TF300TL|TF700T|TF700KL|TF701T|TF810C|ME171|ME301T|ME302C|ME371MG|ME370T|ME372MG|ME172V|ME173X|ME400C|Slider SL101|\\bK00F\\b|\\bK00C\\b|\\bK00E\\b|\\bK00L\\b|TX201LA|ME176C|ME102A|\\bM80TA\\b|ME372CL|ME560CG|ME372CG|ME302KL| K010 | K011 | K017 | K01E |ME572C|ME103K|ME170C|ME171C|\\bME70C\\b|ME581C|ME581CL|ME8510C|ME181C|P01Y|PO1MA|P01Z|\\bP027\\b|\\bP024\\b|\\bP00C\\b",BlackBerryTablet:"PlayBook|RIM Tablet",HTCtablet:"HTC_Flyer_P512|HTC Flyer|HTC Jetstream|HTC-P715a|HTC EVO View 4G|PG41200|PG09410",MotorolaTablet:"xoom|sholest|MZ615|MZ605|MZ505|MZ601|MZ602|MZ603|MZ604|MZ606|MZ607|MZ608|MZ609|MZ615|MZ616|MZ617",NookTablet:"Android.*Nook|NookColor|nook browser|BNRV200|BNRV200A|BNTV250|BNTV250A|BNTV400|BNTV600|LogicPD Zoom2",AcerTablet:"Android.*; \\b(A100|A101|A110|A200|A210|A211|A500|A501|A510|A511|A700|A701|W500|W500P|W501|W501P|W510|W511|W700|G100|G100W|B1-A71|B1-710|B1-711|A1-810|A1-811|A1-830)\\b|W3-810|\\bA3-A10\\b|\\bA3-A11\\b|\\bA3-A20\\b|\\bA3-A30|A3-A40",ToshibaTablet:"Android.*(AT100|AT105|AT200|AT205|AT270|AT275|AT300|AT305|AT1S5|AT500|AT570|AT700|AT830)|TOSHIBA.*FOLIO",LGTablet:"\\bL-06C|LG-V909|LG-V900|LG-V700|LG-V510|LG-V500|LG-V410|LG-V400|LG-VK810\\b",FujitsuTablet:"Android.*\\b(F-01D|F-02F|F-05E|F-10D|M532|Q572)\\b",PrestigioTablet:"PMP3170B|PMP3270B|PMP3470B|PMP7170B|PMP3370B|PMP3570C|PMP5870C|PMP3670B|PMP5570C|PMP5770D|PMP3970B|PMP3870C|PMP5580C|PMP5880D|PMP5780D|PMP5588C|PMP7280C|PMP7280C3G|PMP7280|PMP7880D|PMP5597D|PMP5597|PMP7100D|PER3464|PER3274|PER3574|PER3884|PER5274|PER5474|PMP5097CPRO|PMP5097|PMP7380D|PMP5297C|PMP5297C_QUAD|PMP812E|PMP812E3G|PMP812F|PMP810E|PMP880TD|PMT3017|PMT3037|PMT3047|PMT3057|PMT7008|PMT5887|PMT5001|PMT5002",LenovoTablet:"Lenovo TAB|Idea(Tab|Pad)( A1|A10| K1|)|ThinkPad([ ]+)?Tablet|YT3-850M|YT3-X90L|YT3-X90F|YT3-X90X|Lenovo.*(S2109|S2110|S5000|S6000|K3011|A3000|A3500|A1000|A2107|A2109|A1107|A5500|A7600|B6000|B8000|B8080)(-|)(FL|F|HV|H|)|TB-X103F|TB-X304X|TB-X304F|TB-X304L|TB-X505F|TB-X505L|TB-X505X|TB-X605F|TB-X605L|TB-8703F|TB-8703X|TB-8703N|TB-8704N|TB-8704F|TB-8704X|TB-8704V|TB-7304F|TB-7304I|TB-7304X|Tab2A7-10F|Tab2A7-20F|TB2-X30L|YT3-X50L|YT3-X50F|YT3-X50M|YT-X705F|YT-X703F|YT-X703L|YT-X705L|YT-X705X|TB2-X30F|TB2-X30L|TB2-X30M|A2107A-F|A2107A-H|TB3-730F|TB3-730M|TB3-730X|TB-7504F|TB-7504X|TB-X704F|TB-X104F|TB3-X70F|TB-X705F|TB-8504F|TB3-X70L|TB3-710F|TB-X704L",DellTablet:"Venue 11|Venue 8|Venue 7|Dell Streak 10|Dell Streak 7",YarvikTablet:"Android.*\\b(TAB210|TAB211|TAB224|TAB250|TAB260|TAB264|TAB310|TAB360|TAB364|TAB410|TAB411|TAB420|TAB424|TAB450|TAB460|TAB461|TAB464|TAB465|TAB467|TAB468|TAB07-100|TAB07-101|TAB07-150|TAB07-151|TAB07-152|TAB07-200|TAB07-201-3G|TAB07-210|TAB07-211|TAB07-212|TAB07-214|TAB07-220|TAB07-400|TAB07-485|TAB08-150|TAB08-200|TAB08-201-3G|TAB08-201-30|TAB09-100|TAB09-211|TAB09-410|TAB10-150|TAB10-201|TAB10-211|TAB10-400|TAB10-410|TAB13-201|TAB274EUK|TAB275EUK|TAB374EUK|TAB462EUK|TAB474EUK|TAB9-200)\\b",MedionTablet:"Android.*\\bOYO\\b|LIFE.*(P9212|P9514|P9516|S9512)|LIFETAB",ArnovaTablet:"97G4|AN10G2|AN7bG3|AN7fG3|AN8G3|AN8cG3|AN7G3|AN9G3|AN7dG3|AN7dG3ST|AN7dG3ChildPad|AN10bG3|AN10bG3DT|AN9G2",IntensoTablet:"INM8002KP|INM1010FP|INM805ND|Intenso Tab|TAB1004",IRUTablet:"M702pro",MegafonTablet:"MegaFon V9|\\bZTE V9\\b|Android.*\\bMT7A\\b",EbodaTablet:"E-Boda (Supreme|Impresspeed|Izzycomm|Essential)",AllViewTablet:"Allview.*(Viva|Alldro|City|Speed|All TV|Frenzy|Quasar|Shine|TX1|AX1|AX2)",ArchosTablet:"\\b(101G9|80G9|A101IT)\\b|Qilive 97R|Archos5|\\bARCHOS (70|79|80|90|97|101|FAMILYPAD|)(b|c|)(G10| Cobalt| TITANIUM(HD|)| Xenon| Neon|XSK| 2| XS 2| PLATINUM| CARBON|GAMEPAD)\\b",AinolTablet:"NOVO7|NOVO8|NOVO10|Novo7Aurora|Novo7Basic|NOVO7PALADIN|novo9-Spark",NokiaLumiaTablet:"Lumia 2520",SonyTablet:"Sony.*Tablet|Xperia Tablet|Sony Tablet S|SO-03E|SGPT12|SGPT13|SGPT114|SGPT121|SGPT122|SGPT123|SGPT111|SGPT112|SGPT113|SGPT131|SGPT132|SGPT133|SGPT211|SGPT212|SGPT213|SGP311|SGP312|SGP321|EBRD1101|EBRD1102|EBRD1201|SGP351|SGP341|SGP511|SGP512|SGP521|SGP541|SGP551|SGP621|SGP641|SGP612|SOT31|SGP771|SGP611|SGP612|SGP712",PhilipsTablet:"\\b(PI2010|PI3000|PI3100|PI3105|PI3110|PI3205|PI3210|PI3900|PI4010|PI7000|PI7100)\\b",CubeTablet:"Android.*(K8GT|U9GT|U10GT|U16GT|U17GT|U18GT|U19GT|U20GT|U23GT|U30GT)|CUBE U8GT",CobyTablet:"MID1042|MID1045|MID1125|MID1126|MID7012|MID7014|MID7015|MID7034|MID7035|MID7036|MID7042|MID7048|MID7127|MID8042|MID8048|MID8127|MID9042|MID9740|MID9742|MID7022|MID7010",MIDTablet:"M9701|M9000|M9100|M806|M1052|M806|T703|MID701|MID713|MID710|MID727|MID760|MID830|MID728|MID933|MID125|MID810|MID732|MID120|MID930|MID800|MID731|MID900|MID100|MID820|MID735|MID980|MID130|MID833|MID737|MID960|MID135|MID860|MID736|MID140|MID930|MID835|MID733|MID4X10",MSITablet:"MSI \\b(Primo 73K|Primo 73L|Primo 81L|Primo 77|Primo 93|Primo 75|Primo 76|Primo 73|Primo 81|Primo 91|Primo 90|Enjoy 71|Enjoy 7|Enjoy 10)\\b",SMiTTablet:"Android.*(\\bMID\\b|MID-560|MTV-T1200|MTV-PND531|MTV-P1101|MTV-PND530)",RockChipTablet:"Android.*(RK2818|RK2808A|RK2918|RK3066)|RK2738|RK2808A",FlyTablet:"IQ310|Fly Vision",bqTablet:"Android.*(bq)?.*\\b(Elcano|Curie|Edison|Maxwell|Kepler|Pascal|Tesla|Hypatia|Platon|Newton|Livingstone|Cervantes|Avant|Aquaris ([E|M]10|M8))\\b|Maxwell.*Lite|Maxwell.*Plus",HuaweiTablet:"MediaPad|MediaPad 7 Youth|IDEOS S7|S7-201c|S7-202u|S7-101|S7-103|S7-104|S7-105|S7-106|S7-201|S7-Slim|M2-A01L|BAH-L09|BAH-W09|AGS-L09|CMR-AL19",NecTablet:"\\bN-06D|\\bN-08D",PantechTablet:"Pantech.*P4100",BronchoTablet:"Broncho.*(N701|N708|N802|a710)",VersusTablet:"TOUCHPAD.*[78910]|\\bTOUCHTAB\\b",ZyncTablet:"z1000|Z99 2G|z930|z990|z909|Z919|z900",PositivoTablet:"TB07STA|TB10STA|TB07FTA|TB10FTA",NabiTablet:"Android.*\\bNabi",KoboTablet:"Kobo Touch|\\bK080\\b|\\bVox\\b Build|\\bArc\\b Build",DanewTablet:"DSlide.*\\b(700|701R|702|703R|704|802|970|971|972|973|974|1010|1012)\\b",TexetTablet:"NaviPad|TB-772A|TM-7045|TM-7055|TM-9750|TM-7016|TM-7024|TM-7026|TM-7041|TM-7043|TM-7047|TM-8041|TM-9741|TM-9747|TM-9748|TM-9751|TM-7022|TM-7021|TM-7020|TM-7011|TM-7010|TM-7023|TM-7025|TM-7037W|TM-7038W|TM-7027W|TM-9720|TM-9725|TM-9737W|TM-1020|TM-9738W|TM-9740|TM-9743W|TB-807A|TB-771A|TB-727A|TB-725A|TB-719A|TB-823A|TB-805A|TB-723A|TB-715A|TB-707A|TB-705A|TB-709A|TB-711A|TB-890HD|TB-880HD|TB-790HD|TB-780HD|TB-770HD|TB-721HD|TB-710HD|TB-434HD|TB-860HD|TB-840HD|TB-760HD|TB-750HD|TB-740HD|TB-730HD|TB-722HD|TB-720HD|TB-700HD|TB-500HD|TB-470HD|TB-431HD|TB-430HD|TB-506|TB-504|TB-446|TB-436|TB-416|TB-146SE|TB-126SE",PlaystationTablet:"Playstation.*(Portable|Vita)",TrekstorTablet:"ST10416-1|VT10416-1|ST70408-1|ST702xx-1|ST702xx-2|ST80208|ST97216|ST70104-2|VT10416-2|ST10216-2A|SurfTab",PyleAudioTablet:"\\b(PTBL10CEU|PTBL10C|PTBL72BC|PTBL72BCEU|PTBL7CEU|PTBL7C|PTBL92BC|PTBL92BCEU|PTBL9CEU|PTBL9CUK|PTBL9C)\\b",AdvanTablet:"Android.* \\b(E3A|T3X|T5C|T5B|T3E|T3C|T3B|T1J|T1F|T2A|T1H|T1i|E1C|T1-E|T5-A|T4|E1-B|T2Ci|T1-B|T1-D|O1-A|E1-A|T1-A|T3A|T4i)\\b ",DanyTechTablet:"Genius Tab G3|Genius Tab S2|Genius Tab Q3|Genius Tab G4|Genius Tab Q4|Genius Tab G-II|Genius TAB GII|Genius TAB GIII|Genius Tab S1",GalapadTablet:"Android [0-9.]+; [a-z-]+; \\bG1\\b",MicromaxTablet:"Funbook|Micromax.*\\b(P250|P560|P360|P362|P600|P300|P350|P500|P275)\\b",KarbonnTablet:"Android.*\\b(A39|A37|A34|ST8|ST10|ST7|Smart Tab3|Smart Tab2)\\b",AllFineTablet:"Fine7 Genius|Fine7 Shine|Fine7 Air|Fine8 Style|Fine9 More|Fine10 Joy|Fine11 Wide",PROSCANTablet:"\\b(PEM63|PLT1023G|PLT1041|PLT1044|PLT1044G|PLT1091|PLT4311|PLT4311PL|PLT4315|PLT7030|PLT7033|PLT7033D|PLT7035|PLT7035D|PLT7044K|PLT7045K|PLT7045KB|PLT7071KG|PLT7072|PLT7223G|PLT7225G|PLT7777G|PLT7810K|PLT7849G|PLT7851G|PLT7852G|PLT8015|PLT8031|PLT8034|PLT8036|PLT8080K|PLT8082|PLT8088|PLT8223G|PLT8234G|PLT8235G|PLT8816K|PLT9011|PLT9045K|PLT9233G|PLT9735|PLT9760G|PLT9770G)\\b",YONESTablet:"BQ1078|BC1003|BC1077|RK9702|BC9730|BC9001|IT9001|BC7008|BC7010|BC708|BC728|BC7012|BC7030|BC7027|BC7026",ChangJiaTablet:"TPC7102|TPC7103|TPC7105|TPC7106|TPC7107|TPC7201|TPC7203|TPC7205|TPC7210|TPC7708|TPC7709|TPC7712|TPC7110|TPC8101|TPC8103|TPC8105|TPC8106|TPC8203|TPC8205|TPC8503|TPC9106|TPC9701|TPC97101|TPC97103|TPC97105|TPC97106|TPC97111|TPC97113|TPC97203|TPC97603|TPC97809|TPC97205|TPC10101|TPC10103|TPC10106|TPC10111|TPC10203|TPC10205|TPC10503",GUTablet:"TX-A1301|TX-M9002|Q702|kf026",PointOfViewTablet:"TAB-P506|TAB-navi-7-3G-M|TAB-P517|TAB-P-527|TAB-P701|TAB-P703|TAB-P721|TAB-P731N|TAB-P741|TAB-P825|TAB-P905|TAB-P925|TAB-PR945|TAB-PL1015|TAB-P1025|TAB-PI1045|TAB-P1325|TAB-PROTAB[0-9]+|TAB-PROTAB25|TAB-PROTAB26|TAB-PROTAB27|TAB-PROTAB26XL|TAB-PROTAB2-IPS9|TAB-PROTAB30-IPS9|TAB-PROTAB25XXL|TAB-PROTAB26-IPS10|TAB-PROTAB30-IPS10",OvermaxTablet:"OV-(SteelCore|NewBase|Basecore|Baseone|Exellen|Quattor|EduTab|Solution|ACTION|BasicTab|TeddyTab|MagicTab|Stream|TB-08|TB-09)|Qualcore 1027",HCLTablet:"HCL.*Tablet|Connect-3G-2.0|Connect-2G-2.0|ME Tablet U1|ME Tablet U2|ME Tablet G1|ME Tablet X1|ME Tablet Y2|ME Tablet Sync",DPSTablet:"DPS Dream 9|DPS Dual 7",VistureTablet:"V97 HD|i75 3G|Visture V4( HD)?|Visture V5( HD)?|Visture V10",CrestaTablet:"CTP(-)?810|CTP(-)?818|CTP(-)?828|CTP(-)?838|CTP(-)?888|CTP(-)?978|CTP(-)?980|CTP(-)?987|CTP(-)?988|CTP(-)?989",MediatekTablet:"\\bMT8125|MT8389|MT8135|MT8377\\b",ConcordeTablet:"Concorde([ ]+)?Tab|ConCorde ReadMan",GoCleverTablet:"GOCLEVER TAB|A7GOCLEVER|M1042|M7841|M742|R1042BK|R1041|TAB A975|TAB A7842|TAB A741|TAB A741L|TAB M723G|TAB M721|TAB A1021|TAB I921|TAB R721|TAB I720|TAB T76|TAB R70|TAB R76.2|TAB R106|TAB R83.2|TAB M813G|TAB I721|GCTA722|TAB I70|TAB I71|TAB S73|TAB R73|TAB R74|TAB R93|TAB R75|TAB R76.1|TAB A73|TAB A93|TAB A93.2|TAB T72|TAB R83|TAB R974|TAB R973|TAB A101|TAB A103|TAB A104|TAB A104.2|R105BK|M713G|A972BK|TAB A971|TAB R974.2|TAB R104|TAB R83.3|TAB A1042",ModecomTablet:"FreeTAB 9000|FreeTAB 7.4|FreeTAB 7004|FreeTAB 7800|FreeTAB 2096|FreeTAB 7.5|FreeTAB 1014|FreeTAB 1001 |FreeTAB 8001|FreeTAB 9706|FreeTAB 9702|FreeTAB 7003|FreeTAB 7002|FreeTAB 1002|FreeTAB 7801|FreeTAB 1331|FreeTAB 1004|FreeTAB 8002|FreeTAB 8014|FreeTAB 9704|FreeTAB 1003",VoninoTablet:"\\b(Argus[ _]?S|Diamond[ _]?79HD|Emerald[ _]?78E|Luna[ _]?70C|Onyx[ _]?S|Onyx[ _]?Z|Orin[ _]?HD|Orin[ _]?S|Otis[ _]?S|SpeedStar[ _]?S|Magnet[ _]?M9|Primus[ _]?94[ _]?3G|Primus[ _]?94HD|Primus[ _]?QS|Android.*\\bQ8\\b|Sirius[ _]?EVO[ _]?QS|Sirius[ _]?QS|Spirit[ _]?S)\\b",ECSTablet:"V07OT2|TM105A|S10OT1|TR10CS1",StorexTablet:"eZee[_']?(Tab|Go)[0-9]+|TabLC7|Looney Tunes Tab",VodafoneTablet:"SmartTab([ ]+)?[0-9]+|SmartTabII10|SmartTabII7|VF-1497|VFD 1400",EssentielBTablet:"Smart[ ']?TAB[ ]+?[0-9]+|Family[ ']?TAB2",RossMoorTablet:"RM-790|RM-997|RMD-878G|RMD-974R|RMT-705A|RMT-701|RME-601|RMT-501|RMT-711",iMobileTablet:"i-mobile i-note",TolinoTablet:"tolino tab [0-9.]+|tolino shine",AudioSonicTablet:"\\bC-22Q|T7-QC|T-17B|T-17P\\b",AMPETablet:"Android.* A78 ",SkkTablet:"Android.* (SKYPAD|PHOENIX|CYCLOPS)",TecnoTablet:"TECNO P9|TECNO DP8D",JXDTablet:"Android.* \\b(F3000|A3300|JXD5000|JXD3000|JXD2000|JXD300B|JXD300|S5800|S7800|S602b|S5110b|S7300|S5300|S602|S603|S5100|S5110|S601|S7100a|P3000F|P3000s|P101|P200s|P1000m|P200m|P9100|P1000s|S6600b|S908|P1000|P300|S18|S6600|S9100)\\b",iJoyTablet:"Tablet (Spirit 7|Essentia|Galatea|Fusion|Onix 7|Landa|Titan|Scooby|Deox|Stella|Themis|Argon|Unique 7|Sygnus|Hexen|Finity 7|Cream|Cream X2|Jade|Neon 7|Neron 7|Kandy|Scape|Saphyr 7|Rebel|Biox|Rebel|Rebel 8GB|Myst|Draco 7|Myst|Tab7-004|Myst|Tadeo Jones|Tablet Boing|Arrow|Draco Dual Cam|Aurix|Mint|Amity|Revolution|Finity 9|Neon 9|T9w|Amity 4GB Dual Cam|Stone 4GB|Stone 8GB|Andromeda|Silken|X2|Andromeda II|Halley|Flame|Saphyr 9,7|Touch 8|Planet|Triton|Unique 10|Hexen 10|Memphis 4GB|Memphis 8GB|Onix 10)",FX2Tablet:"FX2 PAD7|FX2 PAD10",XoroTablet:"KidsPAD 701|PAD[ ]?712|PAD[ ]?714|PAD[ ]?716|PAD[ ]?717|PAD[ ]?718|PAD[ ]?720|PAD[ ]?721|PAD[ ]?722|PAD[ ]?790|PAD[ ]?792|PAD[ ]?900|PAD[ ]?9715D|PAD[ ]?9716DR|PAD[ ]?9718DR|PAD[ ]?9719QR|PAD[ ]?9720QR|TelePAD1030|Telepad1032|TelePAD730|TelePAD731|TelePAD732|TelePAD735Q|TelePAD830|TelePAD9730|TelePAD795|MegaPAD 1331|MegaPAD 1851|MegaPAD 2151",ViewsonicTablet:"ViewPad 10pi|ViewPad 10e|ViewPad 10s|ViewPad E72|ViewPad7|ViewPad E100|ViewPad 7e|ViewSonic VB733|VB100a",VerizonTablet:"QTAQZ3|QTAIR7|QTAQTZ3|QTASUN1|QTASUN2|QTAXIA1",OdysTablet:"LOOX|XENO10|ODYS[ -](Space|EVO|Xpress|NOON)|\\bXELIO\\b|Xelio10Pro|XELIO7PHONETAB|XELIO10EXTREME|XELIOPT2|NEO_QUAD10",CaptivaTablet:"CAPTIVA PAD",IconbitTablet:"NetTAB|NT-3702|NT-3702S|NT-3702S|NT-3603P|NT-3603P|NT-0704S|NT-0704S|NT-3805C|NT-3805C|NT-0806C|NT-0806C|NT-0909T|NT-0909T|NT-0907S|NT-0907S|NT-0902S|NT-0902S",TeclastTablet:"T98 4G|\\bP80\\b|\\bX90HD\\b|X98 Air|X98 Air 3G|\\bX89\\b|P80 3G|\\bX80h\\b|P98 Air|\\bX89HD\\b|P98 3G|\\bP90HD\\b|P89 3G|X98 3G|\\bP70h\\b|P79HD 3G|G18d 3G|\\bP79HD\\b|\\bP89s\\b|\\bA88\\b|\\bP10HD\\b|\\bP19HD\\b|G18 3G|\\bP78HD\\b|\\bA78\\b|\\bP75\\b|G17s 3G|G17h 3G|\\bP85t\\b|\\bP90\\b|\\bP11\\b|\\bP98t\\b|\\bP98HD\\b|\\bG18d\\b|\\bP85s\\b|\\bP11HD\\b|\\bP88s\\b|\\bA80HD\\b|\\bA80se\\b|\\bA10h\\b|\\bP89\\b|\\bP78s\\b|\\bG18\\b|\\bP85\\b|\\bA70h\\b|\\bA70\\b|\\bG17\\b|\\bP18\\b|\\bA80s\\b|\\bA11s\\b|\\bP88HD\\b|\\bA80h\\b|\\bP76s\\b|\\bP76h\\b|\\bP98\\b|\\bA10HD\\b|\\bP78\\b|\\bP88\\b|\\bA11\\b|\\bA10t\\b|\\bP76a\\b|\\bP76t\\b|\\bP76e\\b|\\bP85HD\\b|\\bP85a\\b|\\bP86\\b|\\bP75HD\\b|\\bP76v\\b|\\bA12\\b|\\bP75a\\b|\\bA15\\b|\\bP76Ti\\b|\\bP81HD\\b|\\bA10\\b|\\bT760VE\\b|\\bT720HD\\b|\\bP76\\b|\\bP73\\b|\\bP71\\b|\\bP72\\b|\\bT720SE\\b|\\bC520Ti\\b|\\bT760\\b|\\bT720VE\\b|T720-3GE|T720-WiFi",OndaTablet:"\\b(V975i|Vi30|VX530|V701|Vi60|V701s|Vi50|V801s|V719|Vx610w|VX610W|V819i|Vi10|VX580W|Vi10|V711s|V813|V811|V820w|V820|Vi20|V711|VI30W|V712|V891w|V972|V819w|V820w|Vi60|V820w|V711|V813s|V801|V819|V975s|V801|V819|V819|V818|V811|V712|V975m|V101w|V961w|V812|V818|V971|V971s|V919|V989|V116w|V102w|V973|Vi40)\\b[\\s]+|V10 \\b4G\\b",JaytechTablet:"TPC-PA762",BlaupunktTablet:"Endeavour 800NG|Endeavour 1010",DigmaTablet:"\\b(iDx10|iDx9|iDx8|iDx7|iDxD7|iDxD8|iDsQ8|iDsQ7|iDsQ8|iDsD10|iDnD7|3TS804H|iDsQ11|iDj7|iDs10)\\b",EvolioTablet:"ARIA_Mini_wifi|Aria[ _]Mini|Evolio X10|Evolio X7|Evolio X8|\\bEvotab\\b|\\bNeura\\b",LavaTablet:"QPAD E704|\\bIvoryS\\b|E-TAB IVORY|\\bE-TAB\\b",AocTablet:"MW0811|MW0812|MW0922|MTK8382|MW1031|MW0831|MW0821|MW0931|MW0712",MpmanTablet:"MP11 OCTA|MP10 OCTA|MPQC1114|MPQC1004|MPQC994|MPQC974|MPQC973|MPQC804|MPQC784|MPQC780|\\bMPG7\\b|MPDCG75|MPDCG71|MPDC1006|MP101DC|MPDC9000|MPDC905|MPDC706HD|MPDC706|MPDC705|MPDC110|MPDC100|MPDC99|MPDC97|MPDC88|MPDC8|MPDC77|MP709|MID701|MID711|MID170|MPDC703|MPQC1010",CelkonTablet:"CT695|CT888|CT[\\s]?910|CT7 Tab|CT9 Tab|CT3 Tab|CT2 Tab|CT1 Tab|C820|C720|\\bCT-1\\b",WolderTablet:"miTab \\b(DIAMOND|SPACE|BROOKLYN|NEO|FLY|MANHATTAN|FUNK|EVOLUTION|SKY|GOCAR|IRON|GENIUS|POP|MINT|EPSILON|BROADWAY|JUMP|HOP|LEGEND|NEW AGE|LINE|ADVANCE|FEEL|FOLLOW|LIKE|LINK|LIVE|THINK|FREEDOM|CHICAGO|CLEVELAND|BALTIMORE-GH|IOWA|BOSTON|SEATTLE|PHOENIX|DALLAS|IN 101|MasterChef)\\b",MediacomTablet:"M-MPI10C3G|M-SP10EG|M-SP10EGP|M-SP10HXAH|M-SP7HXAH|M-SP10HXBH|M-SP8HXAH|M-SP8MXA",MiTablet:"\\bMI PAD\\b|\\bHM NOTE 1W\\b",NibiruTablet:"Nibiru M1|Nibiru Jupiter One",NexoTablet:"NEXO NOVA|NEXO 10|NEXO AVIO|NEXO FREE|NEXO GO|NEXO EVO|NEXO 3G|NEXO SMART|NEXO KIDDO|NEXO MOBI",LeaderTablet:"TBLT10Q|TBLT10I|TBL-10WDKB|TBL-10WDKBO2013|TBL-W230V2|TBL-W450|TBL-W500|SV572|TBLT7I|TBA-AC7-8G|TBLT79|TBL-8W16|TBL-10W32|TBL-10WKB|TBL-W100",UbislateTablet:"UbiSlate[\\s]?7C",PocketBookTablet:"Pocketbook",KocasoTablet:"\\b(TB-1207)\\b",HisenseTablet:"\\b(F5281|E2371)\\b",Hudl:"Hudl HT7S3|Hudl 2",TelstraTablet:"T-Hub2",GenericTablet:"Android.*\\b97D\\b|Tablet(?!.*PC)|BNTV250A|MID-WCDMA|LogicPD Zoom2|\\bA7EB\\b|CatNova8|A1_07|CT704|CT1002|\\bM721\\b|rk30sdk|\\bEVOTAB\\b|M758A|ET904|ALUMIUM10|Smartfren Tab|Endeavour 1010|Tablet-PC-4|Tagi Tab|\\bM6pro\\b|CT1020W|arc 10HD|\\bTP750\\b|\\bQTAQZ3\\b|WVT101|TM1088|KT107"},oss:{AndroidOS:"Android",BlackBerryOS:"blackberry|\\bBB10\\b|rim tablet os",PalmOS:"PalmOS|avantgo|blazer|elaine|hiptop|palm|plucker|xiino",SymbianOS:"Symbian|SymbOS|Series60|Series40|SYB-[0-9]+|\\bS60\\b",WindowsMobileOS:"Windows CE.*(PPC|Smartphone|Mobile|[0-9]{3}x[0-9]{3})|Windows Mobile|Windows Phone [0-9.]+|WCE;",WindowsPhoneOS:"Windows Phone 10.0|Windows Phone 8.1|Windows Phone 8.0|Windows Phone OS|XBLWP7|ZuneWP7|Windows NT 6.[23]; ARM;",iOS:"\\biPhone.*Mobile|\\biPod|\\biPad|AppleCoreMedia",iPadOS:"CPU OS 13",SailfishOS:"Sailfish",MeeGoOS:"MeeGo",MaemoOS:"Maemo",JavaOS:"J2ME/|\\bMIDP\\b|\\bCLDC\\b",webOS:"webOS|hpwOS",badaOS:"\\bBada\\b",BREWOS:"BREW"},uas:{Chrome:"\\bCrMo\\b|CriOS|Android.*Chrome/[.0-9]* (Mobile)?",Dolfin:"\\bDolfin\\b",Opera:"Opera.*Mini|Opera.*Mobi|Android.*Opera|Mobile.*OPR/[0-9.]+$|Coast/[0-9.]+",Skyfire:"Skyfire",Edge:"\\bEdgiOS\\b|Mobile Safari/[.0-9]* Edge",IE:"IEMobile|MSIEMobile",Firefox:"fennec|firefox.*maemo|(Mobile|Tablet).*Firefox|Firefox.*Mobile|FxiOS",Bolt:"bolt",TeaShark:"teashark",Blazer:"Blazer",Safari:"Version((?!\\bEdgiOS\\b).)*Mobile.*Safari|Safari.*Mobile|MobileSafari",WeChat:"\\bMicroMessenger\\b",UCBrowser:"UC.*Browser|UCWEB",baiduboxapp:"baiduboxapp",baidubrowser:"baidubrowser",DiigoBrowser:"DiigoBrowser",Mercury:"\\bMercury\\b",ObigoBrowser:"Obigo",NetFront:"NF-Browser",GenericBrowser:"NokiaBrowser|OviBrowser|OneBrowser|TwonkyBeamBrowser|SEMC.*Browser|FlyFlow|Minimo|NetFront|Novarra-Vision|MQQBrowser|MicroMessenger",PaleMoon:"Android.*PaleMoon|Mobile.*PaleMoon"},props:{Mobile:"Mobile/[VER]",Build:"Build/[VER]",Version:"Version/[VER]",VendorID:"VendorID/[VER]",iPad:"iPad.*CPU[a-z ]+[VER]",iPhone:"iPhone.*CPU[a-z ]+[VER]",iPod:"iPod.*CPU[a-z ]+[VER]",Kindle:"Kindle/[VER]",Chrome:["Chrome/[VER]","CriOS/[VER]","CrMo/[VER]"],Coast:["Coast/[VER]"],Dolfin:"Dolfin/[VER]",Firefox:["Firefox/[VER]","FxiOS/[VER]"],Fennec:"Fennec/[VER]",Edge:"Edge/[VER]",IE:["IEMobile/[VER];","IEMobile [VER]","MSIE [VER];","Trident/[0-9.]+;.*rv:[VER]"],NetFront:"NetFront/[VER]",NokiaBrowser:"NokiaBrowser/[VER]",Opera:[" OPR/[VER]","Opera Mini/[VER]","Version/[VER]"],"Opera Mini":"Opera Mini/[VER]","Opera Mobi":"Version/[VER]",UCBrowser:["UCWEB[VER]","UC.*Browser/[VER]"],MQQBrowser:"MQQBrowser/[VER]",MicroMessenger:"MicroMessenger/[VER]",baiduboxapp:"baiduboxapp/[VER]",baidubrowser:"baidubrowser/[VER]",SamsungBrowser:"SamsungBrowser/[VER]",Iron:"Iron/[VER]",Safari:["Version/[VER]","Safari/[VER]"],Skyfire:"Skyfire/[VER]",Tizen:"Tizen/[VER]",Webkit:"webkit[ /][VER]",PaleMoon:"PaleMoon/[VER]",SailfishBrowser:"SailfishBrowser/[VER]",Gecko:"Gecko/[VER]",Trident:"Trident/[VER]",Presto:"Presto/[VER]",Goanna:"Goanna/[VER]",iOS:" \\bi?OS\\b [VER][ ;]{1}",Android:"Android [VER]",Sailfish:"Sailfish [VER]",BlackBerry:["BlackBerry[\\w]+/[VER]","BlackBerry.*Version/[VER]","Version/[VER]"],BREW:"BREW [VER]",Java:"Java/[VER]","Windows Phone OS":["Windows Phone OS [VER]","Windows Phone [VER]"],"Windows Phone":"Windows Phone [VER]","Windows CE":"Windows CE/[VER]","Windows NT":"Windows NT [VER]",Symbian:["SymbianOS/[VER]","Symbian/[VER]"],webOS:["webOS/[VER]","hpwOS/[VER];"]},utils:{Bot:"Googlebot|facebookexternalhit|Google-AMPHTML|s~amp-validator|AdsBot-Google|Google Keyword Suggestion|Facebot|YandexBot|YandexMobileBot|bingbot|ia_archiver|AhrefsBot|Ezooms|GSLFbot|WBSearchBot|Twitterbot|TweetmemeBot|Twikle|PaperLiBot|Wotbox|UnwindFetchor|Exabot|MJ12bot|YandexImages|TurnitinBot|Pingdom|contentkingapp|AspiegelBot",MobileBot:"Googlebot-Mobile|AdsBot-Google-Mobile|YahooSeeker/M1A1-R2D2",DesktopMode:"WPDesktop",TV:"SonyDTV|HbbTV",WebKit:"(webkit)[ /]([\\w.]+)",Console:"\\b(Nintendo|Nintendo WiiU|Nintendo 3DS|Nintendo Switch|PLAYSTATION|Xbox)\\b",Watch:"SM-V700"}},g.detectMobileBrowsers={fullPattern:/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i,
shortPattern:/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i,tabletPattern:/android|ipad|playbook|silk/i};var h,i=Object.prototype.hasOwnProperty;return g.FALLBACK_PHONE="UnknownPhone",g.FALLBACK_TABLET="UnknownTablet",g.FALLBACK_MOBILE="UnknownMobile",h="isArray"in Array?Array.isArray:function(a){return"[object Array]"===Object.prototype.toString.call(a)},function(){var a,b,c,e,f,j,k=g.mobileDetectRules;for(a in k.props)if(i.call(k.props,a)){for(b=k.props[a],h(b)||(b=[b]),f=b.length,e=0;e<f;++e)c=b[e],j=c.indexOf("[VER]"),j>=0&&(c=c.substring(0,j)+"([\\w._\\+]+)"+c.substring(j+5)),b[e]=new RegExp(c,"i");k.props[a]=b}d(k.oss),d(k.phones),d(k.tablets),d(k.uas),d(k.utils),k.oss0={WindowsPhoneOS:k.oss.WindowsPhoneOS,WindowsMobileOS:k.oss.WindowsMobileOS}}(),g.findMatch=function(a,b){for(var c in a)if(i.call(a,c)&&a[c].test(b))return c;return null},g.findMatches=function(a,b){var c=[];for(var d in a)i.call(a,d)&&a[d].test(b)&&c.push(d);return c},g.getVersionStr=function(a,b){var c,d,e,f,h=g.mobileDetectRules.props;if(i.call(h,a))for(c=h[a],e=c.length,d=0;d<e;++d)if(f=c[d].exec(b),null!==f)return f[1];return null},g.getVersion=function(a,b){var c=g.getVersionStr(a,b);return c?g.prepareVersionNo(c):NaN},g.prepareVersionNo=function(a){var b;return b=a.split(/[a-z._ \/\-]/i),1===b.length&&(a=b[0]),b.length>1&&(a=b[0]+".",b.shift(),a+=b.join("")),Number(a)},g.isMobileFallback=function(a){return g.detectMobileBrowsers.fullPattern.test(a)||g.detectMobileBrowsers.shortPattern.test(a.substr(0,4))},g.isTabletFallback=function(a){return g.detectMobileBrowsers.tabletPattern.test(a)},g.prepareDetectionCache=function(a,c,d){if(a.mobile===b){var e,h,i;return(h=g.findMatch(g.mobileDetectRules.tablets,c))?(a.mobile=a.tablet=h,void(a.phone=null)):(e=g.findMatch(g.mobileDetectRules.phones,c))?(a.mobile=a.phone=e,void(a.tablet=null)):void(g.isMobileFallback(c)?(i=f.isPhoneSized(d),i===b?(a.mobile=g.FALLBACK_MOBILE,a.tablet=a.phone=null):i?(a.mobile=a.phone=g.FALLBACK_PHONE,a.tablet=null):(a.mobile=a.tablet=g.FALLBACK_TABLET,a.phone=null)):g.isTabletFallback(c)?(a.mobile=a.tablet=g.FALLBACK_TABLET,a.phone=null):a.mobile=a.tablet=a.phone=null)}},g.mobileGrade=function(a){var b=null!==a.mobile();return a.os("iOS")&&a.version("iPad")>=4.3||a.os("iOS")&&a.version("iPhone")>=3.1||a.os("iOS")&&a.version("iPod")>=3.1||a.version("Android")>2.1&&a.is("Webkit")||a.version("Windows Phone OS")>=7||a.is("BlackBerry")&&a.version("BlackBerry")>=6||a.match("Playbook.*Tablet")||a.version("webOS")>=1.4&&a.match("Palm|Pre|Pixi")||a.match("hp.*TouchPad")||a.is("Firefox")&&a.version("Firefox")>=12||a.is("Chrome")&&a.is("AndroidOS")&&a.version("Android")>=4||a.is("Skyfire")&&a.version("Skyfire")>=4.1&&a.is("AndroidOS")&&a.version("Android")>=2.3||a.is("Opera")&&a.version("Opera Mobi")>11&&a.is("AndroidOS")||a.is("MeeGoOS")||a.is("Tizen")||a.is("Dolfin")&&a.version("Bada")>=2||(a.is("UC Browser")||a.is("Dolfin"))&&a.version("Android")>=2.3||a.match("Kindle Fire")||a.is("Kindle")&&a.version("Kindle")>=3||a.is("AndroidOS")&&a.is("NookTablet")||a.version("Chrome")>=11&&!b||a.version("Safari")>=5&&!b||a.version("Firefox")>=4&&!b||a.version("MSIE")>=7&&!b||a.version("Opera")>=10&&!b?"A":a.os("iOS")&&a.version("iPad")<4.3||a.os("iOS")&&a.version("iPhone")<3.1||a.os("iOS")&&a.version("iPod")<3.1||a.is("Blackberry")&&a.version("BlackBerry")>=5&&a.version("BlackBerry")<6||a.version("Opera Mini")>=5&&a.version("Opera Mini")<=6.5&&(a.version("Android")>=2.3||a.is("iOS"))||a.match("NokiaN8|NokiaC7|N97.*Series60|Symbian/3")||a.version("Opera Mobi")>=11&&a.is("SymbianOS")?"B":(a.version("BlackBerry")<5||a.match("MSIEMobile|Windows CE.*Mobile")||a.version("Windows Mobile")<=5.2,"C")},g.detectOS=function(a){return g.findMatch(g.mobileDetectRules.oss0,a)||g.findMatch(g.mobileDetectRules.oss,a)},g.getDeviceSmallerSide=function(){return window.screen.width<window.screen.height?window.screen.width:window.screen.height},f.prototype={constructor:f,mobile:function(){return g.prepareDetectionCache(this._cache,this.ua,this.maxPhoneWidth),this._cache.mobile},phone:function(){return g.prepareDetectionCache(this._cache,this.ua,this.maxPhoneWidth),this._cache.phone},tablet:function(){return g.prepareDetectionCache(this._cache,this.ua,this.maxPhoneWidth),this._cache.tablet},userAgent:function(){return this._cache.userAgent===b&&(this._cache.userAgent=g.findMatch(g.mobileDetectRules.uas,this.ua)),this._cache.userAgent},userAgents:function(){return this._cache.userAgents===b&&(this._cache.userAgents=g.findMatches(g.mobileDetectRules.uas,this.ua)),this._cache.userAgents},os:function(){return this._cache.os===b&&(this._cache.os=g.detectOS(this.ua)),this._cache.os},version:function(a){return g.getVersion(a,this.ua)},versionStr:function(a){return g.getVersionStr(a,this.ua)},is:function(b){return c(this.userAgents(),b)||a(b,this.os())||a(b,this.phone())||a(b,this.tablet())||c(g.findMatches(g.mobileDetectRules.utils,this.ua),b)},match:function(a){return a instanceof RegExp||(a=new RegExp(a,"i")),a.test(this.ua)},isPhoneSized:function(a){return f.isPhoneSized(a||this.maxPhoneWidth)},mobileGrade:function(){return this._cache.grade===b&&(this._cache.grade=g.mobileGrade(this)),this._cache.grade}},"undefined"!=typeof window&&window.screen?f.isPhoneSized=function(a){return a<0?b:g.getDeviceSmallerSide()<=a}:f.isPhoneSized=function(){},f._impl=g,f.version="1.4.5 2021-03-13",f})}(function(a){if("undefined"!=typeof module&&module.exports)return function(a){module.exports=a()};if("function"==typeof define&&define.amd)return define;if("undefined"!=typeof window)return function(a){window.MobileDetect=a()};throw new Error("unknown environment")}());var ai_lists=!0,ai_block_class_def="code-block";
if("undefined"!=typeof ai_lists){function X(b,e){for(var n=[];b=b.previousElementSibling;)("undefined"==typeof e||b.matches(e))&&n.push(b);return n}function fa(b,e){for(var n=[];b=b.nextElementSibling;)("undefined"==typeof e||b.matches(e))&&n.push(b);return n}var host_regexp=RegExp(":\\/\\/(.[^/:]+)","i");function ha(b){b=b.match(host_regexp);return null!=b&&1<b.length&&"string"===typeof b[1]&&0<b[1].length?b[1].toLowerCase():null}function Q(b){return b.includes(":")?(b=b.split(":"),1E3*(3600*parseInt(b[0])+
60*parseInt(b[1])+parseInt(b[2]))):null}function Y(b){try{var e=Date.parse(b);isNaN(e)&&(e=null)}catch(n){e=null}if(null==e&&b.includes(" ")){b=b.split(" ");try{e=Date.parse(b[0]),e+=Q(b[1]),isNaN(e)&&(e=null)}catch(n){e=null}}return e}function Z(){null==document.querySelector("#ai-iab-tcf-bar")&&null==document.querySelector(".ai-list-manual")||"function"!=typeof __tcfapi||"function"!=typeof ai_load_blocks||"undefined"!=typeof ai_iab_tcf_callback_installed||(__tcfapi("addEventListener",2,function(b,
e){e&&"useractioncomplete"===b.eventStatus&&(ai_tcData=b,ai_load_blocks(),b=document.querySelector("#ai-iab-tcf-status"),null!=b&&(b.textContent="IAB TCF 2.0 DATA LOADED"),b=document.querySelector("#ai-iab-tcf-bar"),null!=b&&(b.classList.remove("status-error"),b.classList.add("status-ok")))}),ai_iab_tcf_callback_installed=!0)}ai_process_lists=function(b){function e(a,c,k){if(0==a.length){if("!@!"==k)return!0;c!=k&&("true"==k.toLowerCase()?k=!0:"false"==k.toLowerCase()&&(k=!1));return c==k}if("object"!=
typeof c&&"array"!=typeof c)return!1;var l=a[0];a=a.slice(1);if("*"==l)for(let [,p]of Object.entries(c)){if(e(a,p,k))return!0}else if(l in c)return e(a,c[l],k);return!1}function n(a,c,k){if("object"!=typeof a||-1==c.indexOf("["))return!1;c=c.replace(/]| /gi,"").split("[");return e(c,a,k)}function z(){if("function"==typeof __tcfapi){var a=document.querySelector("#ai-iab-tcf-status"),c=document.querySelector("#ai-iab-tcf-bar");null!=a&&(a.textContent="IAB TCF 2.0 DETECTED");__tcfapi("getTCData",2,function(k,
l){l?(null!=c&&(c.classList.remove("status-error"),c.classList.add("status-ok")),"tcloaded"==k.eventStatus||"useractioncomplete"==k.eventStatus)?(ai_tcData=k,k.gdprApplies?null!=a&&(a.textContent="IAB TCF 2.0 DATA LOADED"):null!=a&&(a.textContent="IAB TCF 2.0 GDPR DOES NOT APPLY"),null!=c&&(c.classList.remove("status-error"),c.classList.add("status-ok")),setTimeout(function(){ai_process_lists()},10)):"cmpuishown"==k.eventStatus&&(ai_cmpuishown=!0,null!=a&&(a.textContent="IAB TCF 2.0 CMP UI SHOWN"),
null!=c&&(c.classList.remove("status-error"),c.classList.add("status-ok"))):(null!=a&&(a.textContent="IAB TCF 2.0 __tcfapi getTCData failed"),null!=c&&(c.classList.remove("status-ok"),c.classList.add("status-error")))})}}function C(a){"function"==typeof __tcfapi?(ai_tcfapi_found=!0,"undefined"==typeof ai_iab_tcf_callback_installed&&Z(),"undefined"==typeof ai_tcData_requested&&(ai_tcData_requested=!0,z(),cookies_need_tcData=!0)):a&&("undefined"==typeof ai_tcfapi_found&&(ai_tcfapi_found=!1,setTimeout(function(){ai_process_lists()},
10)),a=document.querySelector("#ai-iab-tcf-status"),null!=a&&(a.textContent="IAB TCF 2.0 MISSING: __tcfapi function not found"),a=document.querySelector("#ai-iab-tcf-bar"),null!=a&&(a.classList.remove("status-ok"),a.classList.add("status-error")))}if(null==b)b=document.querySelectorAll("div.ai-list-data, meta.ai-list-data");else{window.jQuery&&window.jQuery.fn&&b instanceof jQuery&&(b=Array.prototype.slice.call(b));var x=[];b.forEach((a,c)=>{a.matches(".ai-list-data")?x.push(a):(a=a.querySelectorAll(".ai-list-data"),
a.length&&a.forEach((k,l)=>{x.push(k)}))});b=x}if(b.length){b.forEach((a,c)=>{a.classList.remove("ai-list-data")});var L=ia(window.location.search);if(null!=L.referrer)var A=L.referrer;else A=document.referrer,""!=A&&(A=ha(A));var R=window.navigator.userAgent,S=R.toLowerCase(),aa=navigator.language,M=aa.toLowerCase();if("undefined"!==typeof MobileDetect)var ba=new MobileDetect(R);b.forEach((a,c)=>{var k=document.cookie.split(";");k.forEach(function(f,h){k[h]=f.trim()});c=a.closest("div."+ai_block_class_def);
var l=!0;if(a.hasAttribute("referer-list")){var p=a.getAttribute("referer-list");p=b64d(p).split(",");var v=a.getAttribute("referer-list-type"),E=!1;p.every((f,h)=>{f=f.trim();if(""==f)return!0;if("*"==f.charAt(0))if("*"==f.charAt(f.length-1)){if(f=f.substr(1,f.length-2),-1!=A.indexOf(f))return E=!0,!1}else{if(f=f.substr(1),A.substr(-f.length)==f)return E=!0,!1}else if("*"==f.charAt(f.length-1)){if(f=f.substr(0,f.length-1),0==A.indexOf(f))return E=!0,!1}else if("#"==f){if(""==A)return E=!0,!1}else if(f==
A)return E=!0,!1;return!0});var r=E;switch(v){case "B":r&&(l=!1);break;case "W":r||(l=!1)}}if(l&&a.hasAttribute("client-list")&&"undefined"!==typeof ba)switch(p=a.getAttribute("client-list"),p=b64d(p).split(","),v=a.getAttribute("client-list-type"),r=!1,p.every((f,h)=>{if(""==f.trim())return!0;f.split("&&").every((d,t)=>{t=!0;var w=!1;for(d=d.trim();"!!"==d.substring(0,2);)t=!t,d=d.substring(2);"language:"==d.substring(0,9)&&(w=!0,d=d.substring(9).toLowerCase());var q=!1;w?"*"==d.charAt(0)?"*"==d.charAt(d.length-
1)?(d=d.substr(1,d.length-2).toLowerCase(),-1!=M.indexOf(d)&&(q=!0)):(d=d.substr(1).toLowerCase(),M.substr(-d.length)==d&&(q=!0)):"*"==d.charAt(d.length-1)?(d=d.substr(0,d.length-1).toLowerCase(),0==M.indexOf(d)&&(q=!0)):d==M&&(q=!0):"*"==d.charAt(0)?"*"==d.charAt(d.length-1)?(d=d.substr(1,d.length-2).toLowerCase(),-1!=S.indexOf(d)&&(q=!0)):(d=d.substr(1).toLowerCase(),S.substr(-d.length)==d&&(q=!0)):"*"==d.charAt(d.length-1)?(d=d.substr(0,d.length-1).toLowerCase(),0==S.indexOf(d)&&(q=!0)):ba.is(d)&&
(q=!0);return(r=q?t:!t)?!0:!1});return r?!1:!0}),v){case "B":r&&(l=!1);break;case "W":r||(l=!1)}var N=p=!1;for(v=1;2>=v;v++)if(l){switch(v){case 1:var g=a.getAttribute("cookie-list");break;case 2:g=a.getAttribute("parameter-list")}if(null!=g){g=b64d(g);switch(v){case 1:var y=a.getAttribute("cookie-list-type");break;case 2:y=a.getAttribute("parameter-list-type")}g=g.replace("tcf-gdpr","tcf-v2[gdprApplies]=true");g=g.replace("tcf-no-gdpr","tcf-v2[gdprApplies]=false");g=g.replace("tcf-google","tcf-v2[vendor][consents][755]=true && tcf-v2[purpose][consents][1]=true");
g=g.replace("tcf-no-google","!!tcf-v2[vendor][consents][755]");g=g.replace("tcf-media.net","tcf-v2[vendor][consents][142]=true && tcf-v2[purpose][consents][1]=true");g=g.replace("tcf-no-media.net","!!tcf-v2[vendor][consents][142]");g=g.replace("tcf-amazon","tcf-v2[vendor][consents][793]=true && tcf-v2[purpose][consents][1]=true");g=g.replace("tcf-no-amazon","!!tcf-v2[vendor][consents][793]");g=g.replace("tcf-ezoic","tcf-v2[vendor][consents][347]=true && tcf-v2[purpose][consents][1]=true");g=g.replace("tcf-no-ezoic",
"!!tcf-v2[vendor][consents][347]");var F=g.split(","),ca=[];k.forEach(function(f){f=f.split("=");try{var h=JSON.parse(decodeURIComponent(f[1]))}catch(d){h=decodeURIComponent(f[1])}ca[f[0]]=h});r=!1;var I=a;F.every((f,h)=>{f.split("&&").every((d,t)=>{t=!0;for(d=d.trim();"!!"==d.substring(0,2);)t=!t,d=d.substring(2);var w=d,q="!@!",T="tcf-v2"==w&&"!@!"==q,B=-1!=d.indexOf("["),J=0==d.indexOf("tcf-v2")||0==d.indexOf("euconsent-v2");J=J&&(B||T);-1!=d.indexOf("=")&&(q=d.split("="),w=q[0],q=q[1],B=-1!=w.indexOf("["),
J=(J=0==w.indexOf("tcf-v2")||0==w.indexOf("euconsent-v2"))&&(B||T));if(J)document.querySelector("#ai-iab-tcf-status"),B=document.querySelector("#ai-iab-tcf-bar"),null!=B&&(B.style.display="block"),T&&"boolean"==typeof ai_tcfapi_found?r=ai_tcfapi_found?t:!t:"object"==typeof ai_tcData?(null!=B&&(B.classList.remove("status-error"),B.classList.add("status-ok")),w=w.replace(/]| /gi,"").split("["),w.shift(),r=(w=e(w,ai_tcData,q))?t:!t):"undefined"==typeof ai_tcfapi_found&&(I.classList.add("ai-list-data"),
N=!0,"function"==typeof __tcfapi?C(!1):"undefined"==typeof ai_tcData_retrying&&(ai_tcData_retrying=!0,setTimeout(function(){"function"==typeof __tcfapi?C(!1):setTimeout(function(){"function"==typeof __tcfapi?C(!1):setTimeout(function(){C(!0)},3E3)},1E3)},600)));else if(B)r=(w=n(ca,w,q))?t:!t;else{var U=!1;"!@!"==q?k.every(function(ja){return ja.split("=")[0]==d?(U=!0,!1):!0}):U=-1!=k.indexOf(d);r=U?t:!t}return r?!0:!1});return r?!1:!0});r&&(N=!1,I.classList.remove("ai-list-data"));switch(y){case "B":r&&
(l=!1);break;case "W":r||(l=!1)}}}a.classList.contains("ai-list-manual")&&(l?(I.classList.remove("ai-list-data"),I.classList.remove("ai-list-manual")):(p=!0,I.classList.add("ai-list-data")));(l||!p&&!N)&&a.hasAttribute("data-debug-info")&&(g=document.querySelector("."+a.dataset.debugInfo),null!=g&&(g=g.parentElement,null!=g&&g.classList.contains("ai-debug-info")&&g.remove()));y=X(a,".ai-debug-bar.ai-debug-lists");var ka=""==A?"#":A;0!=y.length&&y.forEach((f,h)=>{h=f.querySelector(".ai-debug-name.ai-list-info");
null!=h&&(h.textContent=ka,h.title=R+"\n"+aa);h=f.querySelector(".ai-debug-name.ai-list-status");null!=h&&(h.textContent=l?ai_front.visible:ai_front.hidden)});g=!1;if(l&&a.hasAttribute("scheduling-start")&&a.hasAttribute("scheduling-end")&&a.hasAttribute("scheduling-days")){var u=a.getAttribute("scheduling-start");v=a.getAttribute("scheduling-end");y=a.getAttribute("scheduling-days");g=!0;u=b64d(u);F=b64d(v);var V=parseInt(a.getAttribute("scheduling-fallback")),O=parseInt(a.getAttribute("gmt"));if(u.includes("-")||
F.includes("-"))P=Y(u)+O,K=Y(F)+O;else var P=Q(u),K=Q(F);P??=0;K??=0;var W=b64d(y).split(",");y=a.getAttribute("scheduling-type");var D=(new Date).getTime()+O;v=new Date(D);var G=v.getDay();0==G?G=6:G--;u.includes("-")||F.includes("-")||(u=(new Date(v.getFullYear(),v.getMonth(),v.getDate())).getTime()+O,D-=u,0>D&&(D+=864E5));scheduling_start_date_ok=D>=P;scheduling_end_date_ok=0==K||D<K;u=scheduling_start_date_ok&&scheduling_end_date_ok&&W.includes(G.toString());switch(y){case "B":u=!u}u||(l=!1);
var la=v.toISOString().split(".")[0].replace("T"," ");y=X(a,".ai-debug-bar.ai-debug-scheduling");0!=y.length&&y.forEach((f,h)=>{h=f.querySelector(".ai-debug-name.ai-scheduling-info");null!=h&&(h.textContent=la+" "+G+" current_time: "+Math.floor(D.toString()/1E3)+"  start_date:"+Math.floor(P/1E3).toString()+"=>"+scheduling_start_date_ok.toString()+" end_date:"+Math.floor(K/1E3).toString()+"=>"+scheduling_end_date_ok.toString()+" days:"+W.toString()+"=>"+W.includes(G.toString()).toString());h=f.querySelector(".ai-debug-name.ai-scheduling-status");
null!=h&&(h.textContent=l?ai_front.visible:ai_front.hidden);l||0==V||(f.classList.remove("ai-debug-scheduling"),f.classList.add("ai-debug-fallback"),h=f.querySelector(".ai-debug-name.ai-scheduling-status"),null!=h&&(h.textContent=ai_front.fallback+" = "+V))})}if(p||!l&&N)return!0;a.style.visibility="";a.style.position="";a.style.width="";a.style.height="";a.style.zIndex="";if(l){if(null!=c&&(c.style.visibility="",c.classList.contains("ai-remove-position")&&(c.style.position="")),a.hasAttribute("data-code")){p=
b64d(a.dataset.code);u=document.createRange();g=!0;try{H=u.createContextualFragment(p)}catch(f){g=!1}g&&(null!=a.closest("head")?(a.parentNode.insertBefore(H,a.nextSibling),a.remove()):a.append(H));da(a)}}else if(g&&!u&&0!=V){null!=c&&(c.style.visibility="",c.classList.contains("ai-remove-position")&&c.css({position:""}));p=fa(a,".ai-fallback");0!=p.length&&p.forEach((f,h)=>{f.classList.remove("ai-fallback")});if(a.hasAttribute("data-fallback-code")){p=b64d(a.dataset.fallbackCode);u=document.createRange();
g=!0;try{var H=u.createContextualFragment(p)}catch(f){g=!1}g&&a.append(H);da(a)}else a.style.display="none",null!=c&&null==c.querySelector(".ai-debug-block")&&c.hasAttribute("style")&&-1==c.getAttribute("style").indexOf("height:")&&(c.style.display="none");null!=c&&c.hasAttribute("data-ai")&&(c.getAttribute("data-ai"),a.hasAttribute("fallback-tracking")&&(H=a.getAttribute("fallback-tracking"),c.setAttribute("data-ai-"+a.getAttribute("fallback_level"),H)))}else a.style.display="none",null!=c&&(c.removeAttribute("data-ai"),
c.classList.remove("ai-track"),null!=c.querySelector(".ai-debug-block")?(c.style.visibility="",c.classList.remove("ai-close"),c.classList.contains("ai-remove-position")&&(c.style.position="")):c.hasAttribute("style")&&-1==c.getAttribute("style").indexOf("height:")&&(c.style.display="none"));a.setAttribute("data-code","");a.setAttribute("data-fallback-code","");null!=c&&c.classList.remove("ai-list-block")})}};function ea(b){b=`; ${document.cookie}`.split(`; ${b}=`);if(2===b.length)return b.pop().split(";").shift()}
function ma(b,e,n){ea(b)&&(document.cookie=b+"="+(e?";path="+e:"")+(n?";domain="+n:"")+";expires=Thu, 01 Jan 1970 00:00:01 GMT")}function m(b){ea(b)&&(ma(b,"/",window.location.hostname),document.cookie=b+"=; Path=/; Expires=Thu, 01 Jan 1970 00:00:01 GMT;")}(function(b){"complete"===document.readyState||"loading"!==document.readyState&&!document.documentElement.doScroll?b():document.addEventListener("DOMContentLoaded",b)})(function(){setTimeout(function(){ai_process_lists();setTimeout(function(){Z();
if("function"==typeof ai_load_blocks){document.addEventListener("cmplzEnableScripts",e);document.addEventListener("cmplz_event_marketing",e);function e(n){"cmplzEnableScripts"!=n.type&&"all"!==n.consentLevel||ai_load_blocks()}document.addEventListener("cmplz_enable_category",function(n){"marketing"===n.detail.category&&ai_load_blocks()})}},50);var b=document.querySelector(".ai-debug-page-type");null!=b&&b.addEventListener("dblclick",e=>{e=document.querySelector("#ai-iab-tcf-status");null!=e&&(e.textContent=
"CONSENT COOKIES");e=document.querySelector("#ai-iab-tcf-bar");null!=e&&(e.style.display="block")});b=document.querySelector("#ai-iab-tcf-bar");null!=b&&b.addEventListener("click",e=>{m("euconsent-v2");m("__lxG__consent__v2");m("__lxG__consent__v2_daisybit");m("__lxG__consent__v2_gdaisybit");m("CookieLawInfoConsent");m("cookielawinfo-checkbox-advertisement");m("cookielawinfo-checkbox-analytics");m("cookielawinfo-checkbox-necessary");m("complianz_policy_id");m("complianz_consent_status");m("cmplz_marketing");
m("cmplz_consent_status");m("cmplz_preferences");m("cmplz_statistics-anonymous");m("cmplz_choice");m("cmplz_banner-status");m("cmplz_functional");m("cmplz_policy_id");m("cmplz_statistics");m("moove_gdpr_popup");m("real_cookie_banner-blog:1-tcf");m("real_cookie_banner-blog:1");e=document.querySelector("#ai-iab-tcf-status");null!=e&&(e.textContent="CONSENT COOKIES DELETED")})},5)});function da(b){setTimeout(function(){"function"==typeof ai_process_rotations_in_element&&ai_process_rotations_in_element(b);
"function"==typeof ai_process_lists&&ai_process_lists();"function"==typeof ai_process_ip_addresses&&ai_process_ip_addresses();"function"==typeof ai_process_filter_hooks&&ai_process_filter_hooks();"function"==typeof ai_adb_process_blocks&&ai_adb_process_blocks(b);"function"==typeof ai_process_impressions&&1==ai_tracking_finished&&ai_process_impressions();"function"==typeof ai_install_click_trackers&&1==ai_tracking_finished&&ai_install_click_trackers();"function"==typeof ai_install_close_buttons&&ai_install_close_buttons(document)},
5)}function ia(b){var e=b?b.split("?")[1]:window.location.search.slice(1);b={};if(e){e=e.split("#")[0];e=e.split("&");for(var n=0;n<e.length;n++){var z=e[n].split("="),C=void 0,x=z[0].replace(/\[\d*\]/,function(L){C=L.slice(1,-1);return""});z="undefined"===typeof z[1]?"":z[1];x=x.toLowerCase();z=z.toLowerCase();b[x]?("string"===typeof b[x]&&(b[x]=[b[x]]),"undefined"===typeof C?b[x].push(z):b[x][C]=z):b[x]=z}}return b}};
ai_run_589747277616 = function(){
ai_document_write=document.write;document.write=function(a){"interactive"==document.readyState?(console.error("document.write called after page load: ",a),"undefined"!=typeof ai_js_errors&&ai_js_errors.push(["document.write called after page load",a,0])):ai_document_write.call(document,a)};
ai_insert ('before', '#nv-footer', b64d ('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'));
};
if (document.readyState === 'complete' || (document.readyState !== 'loading' && !document.documentElement.doScroll)) ai_run_589747277616 (); else document.addEventListener ('DOMContentLoaded', ai_run_589747277616);
ai_js_code = true;
</script>
          <div class="sticky-share-buttons">
        <ul class="entry-meta-social-links-list">
                     <li><a data-wpel-link="external" href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fdeveloper.nvidia.com%2Fblog%2Fscaling-language-model-training-to-a-trillion-parameters-using-megatron%2F" class="for-linkedin" target="_blank" rel="follow">L</a></li>
			         <li><a data-wpel-link="external" href="https://twitter.com/intent/tweet?text=Scaling+Language+Model+Training+to+a+Trillion+Parameters+Using+Megatron+%7C+NVIDIA+Technical+Blog+https%3A%2F%2Fdeveloper.nvidia.com%2Fblog%2Fscaling-language-model-training-to-a-trillion-parameters-using-megatron%2F" class="for-twitter" target="_blank" rel="follow">T</a></li>
			         <li><a data-wpel-link="external" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fdeveloper.nvidia.com%2Fblog%2Fscaling-language-model-training-to-a-trillion-parameters-using-megatron%2F" class="for-facebook" target="_blank" rel="follow">F</a></li>
                     <li><a data-wpel-link="external" href="https://www.reddit.com/submit?url=https%3A%2F%2Fdeveloper.nvidia.com%2Fblog%2Fscaling-language-model-training-to-a-trillion-parameters-using-megatron%2F&amp;title=Scaling+Language+Model+Training+to+a+Trillion+Parameters+Using+Megatron+%7C+NVIDIA+Technical+Blog" class="for-reddit" target="_blank" rel="follow">R</a></li>
			         <li><a href="mailto:?subject=I'd like to share a link with you&body=https%3A%2F%2Fdeveloper.nvidia.com%2Fblog%2Fscaling-language-model-training-to-a-trillion-parameters-using-megatron%2F" class="for-mail">E</a></li>
			       </ul>      </div>
      <script type="text/javascript">window.NREUM||(NREUM={});NREUM.info={"beacon":"bam.nr-data.net","licenseKey":"NRJS-2b0defbeb07862260b2","applicationID":"745178505","transactionName":"Z10BbBRRW0QCAExfWF4XIlsSWVpZTApWUlJI","queueTime":0,"applicationTime":1896,"atts":"SxoCGlxLSEo=","errorBeacon":"bam.nr-data.net","agent":""}</script></body>
</html>
