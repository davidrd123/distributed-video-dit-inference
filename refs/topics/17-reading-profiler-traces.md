# Topic 17: Reading Nsight / torch.profiler traces

Profiling is the primary tool for understanding where time is spent in distributed GPU workloads. PyTorch's built-in profiler integrates with TensorBoard for visualization, while NVIDIA Nsight Compute provides kernel-level analysis including roofline positioning.

## Resources

<!-- Resource IDs from manifest belonging to this topic -->
| ID | Title | Priority | Status |
|----|-------|----------|--------|
| pytorch-profiler-tensorboard | PyTorch Profiler with TensorBoard | medium | pending |
| profiling-torch-compile | Profiling torch.compile performance | medium | pending |
| gpu-mode-lecture-1 | GPU MODE Lecture 1: How to Profile CUDA Kernels in PyTorch | low | link_only |
| nsight-roofline | NVIDIA Nsight Compute: Roofline Analysis | low | pending |

## Synthesis

<!-- To be filled during study -->

### Mental model

### Key concepts

### Cross-resource agreement / disagreement

### Practical checklist

### Gotchas and failure modes

### Experiments to run
