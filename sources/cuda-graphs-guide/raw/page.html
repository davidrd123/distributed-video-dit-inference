

<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>4.2. CUDA Graphs &#8212; CUDA Programming Guide</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/nvidia-sphinx-theme.css?v=933278ad" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=767de534" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/tables.css?v=0bf25c72" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />



    <script rel="preload" src="../_static/modal-table.js"></script>
    <script src="../_static/documentation_options.js?v=7fa8b4cb"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scrollspy-patch.js?v=edc4054a"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=65e89d2a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '04-special-topics/cuda-graphs';</script>
    <script src="../_static/version-patch.js?v=3e13fdd2"></script>

    <link rel="icon" href="../_static/favicon.ico"/>

    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="4.3. Stream-Ordered Memory Allocator" href="stream-ordered-memory-allocation.html" />
    <link rel="prev" title="4.1. Unified Memory" href="unified-memory.html" />


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
    <meta name="docbuild:last-update" content="Dec 12, 2025"/>


  </head>

  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>


  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../contents.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="CUDA Programming Guide - Home"/>
    <img src="../_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="CUDA Programming Guide - Home"/>
  
  
    <p class="title logo__title">CUDA Programming Guide</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">


<div>
  <ul class="bd-navbar-elements navbar-nav">
  
    <li class="nav-item pst-header-nav-item">
      
      <span>v13.1 |</span>
      
    </li>
  
    <li class="nav-item pst-header-nav-item">
      
      <a class="nav-link nav-external" href="https://docs.nvidia.com/cuda/cuda-programming-guide/pdf/cuda-programming-guide.pdf">PDF</a>
      
    </li>
  
    <li class="nav-item pst-header-nav-item">
      
      <span>|</span>
      
    </li>
  
    <li class="nav-item pst-header-nav-item">
      
      <a class="nav-link nav-external" href="https://developer.nvidia.com/cuda-toolkit-archive">Archive</a>
      
    </li>
  
  </ul>
</div>
</div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        



  
    
  

<a class="navbar-brand logo" href="../contents.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="CUDA Programming Guide - Home"/>
    <img src="../_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="CUDA Programming Guide - Home"/>
  
  
    <p class="title logo__title">CUDA Programming Guide</p>
  
</a>


  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">


<div>
  <ul class="bd-navbar-elements navbar-nav">
  
    <li class="nav-item pst-header-nav-item">
      
      <span>v13.1 |</span>
      
    </li>
  
    <li class="nav-item pst-header-nav-item">
      
      <a class="nav-link nav-external" href="https://docs.nvidia.com/cuda/cuda-programming-guide/pdf/cuda-programming-guide.pdf">PDF</a>
      
    </li>
  
    <li class="nav-item pst-header-nav-item">
      
      <span>|</span>
      
    </li>
  
    <li class="nav-item pst-header-nav-item">
      
      <a class="nav-link nav-external" href="https://developer.nvidia.com/cuda-toolkit-archive">Archive</a>
      
    </li>
  
  </ul>
</div>
</div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">



<nav class="bd-docs-nav bd-links"
     aria-label="Table of Contents">
  <p class="bd-links__title" role="heading" aria-level="1">Table of Contents</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html">CUDA Programming Guide</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../part1.html">1. Introduction to CUDA</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../01-introduction/introduction.html">1.1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01-introduction/programming-model.html">1.2. Programming Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01-introduction/cuda-platform.html">1.3. The CUDA platform</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../part2.html">2. Programming GPUs in CUDA</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../02-basics/intro-to-cuda-cpp.html">2.1. Intro to CUDA C++</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02-basics/writing-cuda-kernels.html">2.2. Writing CUDA SIMT Kernels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02-basics/asynchronous-execution.html">2.3. Asynchronous Execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02-basics/understanding-memory.html">2.4. Unified and System Memory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02-basics/nvcc.html">2.5. NVCC: The NVIDIA CUDA Compiler</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../part3.html">3. Advanced CUDA</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../03-advanced/advanced-host-programming.html">3.1. Advanced CUDA APIs and Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03-advanced/advanced-kernel-programming.html">3.2. Advanced Kernel Programming</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03-advanced/driver-api.html">3.3. The CUDA Driver API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03-advanced/multi-gpu-systems.html">3.4. Programming Systems with Multiple GPUs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03-advanced/feature-survey.html">3.5. A Tour of CUDA Features</a></li>
</ul>
</details></li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="../part4.html">4. CUDA Features</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="unified-memory.html">4.1. Unified Memory</a></li>
<li class="toctree-l3 current active"><a class="current reference internal" href="#">4.2. CUDA Graphs</a></li>
<li class="toctree-l3"><a class="reference internal" href="stream-ordered-memory-allocation.html">4.3. Stream-Ordered Memory Allocator</a></li>
<li class="toctree-l3"><a class="reference internal" href="cooperative-groups.html">4.4. Cooperative Groups</a></li>
<li class="toctree-l3"><a class="reference internal" href="programmatic-dependent-launch.html">4.5. Programmatic Dependent Launch and Synchronization</a></li>
<li class="toctree-l3"><a class="reference internal" href="green-contexts.html">4.6. Green Contexts</a></li>
<li class="toctree-l3"><a class="reference internal" href="lazy-loading.html">4.7. Lazy Loading</a></li>
<li class="toctree-l3"><a class="reference internal" href="error-log-management.html">4.8. Error Log Management</a></li>
<li class="toctree-l3"><a class="reference internal" href="async-barriers.html">4.9. Asynchronous Barriers</a></li>
<li class="toctree-l3"><a class="reference internal" href="pipelines.html">4.10. Pipelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="async-copies.html">4.11. Asynchronous Data Copies</a></li>
<li class="toctree-l3"><a class="reference internal" href="cluster-launch-control.html">4.12. Work Stealing with Cluster Launch Control</a></li>
<li class="toctree-l3"><a class="reference internal" href="l2-cache-control.html">4.13. L2 Cache Control</a></li>
<li class="toctree-l3"><a class="reference internal" href="memory-sync-domains.html">4.14. Memory Synchronization Domains</a></li>
<li class="toctree-l3"><a class="reference internal" href="inter-process-communication.html">4.15. Interprocess Communication</a></li>
<li class="toctree-l3"><a class="reference internal" href="virtual-memory-management.html">4.16. Virtual Memory Management</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended-gpu-memory.html">4.17. Extended GPU Memory</a></li>
<li class="toctree-l3"><a class="reference internal" href="dynamic-parallelism.html">4.18. CUDA Dynamic Parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="graphics-interop.html">4.19. CUDA Interoperability with APIs</a></li>
<li class="toctree-l3"><a class="reference internal" href="driver-entry-point-access.html">4.20. Driver Entry Point Access</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../part5.html">5. Technical Appendices</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../05-appendices/compute-capabilities.html">5.1. Compute Capabilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../05-appendices/environment-variables.html">5.2. CUDA Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../05-appendices/cpp-language-support.html">5.3. C++ Language Support</a></li>
<li class="toctree-l3"><a class="reference internal" href="../05-appendices/cpp-language-extensions.html">5.4. C/C++ Language Extensions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../05-appendices/mathematical-functions.html">5.5. Floating-Point Computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../05-appendices/device-callable-apis.html">5.6. Device-Callable APIs and Intrinsics</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../notices.html">6. Notices</a></li>
</ul>
</details></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>



      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../contents.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">CUDA Programming Guide</a></li>
    
    
    <li class="breadcrumb-item"><a href="../part4.html" class="nav-link"><span class="section-number">4. </span>CUDA Features</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis"><span class="section-number">4.2. </span>CUDA Graphs</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="cuda-graphs">
<span id="id1"></span><h1><span class="section-number">4.2. </span>CUDA Graphs<a class="headerlink" href="#cuda-graphs" title="Link to this heading">#</a></h1>
<p>CUDA Graphs present another model for work submission in CUDA. A graph is a series of operations such as kernel launches, data movement, etc., connected by dependencies, which is defined separately from its execution. This allows a graph to be defined once and then launched repeatedly. Separating out the definition of a graph from its execution enables a number of optimizations: first, CPU launch costs are reduced compared to streams, because much of the setup is done in advance; second, presenting the whole workflow to CUDA enables optimizations which might not be possible with the piecewise work submission mechanism of streams.</p>
<p>To see the optimizations possible with graphs, consider what happens in a stream: when you place a kernel into a stream, the host driver performs a sequence of operations in preparation for the execution of the kernel on the GPU. These operations, necessary for setting up and launching the kernel, are an overhead cost which must be paid for each kernel that is issued. For a GPU kernel with a short execution time, this overhead cost can be a significant fraction of the overall end-to-end execution time.  By creating a CUDA graph that encompasses a workflow that will be launched many times, these overhead costs can be paid once for the entire graph during instantiation, and the graph itself can then be launched repeatedly with very little overhead.</p>
<section id="graph-structure">
<span id="cuda-graphs-graph-structure"></span><h2><span class="section-number">4.2.1. </span>Graph Structure<a class="headerlink" href="#graph-structure" title="Link to this heading">#</a></h2>
<p>An operation forms a node in a graph. The dependencies between the operations are the edges. These dependencies constrain the execution sequence of the operations.</p>
<p>An operation may be scheduled at any time once the nodes on which it depends are complete. Scheduling is left up to the CUDA system.</p>
<section id="node-types">
<span id="cuda-graphs-node-types"></span><h3><span class="section-number">4.2.1.1. </span>Node Types<a class="headerlink" href="#node-types" title="Link to this heading">#</a></h3>
<p>A graph node can be one of:</p>
<ul class="simple">
<li><p>kernel</p></li>
<li><p>CPU function call</p></li>
<li><p>memory copy</p></li>
<li><p>memset</p></li>
<li><p>empty node</p></li>
<li><p>waiting on a <a class="reference internal" href="../02-basics/asynchronous-execution.html#cuda-events"><span class="std std-ref">CUDA Event</span></a></p></li>
<li><p>recording a <a class="reference internal" href="../02-basics/asynchronous-execution.html#cuda-events"><span class="std std-ref">CUDA Event</span></a></p></li>
<li><p>signalling an <a class="reference internal" href="graphics-interop.html#external-resource-interoperability"><span class="std std-ref">external semaphore</span></a></p></li>
<li><p>waiting on an <a class="reference internal" href="graphics-interop.html#external-resource-interoperability"><span class="std std-ref">external semaphore</span></a></p></li>
<li><p><a class="reference internal" href="#cuda-graphs-conditional-graph-nodes"><span class="std std-ref">conditional node</span></a></p></li>
<li><p><a class="reference internal" href="#cuda-graphs-graph-memory-nodes"><span class="std std-ref">memory node</span></a></p></li>
<li><p>child graph: To execute a separate nested graph, as shown in the following figure.</p></li>
</ul>
<figure class="align-center" id="cuda-graphs-node-types-fig-child-graph">
<a class="reference internal image-reference" href="../_images/child-graph.png"><img alt="Child Graph Example" src="../_images/child-graph.png" style="width: 200px;" />
</a>
<figcaption>
<p><span class="caption-number">Figure 21 </span><span class="caption-text">Child Graph Example</span><a class="headerlink" href="#cuda-graphs-node-types-fig-child-graph" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="edge-data">
<span id="cuda-graphs-edge-data"></span><h3><span class="section-number">4.2.1.2. </span>Edge Data<a class="headerlink" href="#edge-data" title="Link to this heading">#</a></h3>
<p>CUDA 12.3 introduced edge data on CUDA Graphs. At this time, the only use for non-default edge data is enabling
<a class="reference internal" href="programmatic-dependent-launch.html#programmatic-dependent-launch-and-synchronization"><span class="std std-ref">Programmatic Dependent Launch</span></a>.</p>
<p>Generally speaking, edge data modifies a dependency specified by an edge and consists of three parts:
an outgoing port, an incoming port, and a type. An outgoing port specifies when an associated edge is triggered. An incoming port
specifies what portion of a node is dependent on an associated edge. A type modifies the relation between the endpoints.</p>
<p>Port values are specific to node type and direction, and edge types may be restricted to specific node types. In all cases,
zero-initialized edge data represents default behavior. Outgoing port 0 waits on an entire task, incoming port 0 blocks an
entire task, and edge type 0 is associated with a full dependency with memory synchronizing behavior.</p>
<p>Edge data is optionally specified in various graph APIs via a parallel array to the associated nodes. If it is omitted as an
input parameter, zero-initialized data is used. If it is omitted as an output (query) parameter, the API accepts this if the
edge data being ignored is all zero-initialized, and returns <code class="docutils literal notranslate"><span class="pre">cudaErrorLossyQuery</span></code> if the call would discard information.</p>
<p>Edge data is also available in some stream capture APIs: <code class="docutils literal notranslate"><span class="pre">cudaStreamBeginCaptureToGraph()</span></code>, <code class="docutils literal notranslate"><span class="pre">cudaStreamGetCaptureInfo()</span></code>,
and <code class="docutils literal notranslate"><span class="pre">cudaStreamUpdateCaptureDependencies()</span></code>. In these cases, there is not yet a downstream node. The data is associated with
a dangling edge (half edge) which will either be connected to a future captured node or discarded at termination of stream capture.
Note that some edge types do not wait on full completion of the upstream node. These edges are ignored when considering if a
stream capture has been fully rejoined to the origin stream, and cannot be discarded at the end of capture. See <a class="reference internal" href="#cuda-graphs-creating-a-graph-using-stream-capture"><span class="std std-ref">Stream Capture</span></a>.</p>
<p>No node types define additional incoming ports, and only kernel nodes define additional outgoing ports. There is
one non-default dependency type, <code class="docutils literal notranslate"><span class="pre">cudaGraphDependencyTypeProgrammatic</span></code>, which is used to enable <a class="reference internal" href="programmatic-dependent-launch.html#programmatic-dependent-launch-and-synchronization"><span class="std std-ref">Programmatic Dependent Launch</span></a> between two kernel nodes.</p>
</section>
</section>
<section id="building-and-running-graphs">
<span id="cuda-graphs-building-and-running-graphs"></span><h2><span class="section-number">4.2.2. </span>Building and Running Graphs<a class="headerlink" href="#building-and-running-graphs" title="Link to this heading">#</a></h2>
<p>Work submission using graphs is separated into three distinct stages: definition, instantiation, and execution.</p>
<ul class="simple">
<li><p>During the <strong>definition</strong> or <strong>creation</strong> phase, a program creates a description of the operations in the graph along with the dependencies between them.</p></li>
<li><p><strong>Instantiation</strong> takes a snapshot of the graph template, validates it, and performs much of the setup and initialization of work with the aim of minimizing what needs to be done at launch. The resulting instance is known as an <em>executable graph.</em></p></li>
<li><p>An <strong>executable</strong> graph may be launched into a stream, similar to any other CUDA work. It may be launched any number of times without repeating the instantiation.</p></li>
</ul>
<section id="graph-creation">
<span id="cuda-graphs-graph-creation-methods"></span><h3><span class="section-number">4.2.2.1. </span>Graph Creation<a class="headerlink" href="#graph-creation" title="Link to this heading">#</a></h3>
<p>Graphs can be created via two mechanisms: using the explicit Graph API and via stream capture.</p>
<section id="graph-apis">
<span id="cuda-graphs-creating-a-graph-using-graph-apis"></span><h4><span class="section-number">4.2.2.1.1. </span>Graph APIs<a class="headerlink" href="#graph-apis" title="Link to this heading">#</a></h4>
<p>The following is an example (omitting declarations and other boilerplate code) of creating the below graph.  Note the use of <code class="docutils literal notranslate"><span class="pre">cudaGraphCreate()</span></code> to create the graph and <code class="docutils literal notranslate"><span class="pre">cudaGraphAddNode()</span></code> to add the kernel nodes and their dependencies. <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__GRAPH.html">The CUDA Runtime API documentation</a> lists all the functions available for adding nodes and dependencies.</p>
<figure class="align-center" id="cuda-graphs-creating-a-graph-using-api-fig-creating-using-graph-apis">
<a class="reference internal image-reference" href="../_images/create-a-graph.png"><img alt="Creating a Graph Using Graph APIs Example" src="../_images/create-a-graph.png" style="width: 200px;" />
</a>
<figcaption>
<p><span class="caption-number">Figure 22 </span><span class="caption-text">Creating a Graph Using Graph APIs Example</span><a class="headerlink" href="#cuda-graphs-creating-a-graph-using-api-fig-creating-using-graph-apis" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="c1">// Create the graph - it starts out empty</span>
<span class="n">cudaGraphCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="c1">// Create the nodes and their dependencies</span>
<span class="n">cudaGraphNode_t</span><span class="w"> </span><span class="n">nodes</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>
<span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">kParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeKernel</span><span class="w"> </span><span class="p">};</span>
<span class="n">kParams</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="n">func</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">kernelName</span><span class="p">;</span>
<span class="n">kParams</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">gridDim</span><span class="p">.</span><span class="n">x</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="n">kParams</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">gridDim</span><span class="p">.</span><span class="n">y</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">kParams</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">gridDim</span><span class="p">.</span><span class="n">z</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="n">kParams</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">kParams</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kParams</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>

<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">kParams</span><span class="p">);</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nodes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">kParams</span><span class="p">);</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nodes</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">kParams</span><span class="p">);</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nodes</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nodes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">kParams</span><span class="p">);</span>
</pre></div>
</div>
<p>The example above shows four kernel nodes with dependencies between them to illustrate the creation of a very simple graph.  In a typical user application there would also need to be nodes added for memory operations, such as <code class="docutils literal notranslate"><span class="pre">cudaGraphAddMemcpyNode()</span></code> and the like.  For full reference of all graph API functions to add nodes, see the <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__GRAPH.html">The CUDA Runtime API documentation</a> .</p>
</section>
<section id="stream-capture">
<span id="cuda-graphs-creating-a-graph-using-stream-capture"></span><h4><span class="section-number">4.2.2.1.2. </span>Stream Capture<a class="headerlink" href="#stream-capture" title="Link to this heading">#</a></h4>
<p>Stream capture provides a mechanism to create a graph from existing stream-based APIs. A section of code which launches work into streams, including existing code, can be bracketed with calls to <code class="docutils literal notranslate"><span class="pre">cudaStreamBeginCapture()</span></code> and <code class="docutils literal notranslate"><span class="pre">cudaStreamEndCapture()</span></code>. See below.</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="n">cudaGraph_t</span><span class="w"> </span><span class="n">graph</span><span class="p">;</span>

<span class="n">cudaStreamBeginCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>

<span class="n">kernel_A</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">stream</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span>
<span class="n">kernel_B</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">stream</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span>
<span class="n">libraryCall</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>
<span class="n">kernel_C</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">stream</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span>

<span class="n">cudaStreamEndCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graph</span><span class="p">);</span>
</pre></div>
</div>
<p>A call to <code class="docutils literal notranslate"><span class="pre">cudaStreamBeginCapture()</span></code> places a stream in capture mode. When a stream is being captured, work launched into the stream is not enqueued for execution. It is instead appended to an internal graph that is progressively being built up. This graph is then returned by calling <code class="docutils literal notranslate"><span class="pre">cudaStreamEndCapture()</span></code>, which also ends capture mode for the stream. A graph which is actively being constructed by stream capture is referred to as a <em>capture graph.</em></p>
<p>Stream capture can be used on any CUDA stream except <code class="docutils literal notranslate"><span class="pre">cudaStreamLegacy</span></code> (the “NULL stream”). Note that it <em>can</em> be used on <code class="docutils literal notranslate"><span class="pre">cudaStreamPerThread</span></code>. If a program is using the legacy stream, it may be possible to redefine stream 0 to be the per-thread stream with no functional change. See <a class="reference internal" href="../02-basics/asynchronous-execution.html#async-execution-blocking-non-blocking-default-stream"><span class="std std-ref">Blocking and non-blocking streams and the default stream</span></a>.</p>
<p>Whether a stream is being captured can be queried with <code class="docutils literal notranslate"><span class="pre">cudaStreamIsCapturing()</span></code>.</p>
<p>Work can be captured to an existing graph using <code class="docutils literal notranslate"><span class="pre">cudaStreamBeginCaptureToGraph()</span></code>.  Instead of capturing to an internal graph, work is captured to a graph provided by the user.</p>
<section id="cross-stream-dependencies-and-events">
<span id="cuda-graphs-cross-stream-dependencies"></span><h5><span class="section-number">4.2.2.1.2.1. </span>Cross-stream Dependencies and Events<a class="headerlink" href="#cross-stream-dependencies-and-events" title="Link to this heading">#</a></h5>
<p>Stream capture can handle cross-stream dependencies expressed with <code class="docutils literal notranslate"><span class="pre">cudaEventRecord()</span></code> and <code class="docutils literal notranslate"><span class="pre">cudaStreamWaitEvent()</span></code>, provided the event being waited upon was recorded into the same capture graph.</p>
<p>When an event is recorded in a stream that is in capture mode, it results in a <em>captured event.</em> A captured event represents a set of nodes in a capture graph.</p>
<p>When a captured event is waited on by a stream, it places the stream in capture mode if it is not already, and the next item in the stream will have additional dependencies on the nodes in the captured event. The two streams are then being captured to the same capture graph.</p>
<p>When cross-stream dependencies are present in stream capture, <code class="docutils literal notranslate"><span class="pre">cudaStreamEndCapture()</span></code> must still be called in the same stream where <code class="docutils literal notranslate"><span class="pre">cudaStreamBeginCapture()</span></code> was called; this is the <em>origin stream</em>. Any other streams which are being captured to the same capture graph, due to event-based dependencies, must also be joined back to the origin stream. This is illustrated below. All streams being captured to the same capture graph are taken out of capture mode upon <code class="docutils literal notranslate"><span class="pre">cudaStreamEndCapture()</span></code>. Failure to rejoin to the origin stream will result in failure of the overall capture operation.</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="c1">// stream1 is the origin stream</span>
<span class="n">cudaStreamBeginCapture</span><span class="p">(</span><span class="n">stream1</span><span class="p">);</span>

<span class="n">kernel_A</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">stream1</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span>

<span class="c1">// Fork into stream2</span>
<span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">event1</span><span class="p">,</span><span class="w"> </span><span class="n">stream1</span><span class="p">);</span>
<span class="n">cudaStreamWaitEvent</span><span class="p">(</span><span class="n">stream2</span><span class="p">,</span><span class="w"> </span><span class="n">event1</span><span class="p">);</span>

<span class="n">kernel_B</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">stream1</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span>
<span class="n">kernel_C</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">stream2</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span>

<span class="c1">// Join stream2 back to origin stream (stream1)</span>
<span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">event2</span><span class="p">,</span><span class="w"> </span><span class="n">stream2</span><span class="p">);</span>
<span class="n">cudaStreamWaitEvent</span><span class="p">(</span><span class="n">stream1</span><span class="p">,</span><span class="w"> </span><span class="n">event2</span><span class="p">);</span>

<span class="n">kernel_D</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">stream1</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span>

<span class="c1">// End capture in the origin stream</span>
<span class="n">cudaStreamEndCapture</span><span class="p">(</span><span class="n">stream1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graph</span><span class="p">);</span>

<span class="c1">// stream1 and stream2 no longer in capture mode</span>
</pre></div>
</div>
<p>The graph returned by the above code is shown in <a class="reference internal" href="#cuda-graphs-creating-a-graph-using-api-fig-creating-using-graph-apis"><span class="std std-numref">Figure 22</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When a stream is taken out of capture mode, the next non-captured item in the stream (if any) will still have a dependency on the most recent prior non-captured item, despite intermediate items having been removed.</p>
</div>
</section>
<section id="prohibited-and-unhandled-operations">
<span id="cuda-graphs-prohibited-unhandled-operations"></span><h5><span class="section-number">4.2.2.1.2.2. </span>Prohibited and Unhandled Operations<a class="headerlink" href="#prohibited-and-unhandled-operations" title="Link to this heading">#</a></h5>
<p>It is invalid to synchronize or query the execution status of a stream which is being captured or a captured event, because they do not represent items scheduled for execution. It is also invalid to query the execution status of or synchronize a broader handle which encompasses an active stream capture, such as a device or context handle when any associated stream is in capture mode.</p>
<p>When any stream in the same context is being captured, and it was not created with <code class="docutils literal notranslate"><span class="pre">cudaStreamNonBlocking</span></code>, any attempted use of the legacy stream is invalid. This is because the legacy stream handle at all times encompasses these other streams; enqueueing to the legacy stream would create a dependency on the streams being captured, and querying it or synchronizing it would query or synchronize the streams being captured.</p>
<p>It is therefore also invalid to call synchronous APIs in this case. One example of a synchronous APIs is <code class="docutils literal notranslate"><span class="pre">cudaMemcpy()</span></code> which enqueues work to the legacy stream and synchronizes on it before returning.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As a general rule, when a dependency relation would connect something that is captured with something that was not captured and instead enqueued for execution, CUDA prefers to return an error rather than ignore the dependency. An exception is made for placing a stream into or out of capture mode; this severs a dependency relation between items added to the stream immediately before and after the mode transition.</p>
</div>
<p>It is invalid to merge two separate capture graphs by waiting on a captured event from a stream which is being captured and is associated with a different capture graph than the event. It is invalid to wait on a non-captured event from a stream which is being captured without specifying the <code class="docutils literal notranslate"><span class="pre">cudaEventWaitExternal</span></code> flag.</p>
<p>A small number of APIs that enqueue asynchronous operations into streams are not currently supported in graphs and will return an error if called with a stream which is being captured, such as <code class="docutils literal notranslate"><span class="pre">cudaStreamAttachMemAsync()</span></code>.</p>
</section>
<section id="invalidation">
<h5><span class="section-number">4.2.2.1.2.3. </span>Invalidation<a class="headerlink" href="#invalidation" title="Link to this heading">#</a></h5>
<p>When an invalid operation is attempted during stream capture, any associated capture graphs are <em>invalidated</em>. When a capture graph is invalidated, further use of any streams which are being captured or captured events associated with the graph is invalid and will return an error, until stream capture is ended with <code class="docutils literal notranslate"><span class="pre">cudaStreamEndCapture()</span></code>. This call will take the associated streams out of capture mode, but will also return an error value and a NULL graph.</p>
</section>
<section id="capture-introspection">
<h5><span class="section-number">4.2.2.1.2.4. </span>Capture Introspection<a class="headerlink" href="#capture-introspection" title="Link to this heading">#</a></h5>
<p>Active stream capture operations can be inspected using <code class="docutils literal notranslate"><span class="pre">cudaStreamGetCaptureInfo()</span></code>.  This allows the user to obtain the status of the capture, a unique(per-process) ID for the capture, the underlying graph object, and dependencies/edge data for the next node to be captured in the stream.  This dependency information can be used to obtain a handle to the node(s) which were last captured in the stream.</p>
</section>
</section>
<section id="putting-it-all-together">
<span id="cuda-graphs-putting-it-all-together"></span><h4><span class="section-number">4.2.2.1.3. </span>Putting It All Together<a class="headerlink" href="#putting-it-all-together" title="Link to this heading">#</a></h4>
<p>The example in <a class="reference internal" href="#cuda-graphs-creating-a-graph-using-api-fig-creating-using-graph-apis"><span class="std std-numref">Figure 22</span></a> is a simplistic example intended to show a small graph conceptually.  In an application that utilizes CUDA graphs, there is more complexity to using either the graph API or stream capture.  The following code snippet shows a side by side comparison of the Graph API and Stream Capture to create a CUDA graph to execute a simple two stage reduction algorithm.</p>
<p><a class="reference internal" href="#cuda-graphs-visualize-a-graph-using-graphviz"><span class="std std-numref">Figure 23</span></a> is an illustration of this CUDA graph and was generated using the <code class="docutils literal notranslate"><span class="pre">cudaGraphDebugDotPrint</span></code> function applied to the code below, with small adjustments for readability, and then rendered using <a class="reference external" href="https://graphviz.org/">Graphviz</a>.</p>
<figure class="align-center" id="cuda-graphs-visualize-a-graph-using-graphviz">
<a class="reference internal image-reference" href="../_images/cuda_graph_reduction.png"><img alt="CUDA graph example using two stage reduction kernel" src="../_images/cuda_graph_reduction.png" style="width: 200px;" />
</a>
<figcaption>
<p><span class="caption-number">Figure 23 </span><span class="caption-text">CUDA graph example using two stage reduction kernel</span><a class="headerlink" href="#cuda-graphs-visualize-a-graph-using-graphviz" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" data-sync-group="tab" data-sync-id="c++" for="sd-tab-item-0">
Graph API</label><div class="sd-tab-content docutils">
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">cudaGraphsManual</span><span class="p">(</span><span class="kt">float</span><span class="w">  </span><span class="o">*</span><span class="n">inputVec_h</span><span class="p">,</span>
<span class="w">                      </span><span class="kt">float</span><span class="w">  </span><span class="o">*</span><span class="n">inputVec_d</span><span class="p">,</span>
<span class="w">                      </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">outputVec_d</span><span class="p">,</span>
<span class="w">                      </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">result_d</span><span class="p">,</span>
<span class="w">                      </span><span class="kt">size_t</span><span class="w">  </span><span class="n">inputSize</span><span class="p">,</span>
<span class="w">                      </span><span class="kt">size_t</span><span class="w">  </span><span class="n">numOfBlocks</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">   </span><span class="n">cudaStream_t</span><span class="w">                 </span><span class="n">streamForGraph</span><span class="p">;</span>
<span class="w">   </span><span class="n">cudaGraph_t</span><span class="w">                  </span><span class="n">graph</span><span class="p">;</span>
<span class="w">   </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">cudaGraphNode_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">nodeDependencies</span><span class="p">;</span>
<span class="w">   </span><span class="n">cudaGraphNode_t</span><span class="w">              </span><span class="n">memcpyNode</span><span class="p">,</span><span class="w"> </span><span class="n">kernelNode</span><span class="p">,</span><span class="w"> </span><span class="n">memsetNode</span><span class="p">;</span>
<span class="w">   </span><span class="kt">double</span><span class="w">                       </span><span class="n">result_h</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>

<span class="w">   </span><span class="n">cudaStreamCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">streamForGraph</span><span class="p">));</span>

<span class="w">   </span><span class="n">cudaKernelNodeParams</span><span class="w"> </span><span class="n">kernelNodeParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">};</span>
<span class="w">   </span><span class="n">cudaMemcpy3DParms</span><span class="w">    </span><span class="n">memcpyParams</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">};</span>
<span class="w">   </span><span class="n">cudaMemsetParams</span><span class="w">     </span><span class="n">memsetParams</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">};</span>

<span class="w">   </span><span class="n">memcpyParams</span><span class="p">.</span><span class="n">srcArray</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span>
<span class="w">   </span><span class="n">memcpyParams</span><span class="p">.</span><span class="n">srcPos</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">make_cudaPos</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">   </span><span class="n">memcpyParams</span><span class="p">.</span><span class="n">srcPtr</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">make_cudaPitchedPtr</span><span class="p">(</span><span class="n">inputVec_h</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">inputSize</span><span class="p">,</span><span class="w"> </span><span class="n">inputSize</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">   </span><span class="n">memcpyParams</span><span class="p">.</span><span class="n">dstArray</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span>
<span class="w">   </span><span class="n">memcpyParams</span><span class="p">.</span><span class="n">dstPos</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">make_cudaPos</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">   </span><span class="n">memcpyParams</span><span class="p">.</span><span class="n">dstPtr</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">make_cudaPitchedPtr</span><span class="p">(</span><span class="n">inputVec_d</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">inputSize</span><span class="p">,</span><span class="w"> </span><span class="n">inputSize</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">   </span><span class="n">memcpyParams</span><span class="p">.</span><span class="n">extent</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">make_cudaExtent</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">inputSize</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">   </span><span class="n">memcpyParams</span><span class="p">.</span><span class="n">kind</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">;</span>

<span class="w">   </span><span class="n">memsetParams</span><span class="p">.</span><span class="n">dst</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">outputVec_d</span><span class="p">;</span>
<span class="w">   </span><span class="n">memsetParams</span><span class="p">.</span><span class="n">value</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">   </span><span class="n">memsetParams</span><span class="p">.</span><span class="n">pitch</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">   </span><span class="n">memsetParams</span><span class="p">.</span><span class="n">elementSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span><span class="w"> </span><span class="c1">// elementSize can be max 4 bytes</span>
<span class="w">   </span><span class="n">memsetParams</span><span class="p">.</span><span class="n">width</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">numOfBlocks</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="w">   </span><span class="n">memsetParams</span><span class="p">.</span><span class="n">height</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>

<span class="w">   </span><span class="n">cudaGraphCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">   </span><span class="n">cudaGraphAddMemcpyNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">memcpyNode</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">memcpyParams</span><span class="p">);</span>
<span class="w">   </span><span class="n">cudaGraphAddMemsetNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">memsetNode</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">memsetParams</span><span class="p">);</span>

<span class="w">   </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">memsetNode</span><span class="p">);</span>
<span class="w">   </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">memcpyNode</span><span class="p">);</span>

<span class="w">   </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">kernelArgs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">inputVec_d</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">outputVec_d</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">inputSize</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">numOfBlocks</span><span class="p">};</span>

<span class="w">   </span><span class="n">kernelNodeParams</span><span class="p">.</span><span class="n">func</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">reduce</span><span class="p">;</span>
<span class="w">   </span><span class="n">kernelNodeParams</span><span class="p">.</span><span class="nb">gridDim</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="kt">dim3</span><span class="p">(</span><span class="n">numOfBlocks</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">   </span><span class="n">kernelNodeParams</span><span class="p">.</span><span class="nb">blockDim</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="kt">dim3</span><span class="p">(</span><span class="n">THREADS_PER_BLOCK</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">   </span><span class="n">kernelNodeParams</span><span class="p">.</span><span class="n">sharedMemBytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">   </span><span class="n">kernelNodeParams</span><span class="p">.</span><span class="n">kernelParams</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="n">kernelArgs</span><span class="p">;</span>
<span class="w">   </span><span class="n">kernelNodeParams</span><span class="p">.</span><span class="n">extra</span><span class="w">          </span><span class="o">=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span>

<span class="w">   </span><span class="n">cudaGraphAddKernelNode</span><span class="p">(</span>
<span class="w">      </span><span class="o">&amp;</span><span class="n">kernelNode</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span><span class="w"> </span><span class="o">&amp;</span><span class="n">kernelNodeParams</span><span class="p">);</span>

<span class="w">   </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
<span class="w">   </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">kernelNode</span><span class="p">);</span>

<span class="w">   </span><span class="n">memset</span><span class="p">(</span><span class="o">&amp;</span><span class="n">memsetParams</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">memsetParams</span><span class="p">));</span>
<span class="w">   </span><span class="n">memsetParams</span><span class="p">.</span><span class="n">dst</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">result_d</span><span class="p">;</span>
<span class="w">   </span><span class="n">memsetParams</span><span class="p">.</span><span class="n">value</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">   </span><span class="n">memsetParams</span><span class="p">.</span><span class="n">elementSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
<span class="w">   </span><span class="n">memsetParams</span><span class="p">.</span><span class="n">width</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="w">   </span><span class="n">memsetParams</span><span class="p">.</span><span class="n">height</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">   </span><span class="n">cudaGraphAddMemsetNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">memsetNode</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">memsetParams</span><span class="p">);</span>

<span class="w">   </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">memsetNode</span><span class="p">);</span>

<span class="w">   </span><span class="n">memset</span><span class="p">(</span><span class="o">&amp;</span><span class="n">kernelNodeParams</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">kernelNodeParams</span><span class="p">));</span>
<span class="w">   </span><span class="n">kernelNodeParams</span><span class="p">.</span><span class="n">func</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">reduceFinal</span><span class="p">;</span>
<span class="w">   </span><span class="n">kernelNodeParams</span><span class="p">.</span><span class="nb">gridDim</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="kt">dim3</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">   </span><span class="n">kernelNodeParams</span><span class="p">.</span><span class="nb">blockDim</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="kt">dim3</span><span class="p">(</span><span class="n">THREADS_PER_BLOCK</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">   </span><span class="n">kernelNodeParams</span><span class="p">.</span><span class="n">sharedMemBytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">   </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">kernelArgs2</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="w">            </span><span class="o">=</span><span class="w"> </span><span class="p">{(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">outputVec_d</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">result_d</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">numOfBlocks</span><span class="p">};</span>
<span class="w">   </span><span class="n">kernelNodeParams</span><span class="p">.</span><span class="n">kernelParams</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">kernelArgs2</span><span class="p">;</span>
<span class="w">   </span><span class="n">kernelNodeParams</span><span class="p">.</span><span class="n">extra</span><span class="w">          </span><span class="o">=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span>

<span class="w">   </span><span class="n">cudaGraphAddKernelNode</span><span class="p">(</span>
<span class="w">      </span><span class="o">&amp;</span><span class="n">kernelNode</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span><span class="w"> </span><span class="o">&amp;</span><span class="n">kernelNodeParams</span><span class="p">);</span>

<span class="w">   </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
<span class="w">   </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">kernelNode</span><span class="p">);</span>

<span class="w">   </span><span class="n">memset</span><span class="p">(</span><span class="o">&amp;</span><span class="n">memcpyParams</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">memcpyParams</span><span class="p">));</span>

<span class="w">   </span><span class="n">memcpyParams</span><span class="p">.</span><span class="n">srcArray</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span>
<span class="w">   </span><span class="n">memcpyParams</span><span class="p">.</span><span class="n">srcPos</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">make_cudaPos</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">   </span><span class="n">memcpyParams</span><span class="p">.</span><span class="n">srcPtr</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">make_cudaPitchedPtr</span><span class="p">(</span><span class="n">result_d</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">),</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">   </span><span class="n">memcpyParams</span><span class="p">.</span><span class="n">dstArray</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span>
<span class="w">   </span><span class="n">memcpyParams</span><span class="p">.</span><span class="n">dstPos</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">make_cudaPos</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">   </span><span class="n">memcpyParams</span><span class="p">.</span><span class="n">dstPtr</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">make_cudaPitchedPtr</span><span class="p">(</span><span class="o">&amp;</span><span class="n">result_h</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">),</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">   </span><span class="n">memcpyParams</span><span class="p">.</span><span class="n">extent</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">make_cudaExtent</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">),</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">   </span><span class="n">memcpyParams</span><span class="p">.</span><span class="n">kind</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">;</span>

<span class="w">   </span><span class="n">cudaGraphAddMemcpyNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">memcpyNode</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span><span class="w"> </span><span class="o">&amp;</span><span class="n">memcpyParams</span><span class="p">);</span>
<span class="w">   </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
<span class="w">   </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">memcpyNode</span><span class="p">);</span>

<span class="w">   </span><span class="n">cudaGraphNode_t</span><span class="w">    </span><span class="n">hostNode</span><span class="p">;</span>
<span class="w">   </span><span class="n">cudaHostNodeParams</span><span class="w"> </span><span class="n">hostParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">};</span>
<span class="w">   </span><span class="n">hostParams</span><span class="p">.</span><span class="n">fn</span><span class="w">                 </span><span class="o">=</span><span class="w"> </span><span class="n">myHostNodeCallback</span><span class="p">;</span>
<span class="w">   </span><span class="n">callBackData_t</span><span class="w"> </span><span class="n">hostFnData</span><span class="p">;</span>
<span class="w">   </span><span class="n">hostFnData</span><span class="p">.</span><span class="n">data</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">result_h</span><span class="p">;</span>
<span class="w">   </span><span class="n">hostFnData</span><span class="p">.</span><span class="n">fn_name</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;cudaGraphsManual&quot;</span><span class="p">;</span>
<span class="w">   </span><span class="n">hostParams</span><span class="p">.</span><span class="n">userData</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">hostFnData</span><span class="p">;</span>

<span class="w">   </span><span class="n">cudaGraphAddHostNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">hostNode</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span><span class="w"> </span><span class="n">nodeDependencies</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span><span class="w"> </span><span class="o">&amp;</span><span class="n">hostParams</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" data-sync-group="tab" data-sync-id="c++" for="sd-tab-item-1">
Stream Capture</label><div class="sd-tab-content docutils">
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">cudaGraphsUsingStreamCapture</span><span class="p">(</span><span class="kt">float</span><span class="w">  </span><span class="o">*</span><span class="n">inputVec_h</span><span class="p">,</span>
<span class="w">                      </span><span class="kt">float</span><span class="w">  </span><span class="o">*</span><span class="n">inputVec_d</span><span class="p">,</span>
<span class="w">                      </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">outputVec_d</span><span class="p">,</span>
<span class="w">                      </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">result_d</span><span class="p">,</span>
<span class="w">                      </span><span class="kt">size_t</span><span class="w">  </span><span class="n">inputSize</span><span class="p">,</span>
<span class="w">                      </span><span class="kt">size_t</span><span class="w">  </span><span class="n">numOfBlocks</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">   </span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">stream1</span><span class="p">,</span><span class="w"> </span><span class="n">stream2</span><span class="p">,</span><span class="w"> </span><span class="n">stream3</span><span class="p">,</span><span class="w"> </span><span class="n">streamForGraph</span><span class="p">;</span>
<span class="w">   </span><span class="n">cudaEvent_t</span><span class="w">  </span><span class="n">forkStreamEvent</span><span class="p">,</span><span class="w"> </span><span class="n">memsetEvent1</span><span class="p">,</span><span class="w"> </span><span class="n">memsetEvent2</span><span class="p">;</span>
<span class="w">   </span><span class="n">cudaGraph_t</span><span class="w">  </span><span class="n">graph</span><span class="p">;</span>
<span class="w">   </span><span class="kt">double</span><span class="w">       </span><span class="n">result_h</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>

<span class="w">   </span><span class="n">cudaStreamCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stream1</span><span class="p">);</span>
<span class="w">   </span><span class="n">cudaStreamCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stream2</span><span class="p">);</span>
<span class="w">   </span><span class="n">cudaStreamCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stream3</span><span class="p">);</span>
<span class="w">   </span><span class="n">cudaStreamCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">streamForGraph</span><span class="p">);</span>

<span class="w">   </span><span class="n">cudaEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">forkStreamEvent</span><span class="p">);</span>
<span class="w">   </span><span class="n">cudaEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">memsetEvent1</span><span class="p">);</span>
<span class="w">   </span><span class="n">cudaEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">memsetEvent2</span><span class="p">);</span>

<span class="w">   </span><span class="n">cudaStreamBeginCapture</span><span class="p">(</span><span class="n">stream1</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamCaptureModeGlobal</span><span class="p">);</span>

<span class="w">   </span><span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">forkStreamEvent</span><span class="p">,</span><span class="w"> </span><span class="n">stream1</span><span class="p">);</span>
<span class="w">   </span><span class="n">cudaStreamWaitEvent</span><span class="p">(</span><span class="n">stream2</span><span class="p">,</span><span class="w"> </span><span class="n">forkStreamEvent</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">   </span><span class="n">cudaStreamWaitEvent</span><span class="p">(</span><span class="n">stream3</span><span class="p">,</span><span class="w"> </span><span class="n">forkStreamEvent</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">   </span><span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="n">inputVec_d</span><span class="p">,</span><span class="w"> </span><span class="n">inputVec_h</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">inputSize</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyDefault</span><span class="p">,</span><span class="w"> </span><span class="n">stream1</span><span class="p">);</span>

<span class="w">   </span><span class="n">cudaMemsetAsync</span><span class="p">(</span><span class="n">outputVec_d</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">numOfBlocks</span><span class="p">,</span><span class="w"> </span><span class="n">stream2</span><span class="p">);</span>

<span class="w">   </span><span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">memsetEvent1</span><span class="p">,</span><span class="w"> </span><span class="n">stream2</span><span class="p">);</span>

<span class="w">   </span><span class="n">cudaMemsetAsync</span><span class="p">(</span><span class="n">result_d</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">),</span><span class="w"> </span><span class="n">stream3</span><span class="p">);</span>
<span class="w">   </span><span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">memsetEvent2</span><span class="p">,</span><span class="w"> </span><span class="n">stream3</span><span class="p">);</span>

<span class="w">   </span><span class="n">cudaStreamWaitEvent</span><span class="p">(</span><span class="n">stream1</span><span class="p">,</span><span class="w"> </span><span class="n">memsetEvent1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">   </span><span class="n">reduce</span><span class="o">&lt;&lt;&lt;</span><span class="n">numOfBlocks</span><span class="p">,</span><span class="w"> </span><span class="n">THREADS_PER_BLOCK</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream1</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">inputVec_d</span><span class="p">,</span><span class="w"> </span><span class="n">outputVec_d</span><span class="p">,</span><span class="w"> </span><span class="n">inputSize</span><span class="p">,</span><span class="w"> </span><span class="n">numOfBlocks</span><span class="p">);</span>

<span class="w">   </span><span class="n">cudaStreamWaitEvent</span><span class="p">(</span><span class="n">stream1</span><span class="p">,</span><span class="w"> </span><span class="n">memsetEvent2</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">   </span><span class="n">reduceFinal</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">THREADS_PER_BLOCK</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream1</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">outputVec_d</span><span class="p">,</span><span class="w"> </span><span class="n">result_d</span><span class="p">,</span><span class="w"> </span><span class="n">numOfBlocks</span><span class="p">);</span>
<span class="w">   </span><span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="o">&amp;</span><span class="n">result_h</span><span class="p">,</span><span class="w"> </span><span class="n">result_d</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">),</span><span class="w"> </span><span class="n">cudaMemcpyDefault</span><span class="p">,</span><span class="w"> </span><span class="n">stream1</span><span class="p">);</span>

<span class="w">   </span><span class="n">callBackData_t</span><span class="w"> </span><span class="n">hostFnData</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">};</span>
<span class="w">   </span><span class="n">hostFnData</span><span class="p">.</span><span class="n">data</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">result_h</span><span class="p">;</span>
<span class="w">   </span><span class="n">hostFnData</span><span class="p">.</span><span class="n">fn_name</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;cudaGraphsUsingStreamCapture&quot;</span><span class="p">;</span>
<span class="w">   </span><span class="n">cudaHostFn_t</span><span class="w"> </span><span class="n">fn</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="n">myHostNodeCallback</span><span class="p">;</span>
<span class="w">   </span><span class="n">cudaLaunchHostFunc</span><span class="p">(</span><span class="n">stream1</span><span class="p">,</span><span class="w"> </span><span class="n">fn</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">hostFnData</span><span class="p">);</span>
<span class="w">   </span><span class="n">cudaStreamEndCapture</span><span class="p">(</span><span class="n">stream1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graph</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="graph-instantiation">
<span id="cuda-graphs-graph-instantiation"></span><h3><span class="section-number">4.2.2.2. </span>Graph Instantiation<a class="headerlink" href="#graph-instantiation" title="Link to this heading">#</a></h3>
<p>Once a graph has been created, either by the use of the graph API or stream capture, the graph must be instantiated to create an executable graph, which can then be launched.  Assuming the <code class="docutils literal notranslate"><span class="pre">cudaGraph_t</span> <span class="pre">graph</span></code> has been created successfully, the following code will instantiate the graph and create the executable graph <code class="docutils literal notranslate"><span class="pre">cudaGraphExec_t</span> <span class="pre">graphExec</span></code>:</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="n">cudaGraphExec_t</span><span class="w"> </span><span class="n">graphExec</span><span class="p">;</span>
<span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="graph-execution">
<span id="cuda-graphs-graph-execution"></span><h3><span class="section-number">4.2.2.3. </span>Graph Execution<a class="headerlink" href="#graph-execution" title="Link to this heading">#</a></h3>
<p>After a graph has been created and instantiated to create an executable graph, it can be launched. Assuming the <code class="docutils literal notranslate"><span class="pre">cudaGraphExec_t</span> <span class="pre">graphExec</span></code> has been created successfully, the following code snippet will launch the graph into the specified stream:</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
</pre></div>
</div>
<p>Pulling it all together and using the stream capture example from <a class="reference internal" href="#cuda-graphs-creating-a-graph-using-stream-capture"><span class="std std-numref">Section 4.2.2.1.2</span></a>, the following code snippet will create a graph, instantiate it, and launch it:</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="n">cudaGraph_t</span><span class="w"> </span><span class="n">graph</span><span class="p">;</span>

<span class="n">cudaStreamBeginCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>

<span class="n">kernel_A</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">stream</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span>
<span class="n">kernel_B</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">stream</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span>
<span class="n">libraryCall</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>
<span class="n">kernel_C</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">stream</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(...);</span>

<span class="n">cudaStreamEndCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graph</span><span class="p">);</span>

<span class="n">cudaGraphExec_t</span><span class="w"> </span><span class="n">graphExec</span><span class="p">;</span>
<span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
</pre></div>
</div>
</section>
</section>
<section id="updating-instantiated-graphs">
<span id="cuda-graphs-updating-instantiated-graphs"></span><h2><span class="section-number">4.2.3. </span>Updating Instantiated Graphs<a class="headerlink" href="#updating-instantiated-graphs" title="Link to this heading">#</a></h2>
<p>When a workflow changes, the graph becomes out of date and must be modified. Major changes to graph structure (such as topology or node types) require re-instantiation because topology-related optimizations must be re-applied. However, it is common for only node parameters (such as kernel parameters and memory addresses) to change while the graph topology remains the same. For this case, CUDA provides a lightweight “Graph Update” mechanism that allows certain node parameters to be modified in-place without rebuilding the entire graph, which is much more efficient than re-instantiation.</p>
<p>Updates take effect the next time the graph is launched, so they do not impact previous graph launches, even if they are running at the time of the update. A graph may be updated and relaunched repeatedly, so multiple updates/launches can be queued on a stream.</p>
<p>CUDA provides two mechanisms for updating instantiated graph parameters, whole graph update and individual node update. Whole graph update allows the user to supply a topologically identical <code class="docutils literal notranslate"><span class="pre">cudaGraph_t</span></code> object whose nodes contain updated parameters. Individual node update allows the user to explicitly update the parameters of individual nodes. Using an updated <code class="docutils literal notranslate"><span class="pre">cudaGraph_t</span></code> is more convenient when a large number of nodes are being updated, or when the graph topology is unknown to the caller (i.e., The graph resulted from stream capture of a library call). Using individual node update is preferred when the number of changes is small and the user has the handles to the nodes requiring updates. Individual node update skips the topology checks and comparisons for unchanged nodes, so it can be more efficient in many cases.</p>
<p>CUDA also provides a mechanism for enabling and disabling individual nodes without affecting their current parameters.</p>
<p>The following sections explain each approach in more detail.</p>
<section id="whole-graph-update">
<span id="cuda-graphs-whole-graph-update"></span><h3><span class="section-number">4.2.3.1. </span>Whole Graph Update<a class="headerlink" href="#whole-graph-update" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">cudaGraphExecUpdate()</span></code> allows an instantiated graph (the “original graph”) to be updated with the parameters from a topologically identical graph (the “updating” graph). The topology of the updating graph must be identical to the original graph used to instantiate the <code class="docutils literal notranslate"><span class="pre">cudaGraphExec_t</span></code>. In addition, the order in which the dependencies are specified must match. Finally, CUDA needs to consistently order the sink nodes (nodes with no dependencies). CUDA relies on the order of specific api calls to achieve consistent sink node ordering.</p>
<p>More explicitly, following the following rules will cause <code class="docutils literal notranslate"><span class="pre">cudaGraphExecUpdate()</span></code> to pair the nodes in the original graph and the updating graph deterministically:</p>
<ol class="arabic simple">
<li><p>For any capturing stream, the API calls operating on that stream must be made in the same order, including event wait and other api calls not directly corresponding to node creation.</p></li>
<li><p>The API calls which directly manipulate a given graph node’s incoming edges (including captured stream APIs, node add APIs, and edge addition / removal APIs) must be made in the same order. Moreover, when dependencies are specified in arrays to these APIs, the order in which the dependencies are specified inside those arrays must match.</p></li>
<li><p>Sink nodes must be consistently ordered. Sink nodes are nodes without dependent nodes / outgoing edges in the final graph at the time of the <code class="docutils literal notranslate"><span class="pre">cudaGraphExecUpdate()</span></code> invocation. The following operations affect sink node ordering (if present) and must (as a combined set) be made in the same order:</p>
<ul class="simple">
<li><p>Node add APIs resulting in a sink node.</p></li>
<li><p>Edge removal resulting in a node becoming a sink node.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cudaStreamUpdateCaptureDependencies()</span></code>, if it removes a sink node from a capturing stream’s dependency set.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cudaStreamEndCapture()</span></code>.</p></li>
</ul>
</li>
</ol>
<p>The following example shows how the API could be used to update an instantiated graph:</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="n">cudaGraphExec_t</span><span class="w"> </span><span class="n">graphExec</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">;</span>

<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cudaGraph_t</span><span class="w"> </span><span class="n">graph</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphExecUpdateResult</span><span class="w"> </span><span class="n">updateResult</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphNode_t</span><span class="w"> </span><span class="n">errorNode</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// In this example we use stream capture to create the graph.</span>
<span class="w">    </span><span class="c1">// You can also use the Graph API to produce a graph.</span>
<span class="w">    </span><span class="n">cudaStreamBeginCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamCaptureModeGlobal</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Call a user-defined, stream based workload, for example</span>
<span class="w">    </span><span class="n">do_cuda_work</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>

<span class="w">    </span><span class="n">cudaStreamEndCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graph</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// If we&#39;ve already instantiated the graph, try to update it directly</span>
<span class="w">    </span><span class="c1">// and avoid the instantiation overhead</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">graphExec</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// If the graph fails to update, errorNode will be set to the</span>
<span class="w">        </span><span class="c1">// node causing the failure and updateResult will be set to a</span>
<span class="w">        </span><span class="c1">// reason code.</span>
<span class="w">        </span><span class="n">cudaGraphExecUpdate</span><span class="p">(</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">errorNode</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">updateResult</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Instantiate during the first iteration or whenever the update</span>
<span class="w">    </span><span class="c1">// fails for any reason</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">graphExec</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nb">NULL</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="n">updateResult</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">cudaGraphExecUpdateSuccess</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">        </span><span class="c1">// If a previous update failed, destroy the cudaGraphExec_t</span>
<span class="w">        </span><span class="c1">// before re-instantiating it</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">graphExec</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">cudaGraphExecDestroy</span><span class="p">(</span><span class="n">graphExec</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="c1">// Instantiate graphExec from graph. The error node and</span>
<span class="w">        </span><span class="c1">// error message parameters are unused here.</span>
<span class="w">        </span><span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="n">cudaGraphDestroy</span><span class="p">(</span><span class="n">graph</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaStreamSynchronize</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>A typical workflow is to create the initial <code class="docutils literal notranslate"><span class="pre">cudaGraph_t</span></code> using either the stream capture or graph API. The <code class="docutils literal notranslate"><span class="pre">cudaGraph_t</span></code> is then instantiated and launched as normal. After the initial launch, a new <code class="docutils literal notranslate"><span class="pre">cudaGraph_t</span></code> is created using the same method as the initial graph and <code class="docutils literal notranslate"><span class="pre">cudaGraphExecUpdate()</span></code> is called. If the graph update is successful, indicated by the <code class="docutils literal notranslate"><span class="pre">updateResult</span></code> parameter in the above example, the updated <code class="docutils literal notranslate"><span class="pre">cudaGraphExec_t</span></code> is launched. If the update fails for any reason, the <code class="docutils literal notranslate"><span class="pre">cudaGraphExecDestroy()</span></code> and <code class="docutils literal notranslate"><span class="pre">cudaGraphInstantiate()</span></code> are called to destroy the original <code class="docutils literal notranslate"><span class="pre">cudaGraphExec_t</span></code> and instantiate a new one.</p>
<p>It is also possible to update the <code class="docutils literal notranslate"><span class="pre">cudaGraph_t</span></code> nodes directly (i.e., Using <code class="docutils literal notranslate"><span class="pre">cudaGraphKernelNodeSetParams()</span></code>) and subsequently update the <code class="docutils literal notranslate"><span class="pre">cudaGraphExec_t</span></code>, however it is more efficient to use the explicit node update APIs covered in the next section.</p>
<p>Conditional handle flags and default values are updated as part of the graph update.</p>
<p>Please see the <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__GRAPH.html#group__CUDART__GRAPH">Graph API</a> for more information on usage and current limitations.</p>
</section>
<section id="individual-node-update">
<span id="cuda-graphs-individual-node-update"></span><h3><span class="section-number">4.2.3.2. </span>Individual Node Update<a class="headerlink" href="#individual-node-update" title="Link to this heading">#</a></h3>
<p>Instantiated graph node parameters can be updated directly. This eliminates the overhead of instantiation as well as the overhead of creating a new <code class="docutils literal notranslate"><span class="pre">cudaGraph_t</span></code>. If the number of nodes requiring update is small relative to the total number of nodes in the graph, it is better to update the nodes individually. The following methods are available for updating <code class="docutils literal notranslate"><span class="pre">cudaGraphExec_t</span></code> nodes:</p>
<div class="pst-scrollable-table-container"><table class="table-no-stripes table" id="id4">
<caption><span class="caption-number">Table 8 </span><span class="caption-text">Individual Node Update APIs</span><a class="headerlink" href="#id4" title="Link to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>API</p></th>
<th class="head"><p>Node Type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">cudaGraphExecKernelNodeSetParams()</span></code></p></td>
<td><p>Kernel node</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">cudaGraphExecMemcpyNodeSetParams()</span></code></p></td>
<td><p>Memory copy node</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">cudaGraphExecMemsetNodeSetParams()</span></code></p></td>
<td><p>Memory set node</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">cudaGraphExecHostNodeSetParams()</span></code></p></td>
<td><p>Host node</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">cudaGraphExecChildGraphNodeSetParams()</span></code></p></td>
<td><p>Child graph node</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">cudaGraphExecEventRecordNodeSetEvent()</span></code></p></td>
<td><p>Event record node</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">cudaGraphExecEventWaitNodeSetEvent()</span></code></p></td>
<td><p>Event wait node</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">cudaGraphExecExternalSemaphoresSignalNodeSetParams()</span></code></p></td>
<td><p>External semaphore signal node</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">cudaGraphExecExternalSemaphoresWaitNodeSetParams()</span></code></p></td>
<td><p>External semaphore wait node</p></td>
</tr>
</tbody>
</table>
</div>
<p>Please see the <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__GRAPH.html#group__CUDART__GRAPH">Graph API</a> for more information on usage and current limitations.</p>
</section>
<section id="individual-node-enable">
<span id="cuda-graphs-individual-node-enable"></span><h3><span class="section-number">4.2.3.3. </span>Individual Node Enable<a class="headerlink" href="#individual-node-enable" title="Link to this heading">#</a></h3>
<p>Kernel, memset and memcpy nodes in an instantiated graph can be enabled or disabled using the <code class="docutils literal notranslate"><span class="pre">cudaGraphNodeSetEnabled()</span></code> API. This allows the creation of a graph which contains a superset of the desired functionality which can be customized for each launch. The enable state of a node can be queried using the <code class="docutils literal notranslate"><span class="pre">cudaGraphNodeGetEnabled()</span></code> API.</p>
<p>A disabled node is functionally equivalent to empty node until it is re-enabled. Node parameters are not affected by enabling/disabling a node. Enable state is unaffected by individual node update or whole graph update with <code class="docutils literal notranslate"><span class="pre">cudaGraphExecUpdate()</span></code>. Parameter updates while the node is disabled will take effect when the node is re-enabled.</p>
<p>Refer to the <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__GRAPH.html#group__CUDART__GRAPH">Graph API</a> for more information on usage and current limitations.</p>
</section>
<section id="graph-update-limitations">
<span id="cuda-graphs-graph-update-limitations"></span><h3><span class="section-number">4.2.3.4. </span>Graph Update Limitations<a class="headerlink" href="#graph-update-limitations" title="Link to this heading">#</a></h3>
<p>Kernel nodes:</p>
<ul class="simple">
<li><p>The owning context of the function cannot change.</p></li>
<li><p>A node whose function originally did not use CUDA dynamic parallelism cannot be updated to a function which uses CUDA dynamic parallelism.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">cudaMemset</span></code> and <code class="docutils literal notranslate"><span class="pre">cudaMemcpy</span></code> nodes:</p>
<ul class="simple">
<li><p>The CUDA device(s) to which the operand(s) was allocated/mapped cannot change.</p></li>
<li><p>The source/destination memory must be allocated from the same context as the original source/destination memory.</p></li>
<li><p>Only 1D <code class="docutils literal notranslate"><span class="pre">cudaMemset</span></code>/<code class="docutils literal notranslate"><span class="pre">cudaMemcpy</span></code> nodes can be changed.</p></li>
</ul>
<p>Additional memcpy node restrictions:</p>
<ul class="simple">
<li><p>Changing either the source or destination memory type (i.e., <code class="docutils literal notranslate"><span class="pre">cudaPitchedPtr</span></code>, <code class="docutils literal notranslate"><span class="pre">cudaArray_t</span></code>, etc.), or the type of transfer (i.e., <code class="docutils literal notranslate"><span class="pre">cudaMemcpyKind</span></code>) is not supported.</p></li>
</ul>
<p>External semaphore wait nodes and record nodes:</p>
<ul class="simple">
<li><p>Changing the number of semaphores is not supported.</p></li>
</ul>
<p>Conditional nodes:</p>
<ul class="simple">
<li><p>The order of handle creation and assignment must match between the graphs.</p></li>
<li><p>Changing node parameters is not supported (i.e. number of graphs in the conditional, node context, etc).</p></li>
<li><p>Changing parameters of nodes within the conditional body graph is subject to the rules above.</p></li>
</ul>
<p>Memory nodes:</p>
<ul class="simple">
<li><p>It is not possible to update a <code class="docutils literal notranslate"><span class="pre">cudaGraphExec_t</span></code> with a <code class="docutils literal notranslate"><span class="pre">cudaGraph_t</span></code> if the <code class="docutils literal notranslate"><span class="pre">cudaGraph_t</span></code> is currently instantiated as a different <code class="docutils literal notranslate"><span class="pre">cudaGraphExec_t</span></code>.</p></li>
</ul>
<p>There are no restrictions on updates to host nodes, event record nodes, or event wait nodes.</p>
</section>
</section>
<section id="conditional-graph-nodes">
<span id="cuda-graphs-conditional-graph-nodes"></span><h2><span class="section-number">4.2.4. </span>Conditional Graph Nodes<a class="headerlink" href="#conditional-graph-nodes" title="Link to this heading">#</a></h2>
<p>Conditional nodes allow conditional execution and looping of a graph contained within the conditional node. This allows dynamic and iterative workflows to be represented completely within a graph and frees up the host CPU to perform other work in parallel.</p>
<p>Evaluation of the condition value is performed on the device when the dependencies of the conditional node have been met. Conditional nodes can be one of the following types:</p>
<ul class="simple">
<li><p>Conditional <a class="reference internal" href="#cuda-graphs-conditional-if-nodes"><span class="std std-ref">IF nodes</span></a> execute their body graph once if the condition value is non-zero when the node is executed. An optional second body graph can be provided and this will be executed once if the condition value is zero when the node is executed.</p></li>
<li><p>Conditional <a class="reference internal" href="#cuda-graphs-conditional-while-nodes"><span class="std std-ref">WHILE nodes</span></a> execute their body graph if the condition value is non-zero when the node is executed and will continue to execute their body graph until the condition value is zero.</p></li>
<li><p>Conditional <a class="reference internal" href="#cuda-graphs-conditional-switch-nodes"><span class="std std-ref">SWITCH nodes</span></a> execute the zero-indexed nth body graph once if the condition value is equal to n.  If the condition value does not correspond to a body graph, no body graph is launched.</p></li>
</ul>
<p>A condition value is accessed by a <a class="reference internal" href="#cuda-graphs-conditional-handles"><span class="std std-ref">conditional handle</span></a> , which must be created before the node. The condition value can be set by device code using <code class="docutils literal notranslate"><span class="pre">cudaGraphSetConditional()</span></code>. A default value, applied on each graph launch, can also be specified when the handle is created.</p>
<p>When the conditional node is created, an empty graph is created and the handle is returned to the user so that the graph can be populated.  This conditional body graph can be populated using either the <a class="reference internal" href="#cuda-graphs-creating-a-graph-using-graph-apis"><span class="std std-ref">graph APIs</span></a> or <a class="reference internal" href="#cuda-graphs-creating-a-graph-using-stream-capture"><span class="std std-ref">cudaStreamBeginCaptureToGraph()</span></a>.</p>
<p>Conditional nodes can be nested.</p>
<section id="conditional-handles">
<span id="cuda-graphs-conditional-handles"></span><h3><span class="section-number">4.2.4.1. </span>Conditional Handles<a class="headerlink" href="#conditional-handles" title="Link to this heading">#</a></h3>
<p>A condition value is represented by <code class="docutils literal notranslate"><span class="pre">cudaGraphConditionalHandle</span></code> and is created by <code class="docutils literal notranslate"><span class="pre">cudaGraphConditionalHandleCreate()</span></code>.</p>
<p>The handle must be associated with a single conditional node. Handles cannot be destroyed and as such there is no need to keep track of them.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">cudaGraphCondAssignDefault</span></code> is specified when the handle is created, the condition value will be initialized to the specified default at the beginning of each graph execution. If this flag is not provided, the condition value is undefined at the start of each graph execution and code should not assume that the condition value persists across executions.</p>
<p>The default value and flags associated with a handle will be updated during <a class="reference internal" href="#cuda-graphs-whole-graph-update"><span class="std std-ref">whole graph update</span></a>.</p>
</section>
<section id="conditional-node-body-graph-requirements">
<span id="cuda-graphs-conditional-node-body-graph-requirements"></span><h3><span class="section-number">4.2.4.2. </span>Conditional Node Body Graph Requirements<a class="headerlink" href="#conditional-node-body-graph-requirements" title="Link to this heading">#</a></h3>
<p>General requirements:</p>
<ul class="simple">
<li><p>The graph’s nodes must all reside on a single device.</p></li>
<li><p>The graph can only contain kernel nodes, empty nodes, memcpy nodes, memset nodes, child graph nodes, and conditional nodes.</p></li>
</ul>
<p>Kernel nodes:</p>
<ul class="simple">
<li><p>Use of CUDA Dynamic Parallelism or Device Graph Launch by kernels in the graph is not permitted.</p></li>
<li><p>Cooperative launches are permitted so long as MPS is not in use.</p></li>
</ul>
<p>Memcpy/Memset nodes:</p>
<ul class="simple">
<li><p>Only copies/memsets involving device memory and/or pinned device-mapped host memory are permitted.</p></li>
<li><p>Copies/memsets involving CUDA arrays are not permitted.</p></li>
<li><p>Both operands must be accessible from the current device at time of instantiation. Note that the copy operation will be performed from the device on which the graph resides, even if it is targeting memory on another device.</p></li>
</ul>
</section>
<section id="conditional-if-nodes">
<span id="cuda-graphs-conditional-if-nodes"></span><h3><span class="section-number">4.2.4.3. </span>Conditional IF Nodes<a class="headerlink" href="#conditional-if-nodes" title="Link to this heading">#</a></h3>
<p>The body graph of an IF node will be executed once if the condition is non-zero when the node is executed.  The following diagram depicts a 3 node graph where the middle node, B, is a conditional node:</p>
<figure class="align-default" id="id5">
<img alt="../_images/conditional-if-node.png" class="image" src="../_images/conditional-if-node.png" />
<figcaption>
<p><span class="caption-number">Figure 24 </span><span class="caption-text">Conditional IF Node</span><a class="headerlink" href="#id5" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>The following code illustrates the creation of a graph containing an IF conditional node. The default value of the condition is set using an upstream kernel. The body of the conditional is populated using the <a class="reference internal" href="#cuda-graphs-creating-a-graph-using-graph-apis"><span class="std std-ref">graph API</span></a>.</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">setHandle</span><span class="p">(</span><span class="n">cudaGraphConditionalHandle</span><span class="w"> </span><span class="n">handle</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">value</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="p">...</span>
<span class="w">    </span><span class="c1">// Set the condition value to the value passed to the kernel</span>
<span class="w">    </span><span class="n">cudaGraphSetConditional</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="w">    </span><span class="p">...</span>
<span class="p">}</span>

<span class="kt">void</span><span class="w"> </span><span class="n">graphSetup</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cudaGraph_t</span><span class="w"> </span><span class="n">graph</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphExec_t</span><span class="w"> </span><span class="n">graphExec</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphNode_t</span><span class="w"> </span><span class="n">node</span><span class="p">;</span>
<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">kernelArgs</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Create the graph</span>
<span class="w">    </span><span class="n">cudaGraphCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Create the conditional handle; because no default value is provided, the condition value is undefined at the start of each graph execution</span>
<span class="w">    </span><span class="n">cudaGraphConditionalHandle</span><span class="w"> </span><span class="n">handle</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphConditionalHandleCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">handle</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Use a kernel upstream of the conditional to set the handle value</span>
<span class="w">    </span><span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeKernel</span><span class="w"> </span><span class="p">};</span>
<span class="w">    </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="n">func</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">setHandle</span><span class="p">;</span>
<span class="w">    </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">gridDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">gridDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">gridDim</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="n">kernelParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kernelArgs</span><span class="p">;</span>
<span class="w">    </span><span class="n">kernelArgs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">handle</span><span class="p">;</span>
<span class="w">    </span><span class="n">kernelArgs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">value</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">params</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Create and add the conditional node</span>
<span class="w">    </span><span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">cParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeConditional</span><span class="w"> </span><span class="p">};</span>
<span class="w">    </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">handle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">handle</span><span class="p">;</span>
<span class="w">    </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">type</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">cudaGraphCondTypeIf</span><span class="p">;</span>
<span class="w">    </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">size</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="c1">// There is only an &quot;if&quot; body graph</span>
<span class="w">    </span><span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cParams</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Get the body graph of the conditional node</span>
<span class="w">    </span><span class="n">cudaGraph_t</span><span class="w"> </span><span class="n">bodyGraph</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">phGraph_out</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>

<span class="w">    </span><span class="c1">// Populate the body graph of the IF conditional node</span>
<span class="w">    </span><span class="p">...</span>
<span class="w">    </span><span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">bodyGraph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">params</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Instantiate and launch the graph</span>
<span class="w">    </span><span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaDeviceSynchronize</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// Clean up</span>
<span class="w">    </span><span class="n">cudaGraphExecDestroy</span><span class="p">(</span><span class="n">graphExec</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphDestroy</span><span class="p">(</span><span class="n">graph</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>IF nodes can also have an optional second body graph which is executed once when the node is executed if the condition value is zero.</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">graphSetup</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cudaGraph_t</span><span class="w"> </span><span class="n">graph</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphExec_t</span><span class="w"> </span><span class="n">graphExec</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphNode_t</span><span class="w"> </span><span class="n">node</span><span class="p">;</span>
<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">kernelArgs</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Create the graph</span>
<span class="w">    </span><span class="n">cudaGraphCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Create the conditional handle; because no default value is provided, the condition value is undefined at the start of each graph execution</span>
<span class="w">    </span><span class="n">cudaGraphConditionalHandle</span><span class="w"> </span><span class="n">handle</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphConditionalHandleCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">handle</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Use a kernel upstream of the conditional to set the handle value</span>
<span class="w">    </span><span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeKernel</span><span class="w"> </span><span class="p">};</span>
<span class="w">    </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="n">func</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">setHandle</span><span class="p">;</span>
<span class="w">    </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">gridDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">gridDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">gridDim</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="n">kernelParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kernelArgs</span><span class="p">;</span>
<span class="w">    </span><span class="n">kernelArgs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">handle</span><span class="p">;</span>
<span class="w">    </span><span class="n">kernelArgs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">value</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">params</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Create and add the IF conditional node</span>
<span class="w">    </span><span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">cParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeConditional</span><span class="w"> </span><span class="p">};</span>
<span class="w">    </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">handle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">handle</span><span class="p">;</span>
<span class="w">    </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">type</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">cudaGraphCondTypeIf</span><span class="p">;</span>
<span class="w">    </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">size</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span><span class="w"> </span><span class="c1">// There is both an &quot;if&quot; and an &quot;else&quot; body graph</span>
<span class="w">    </span><span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cParams</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Get the body graphs of the conditional node</span>
<span class="w">    </span><span class="n">cudaGraph_t</span><span class="w"> </span><span class="n">ifBodyGraph</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">phGraph_out</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="w">    </span><span class="n">cudaGraph_t</span><span class="w"> </span><span class="n">elseBodyGraph</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">phGraph_out</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>

<span class="w">    </span><span class="c1">// Populate the body graphs of the IF conditional node</span>
<span class="w">    </span><span class="p">...</span>
<span class="w">    </span><span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">ifBodyGraph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">params</span><span class="p">);</span>
<span class="w">    </span><span class="p">...</span>
<span class="w">    </span><span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">elseBodyGraph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">params</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Instantiate and launch the graph</span>
<span class="w">    </span><span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaDeviceSynchronize</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// Clean up</span>
<span class="w">    </span><span class="n">cudaGraphExecDestroy</span><span class="p">(</span><span class="n">graphExec</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphDestroy</span><span class="p">(</span><span class="n">graph</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="conditional-while-nodes">
<span id="cuda-graphs-conditional-while-nodes"></span><h3><span class="section-number">4.2.4.4. </span>Conditional WHILE Nodes<a class="headerlink" href="#conditional-while-nodes" title="Link to this heading">#</a></h3>
<p>The body graph of a WHILE node will be executed as long as the condition is non-zero. The condition will be
evaluated when the node is executed and after completion of the body graph. The following diagram depicts
a 3 node graph where the middle node, B, is a conditional node:</p>
<figure class="align-default" id="id6">
<img alt="../_images/conditional-while-node.png" class="image" src="../_images/conditional-while-node.png" />
<figcaption>
<p><span class="caption-number">Figure 25 </span><span class="caption-text">Conditional WHILE Node</span><a class="headerlink" href="#id6" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>The following code illustrates the creation of a graph containing a WHILE conditional node. The handle
is created using <em>cudaGraphCondAssignDefault</em> to avoid the need for an upstream kernel. The body of the
conditional is populated using the <a class="reference internal" href="#cuda-graphs-creating-a-graph-using-graph-apis"><span class="std std-ref">graph API</span></a>.</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">loopKernel</span><span class="p">(</span><span class="n">cudaGraphConditionalHandle</span><span class="w"> </span><span class="n">handle</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">dPtr</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">   </span><span class="c1">// Decrement the value of dPtr and set the condition value to 0 once dPtr is 0</span>
<span class="w">   </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">--</span><span class="p">(</span><span class="o">*</span><span class="n">dPtr</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">cudaGraphSetConditional</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">   </span><span class="p">}</span>
<span class="p">}</span>

<span class="kt">void</span><span class="w"> </span><span class="n">graphSetup</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cudaGraph_t</span><span class="w"> </span><span class="n">graph</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphExec_t</span><span class="w"> </span><span class="n">graphExec</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphNode_t</span><span class="w"> </span><span class="n">node</span><span class="p">;</span>
<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">kernelArgs</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>

<span class="w">    </span><span class="c1">// Allocate a byte of device memory to use as input</span>
<span class="w">    </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">dPtr</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dPtr</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Create the graph</span>
<span class="w">    </span><span class="n">cudaGraphCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Create the conditional handle with a default value of 1</span>
<span class="w">    </span><span class="n">cudaGraphConditionalHandle</span><span class="w"> </span><span class="n">handle</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphConditionalHandleCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">handle</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">cudaGraphCondAssignDefault</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Create and add the WHILE conditional node</span>
<span class="w">    </span><span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">cParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeConditional</span><span class="w"> </span><span class="p">};</span>
<span class="w">    </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">handle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">handle</span><span class="p">;</span>
<span class="w">    </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">type</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">cudaGraphCondTypeWhile</span><span class="p">;</span>
<span class="w">    </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">size</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cParams</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Get the body graph of the conditional node</span>
<span class="w">    </span><span class="n">cudaGraph_t</span><span class="w"> </span><span class="n">bodyGraph</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">phGraph_out</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>

<span class="w">    </span><span class="c1">// Populate the body graph of the conditional node</span>
<span class="w">    </span><span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeKernel</span><span class="w"> </span><span class="p">};</span>
<span class="w">    </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="n">func</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">loopKernel</span><span class="p">;</span>
<span class="w">    </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">gridDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">gridDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">gridDim</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="n">kernelParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kernelArgs</span><span class="p">;</span>
<span class="w">    </span><span class="n">kernelArgs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">handle</span><span class="p">;</span>
<span class="w">    </span><span class="n">kernelArgs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">dPtr</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">bodyGraph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">params</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Initialize device memory, instantiate, and launch the graph</span>
<span class="w">    </span><span class="n">cudaMemset</span><span class="p">(</span><span class="n">dPtr</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w"> </span><span class="c1">// Set dPtr to 10; the loop will run until dPtr is 0</span>
<span class="w">    </span><span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaDeviceSynchronize</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// Clean up</span>
<span class="w">    </span><span class="n">cudaGraphExecDestroy</span><span class="p">(</span><span class="n">graphExec</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphDestroy</span><span class="p">(</span><span class="n">graph</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">dPtr</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="conditional-switch-nodes">
<span id="cuda-graphs-conditional-switch-nodes"></span><h3><span class="section-number">4.2.4.5. </span>Conditional SWITCH Nodes<a class="headerlink" href="#conditional-switch-nodes" title="Link to this heading">#</a></h3>
<p>The zero-indexed nth body graph of a SWITCH node will be executed once if the condition is equal to n when the node is executed.  The following diagram depicts a 3 node graph where the middle node, B, is a conditional node:</p>
<figure class="align-default" id="id7">
<img alt="../_images/conditional-switch-node.png" class="image" src="../_images/conditional-switch-node.png" />
<figcaption>
<p><span class="caption-number">Figure 26 </span><span class="caption-text">Conditional SWITCH Node</span><a class="headerlink" href="#id7" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>The following code illustrates the creation of a graph containing a SWITCH conditional node. The value of the condition is set using an upstream kernel. The bodies of the conditional are populated using the <a class="reference internal" href="#cuda-graphs-creating-a-graph-using-graph-apis"><span class="std std-ref">graph API</span></a>.</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">setHandle</span><span class="p">(</span><span class="n">cudaGraphConditionalHandle</span><span class="w"> </span><span class="n">handle</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">value</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="p">...</span>
<span class="w">    </span><span class="c1">// Set the condition value to the value passed to the kernel</span>
<span class="w">    </span><span class="n">cudaGraphSetConditional</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="w">    </span><span class="p">...</span>
<span class="p">}</span>

<span class="kt">void</span><span class="w"> </span><span class="n">graphSetup</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cudaGraph_t</span><span class="w"> </span><span class="n">graph</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphExec_t</span><span class="w"> </span><span class="n">graphExec</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphNode_t</span><span class="w"> </span><span class="n">node</span><span class="p">;</span>
<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">kernelArgs</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Create the graph</span>
<span class="w">    </span><span class="n">cudaGraphCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Create the conditional handle; because no default value is provided, the condition value is undefined at the start of each graph execution</span>
<span class="w">    </span><span class="n">cudaGraphConditionalHandle</span><span class="w"> </span><span class="n">handle</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphConditionalHandleCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">handle</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Use a kernel upstream of the conditional to set the handle value</span>
<span class="w">    </span><span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeKernel</span><span class="w"> </span><span class="p">};</span>
<span class="w">    </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="n">func</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">setHandle</span><span class="p">;</span>
<span class="w">    </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">gridDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">gridDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">gridDim</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="n">params</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="n">kernelParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kernelArgs</span><span class="p">;</span>
<span class="w">    </span><span class="n">kernelArgs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">handle</span><span class="p">;</span>
<span class="w">    </span><span class="n">kernelArgs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">value</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">params</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Create and add the conditional SWITCH node</span>
<span class="w">    </span><span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">cParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeConditional</span><span class="w"> </span><span class="p">};</span>
<span class="w">    </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">handle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">handle</span><span class="p">;</span>
<span class="w">    </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">type</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">cudaGraphCondTypeSwitch</span><span class="p">;</span>
<span class="w">    </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">size</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cParams</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Get the body graphs of the conditional node</span>
<span class="w">    </span><span class="n">cudaGraph_t</span><span class="w"> </span><span class="o">*</span><span class="n">bodyGraphs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cParams</span><span class="p">.</span><span class="n">conditional</span><span class="p">.</span><span class="n">phGraph_out</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Populate the body graphs of the SWITCH conditional node</span>
<span class="w">    </span><span class="p">...</span>
<span class="w">    </span><span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">bodyGraphs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">params</span><span class="p">);</span>
<span class="w">    </span><span class="p">...</span>
<span class="w">    </span><span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">bodyGraphs</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">params</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Instantiate and launch the graph</span>
<span class="w">    </span><span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaDeviceSynchronize</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// Clean up</span>
<span class="w">    </span><span class="n">cudaGraphExecDestroy</span><span class="p">(</span><span class="n">graphExec</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphDestroy</span><span class="p">(</span><span class="n">graph</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
<section id="graph-memory-nodes">
<span id="cuda-graphs-graph-memory-nodes"></span><h2><span class="section-number">4.2.5. </span>Graph Memory Nodes<a class="headerlink" href="#graph-memory-nodes" title="Link to this heading">#</a></h2>
<section id="introduction">
<span id="cuda-graphs-graph-memory-nodes-intro"></span><h3><span class="section-number">4.2.5.1. </span>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h3>
<p>Graph memory nodes allow graphs to create and own memory allocations. Graph memory nodes have GPU ordered lifetime semantics, which dictate when memory is allowed to be accessed on the device. These GPU ordered lifetime semantics enable driver-managed memory reuse, and match those of the stream ordered allocation APIs <code class="docutils literal notranslate"><span class="pre">cudaMallocAsync</span></code> and <code class="docutils literal notranslate"><span class="pre">cudaFreeAsync</span></code>, which may be captured when creating a graph.</p>
<p>Graph allocations have fixed addresses over the life of a graph including repeated instantiations and launches. This allows the memory to be directly referenced by other operations within the graph without the need of a graph update, even when CUDA changes the backing physical memory. Within a graph, allocations whose graph ordered lifetimes do not overlap may use the same underlying physical memory.</p>
<p>CUDA may reuse the same physical memory for allocations across multiple graphs, aliasing virtual address mappings according to the GPU ordered lifetime semantics. For example when different graphs are launched into the same stream, CUDA may virtually alias the same physical memory to satisfy the needs of allocations which have single-graph lifetimes.</p>
</section>
<section id="api-fundamentals">
<span id="cuda-graphs-graph-memory-node-api-fundamentals"></span><h3><span class="section-number">4.2.5.2. </span>API Fundamentals<a class="headerlink" href="#api-fundamentals" title="Link to this heading">#</a></h3>
<p>Graph memory nodes are graph nodes representing either memory allocation or free actions. As a shorthand, nodes that allocate memory are called allocation nodes. Likewise, nodes that free memory are called free nodes. Allocations created by allocation nodes are called graph allocations. CUDA assigns virtual addresses for the graph allocation at node creation time. While these virtual addresses are fixed for the lifetime of the allocation node, the allocation contents are not persistent past the freeing operation and may be overwritten by accesses referring to a different allocation.</p>
<p>Graph allocations are considered recreated every time a graph runs. A graph allocation’s lifetime, which differs from the node’s lifetime, begins when GPU execution reaches the allocating graph node and ends when one of the following occurs:</p>
<ul class="simple">
<li><p>GPU execution reaches the freeing graph node</p></li>
<li><p>GPU execution reaches the freeing <code class="docutils literal notranslate"><span class="pre">cudaFreeAsync()</span></code> stream call</p></li>
<li><p>immediately upon the freeing call to <code class="docutils literal notranslate"><span class="pre">cudaFree()</span></code></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Graph destruction does not automatically free any live graph-allocated memory, even though it ends the lifetime of the allocation node. The allocation must subsequently be freed in another graph, or using <code class="docutils literal notranslate"><span class="pre">cudaFreeAsync()</span></code><code class="docutils literal notranslate"><span class="pre">/cudaFree()</span></code>.</p>
</div>
<p>Just like other <a class="reference internal" href="#cuda-graphs-graph-structure"><span class="std std-ref">graph-structure</span></a>, graph memory nodes are ordered within a graph by dependency edges. A program must guarantee that operations accessing graph memory:</p>
<ul class="simple">
<li><p>are ordered after the allocation node</p></li>
<li><p>are ordered before the operation freeing the memory</p></li>
</ul>
<p>Graph allocation lifetimes begin and usually end according to GPU execution (as opposed to API invocation). GPU ordering is the order that work runs on the GPU as opposed to the order that the work is enqueued or described. Thus, graph allocations are considered ‘GPU ordered.’</p>
<section id="graph-node-apis">
<span id="cuda-graphs-graph-node-apis"></span><h4><span class="section-number">4.2.5.2.1. </span>Graph Node APIs<a class="headerlink" href="#graph-node-apis" title="Link to this heading">#</a></h4>
<p>Graph memory nodes may be explicitly created with the node creation API, <code class="docutils literal notranslate"><span class="pre">cudaGraphAddNode</span></code>. The address allocated when adding a cudaGraphNodeTypeMemAlloc node is returned to the user in the <code class="docutils literal notranslate"><span class="pre">alloc::dptr</span></code> field of the passed <code class="docutils literal notranslate"><span class="pre">cudaGraphNodeParams</span></code> structure. All operations using graph allocations inside the allocating graph must be ordered after the allocating node. Similarly, any free nodes must be ordered after all uses of the allocation within the graph. Free nodes are created using <code class="docutils literal notranslate"><span class="pre">cudaGraphAddNode</span></code> and a node type of cudaGraphNodeTypeMemFree.</p>
<p>In the following figure, there is an example graph with an alloc and a free node. Kernel nodes <strong>a</strong>, <strong>b</strong>, and <strong>c</strong> are ordered after the allocation node and before the free node such that the kernels can access the allocation. Kernel node <strong>e</strong> is not ordered after the alloc node and therefore cannot safely access the memory. Kernel node <strong>d</strong> is not ordered before the free node, therefore it cannot safely access the memory.</p>
<figure class="align-default" id="id8">
<img alt="Kernel Nodes" src="../_images/kernel-nodes.png" />
<figcaption>
<p><span class="caption-number">Figure 27 </span><span class="caption-text">Kernel Nodes</span><a class="headerlink" href="#id8" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>The following code snippet establishes the graph in this figure:</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="c1">// Create the graph - it starts out empty</span>
<span class="n">cudaGraphCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="c1">// parameters for a basic allocation</span>
<span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeMemAlloc</span><span class="w"> </span><span class="p">};</span>
<span class="n">params</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">poolProps</span><span class="p">.</span><span class="n">allocType</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemAllocationTypePinned</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">poolProps</span><span class="p">.</span><span class="n">location</span><span class="p">.</span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemLocationTypeDevice</span><span class="p">;</span>
<span class="c1">// specify device 0 as the resident device</span>
<span class="n">params</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">poolProps</span><span class="p">.</span><span class="n">location</span><span class="p">.</span><span class="n">id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">bytesize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">size</span><span class="p">;</span>

<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">allocNode</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">params</span><span class="p">);</span>

<span class="c1">// create a kernel node that uses the graph allocation</span>
<span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">nodeParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeKernel</span><span class="w"> </span><span class="p">};</span>
<span class="n">nodeParams</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="n">kernelParams</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">dptr</span><span class="p">;</span>
<span class="c1">// ...set other kernel node parameters...</span>

<span class="c1">// add the kernel node to the graph</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">allocNode</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nodeParams</span><span class="p">);</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nodeParams</span><span class="p">);</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nodeParams</span><span class="p">);</span>
<span class="n">cudaGraphNode_t</span><span class="w"> </span><span class="n">dependencies</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="c1">// kernel nodes b and c are using the graph allocation, so the freeing node must depend on them.  Since the dependency of node b on node a establishes an indirect dependency, the free node does not need to explicitly depend on node a.</span>
<span class="n">dependencies</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b</span><span class="p">;</span>
<span class="n">dependencies</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">c</span><span class="p">;</span>
<span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">freeNodeParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeMemFree</span><span class="w"> </span><span class="p">};</span>
<span class="n">freeNodeParams</span><span class="p">.</span><span class="n">free</span><span class="p">.</span><span class="n">dptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">dptr</span><span class="p">;</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">freeNode</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="n">dependencies</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">freeNodeParams</span><span class="p">);</span>
<span class="c1">// free node does not depend on kernel node d, so it must not access the freed graph allocation.</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nodeParams</span><span class="p">);</span>

<span class="c1">// node e does not depend on the allocation node, so it must not access the allocation.  This would be true even if the freeNode depended on kernel node e.</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">e</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nodeParams</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="cuda-graphs-graph-memory-nodes-stream-capture">
<span id="id3"></span><h4><span class="section-number">4.2.5.2.2. </span>Stream Capture<a class="headerlink" href="#cuda-graphs-graph-memory-nodes-stream-capture" title="Link to this heading">#</a></h4>
<p>Graph memory nodes can be created by capturing the corresponding stream ordered allocation and free calls <code class="docutils literal notranslate"><span class="pre">cudaMallocAsync</span></code> and <code class="docutils literal notranslate"><span class="pre">cudaFreeAsync</span></code>. In this case, the virtual addresses returned by the captured allocation API can be used by other operations inside the graph. Since the stream ordered dependencies will be captured into the graph, the ordering requirements of the stream ordered allocation APIs guarantee that the graph memory nodes will be properly ordered with respect to the captured stream operations (for correctly written stream code).</p>
<p>Ignoring kernel nodes <strong>d</strong> and <strong>e</strong>, for clarity, the following code snippet shows how to use stream capture to create the graph from the previous figure:</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="n">cudaMallocAsync</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dptr</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">stream1</span><span class="p">);</span>
<span class="n">kernel_A</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">stream1</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">dptr</span><span class="p">,</span><span class="w"> </span><span class="p">...);</span>

<span class="c1">// Fork into stream2</span>
<span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">event1</span><span class="p">,</span><span class="w"> </span><span class="n">stream1</span><span class="p">);</span>
<span class="n">cudaStreamWaitEvent</span><span class="p">(</span><span class="n">stream2</span><span class="p">,</span><span class="w"> </span><span class="n">event1</span><span class="p">);</span>

<span class="n">kernel_B</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">stream1</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">dptr</span><span class="p">,</span><span class="w"> </span><span class="p">...);</span>
<span class="c1">// event dependencies translated into graph dependencies, so the kernel node created by the capture of kernel C will depend on the allocation node created by capturing the cudaMallocAsync call.</span>
<span class="n">kernel_C</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">stream2</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">dptr</span><span class="p">,</span><span class="w"> </span><span class="p">...);</span>

<span class="c1">// Join stream2 back to origin stream (stream1)</span>
<span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">event2</span><span class="p">,</span><span class="w"> </span><span class="n">stream2</span><span class="p">);</span>
<span class="n">cudaStreamWaitEvent</span><span class="p">(</span><span class="n">stream1</span><span class="p">,</span><span class="w"> </span><span class="n">event2</span><span class="p">);</span>

<span class="c1">// Free depends on all work accessing the memory.</span>
<span class="n">cudaFreeAsync</span><span class="p">(</span><span class="n">dptr</span><span class="p">,</span><span class="w"> </span><span class="n">stream1</span><span class="p">);</span>

<span class="c1">// End capture in the origin stream</span>
<span class="n">cudaStreamEndCapture</span><span class="p">(</span><span class="n">stream1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graph</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="accessing-and-freeing-graph-memory-outside-of-the-allocating-graph">
<span id="cuda-graphs-graph-memory-accessing-and-freeing"></span><h4><span class="section-number">4.2.5.2.3. </span>Accessing and Freeing Graph Memory Outside of the Allocating Graph<a class="headerlink" href="#accessing-and-freeing-graph-memory-outside-of-the-allocating-graph" title="Link to this heading">#</a></h4>
<p>Graph allocations do not have to be freed by the allocating graph. When a graph does not free an allocation, that allocation persists beyond the execution of the graph and can be accessed by subsequent CUDA operations. These allocations may be accessed in another graph or directly using a stream operation as long as the accessing operation is ordered after the allocation through CUDA events and other stream ordering mechanisms. An allocation may subsequently be freed by regular calls to <code class="docutils literal notranslate"><span class="pre">cudaFree</span></code>, <code class="docutils literal notranslate"><span class="pre">cudaFreeAsync</span></code>, or by the launch of another graph with a corresponding free node, or a subsequent launch of the allocating graph (if it was instantiated with the <a class="reference internal" href="#cuda-graphs-graph-memory-nodes-cudagraphinstantiateflagautofreeonlaunch"><span class="std std-ref">graph-memory-nodes-cudagraphinstantiateflagautofreeonlaunch</span></a> flag). It is illegal to access memory after it has been freed - the free operation must be ordered after all operations accessing the memory using graph dependencies, CUDA events, and other stream ordering mechanisms.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Since graph allocations may share underlying physical memory, free operations must be ordered after all device operations complete. Out-of-band synchronization (such as memory-based synchronization within a compute kernel) is insufficient for ordering between memory writes and free operations. For more information, see the <a class="reference internal" href="virtual-memory-management.html#virtual-aliasing-support"><span class="std std-ref">Virtual Aliasing Support</span></a> rules relating to consistency and coherency.</p>
</div>
<p>The three following code snippets demonstrate accessing graph allocations outside of the allocating graph with ordering properly established by: using a single stream, using events between streams, and using events baked into the allocating and freeing graph.</p>
<p>First, ordering established by using a single stream:</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="c1">// Contents of allocating graph</span>
<span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">dptr</span><span class="p">;</span>
<span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeMemAlloc</span><span class="w"> </span><span class="p">};</span>
<span class="n">params</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">poolProps</span><span class="p">.</span><span class="n">allocType</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemAllocationTypePinned</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">poolProps</span><span class="p">.</span><span class="n">location</span><span class="p">.</span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemLocationTypeDevice</span><span class="p">;</span>
<span class="n">params</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">bytesize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">size</span><span class="p">;</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">allocNode</span><span class="p">,</span><span class="w"> </span><span class="n">allocGraph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">params</span><span class="p">);</span>
<span class="n">dptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">params</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">dptr</span><span class="p">;</span>

<span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">allocGraphExec</span><span class="p">,</span><span class="w"> </span><span class="n">allocGraph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">allocGraphExec</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
<span class="n">kernel</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">stream</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">dptr</span><span class="p">,</span><span class="w"> </span><span class="p">...);</span>
<span class="n">cudaFreeAsync</span><span class="p">(</span><span class="n">dptr</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
</pre></div>
</div>
<p>Second, ordering established by recording and waiting on CUDA events:</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="c1">// Contents of allocating graph</span>
<span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">dptr</span><span class="p">;</span>

<span class="c1">// Contents of allocating graph</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">allocNode</span><span class="p">,</span><span class="w"> </span><span class="n">allocGraph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">allocNodeParams</span><span class="p">);</span>
<span class="n">dptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">allocNodeParams</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">dptr</span><span class="p">;</span>

<span class="c1">// contents of consuming/freeing graph</span>
<span class="n">kernelNodeParams</span><span class="p">.</span><span class="n">kernel</span><span class="p">.</span><span class="n">kernelParams</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">allocNodeParams</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">dptr</span><span class="p">;</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">freeNode</span><span class="p">,</span><span class="w"> </span><span class="n">freeGraph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">dptr</span><span class="p">);</span>

<span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">allocGraphExec</span><span class="p">,</span><span class="w"> </span><span class="n">allocGraph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">freeGraphExec</span><span class="p">,</span><span class="w"> </span><span class="n">freeGraph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">allocGraphExec</span><span class="p">,</span><span class="w"> </span><span class="n">allocStream</span><span class="p">);</span>

<span class="c1">// establish the dependency of stream2 on the allocation node</span>
<span class="c1">// note: the dependency could also have been established with a stream synchronize operation</span>
<span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">allocEvent</span><span class="p">,</span><span class="w"> </span><span class="n">allocStream</span><span class="p">);</span>
<span class="n">cudaStreamWaitEvent</span><span class="p">(</span><span class="n">stream2</span><span class="p">,</span><span class="w"> </span><span class="n">allocEvent</span><span class="p">);</span>

<span class="n">kernel</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">stream2</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="p">(</span><span class="n">dptr</span><span class="p">,</span><span class="w"> </span><span class="p">...);</span>

<span class="c1">// establish the dependency between the stream 3 and the allocation use</span>
<span class="n">cudaStreamRecordEvent</span><span class="p">(</span><span class="n">streamUseDoneEvent</span><span class="p">,</span><span class="w"> </span><span class="n">stream2</span><span class="p">);</span>
<span class="n">cudaStreamWaitEvent</span><span class="p">(</span><span class="n">stream3</span><span class="p">,</span><span class="w"> </span><span class="n">streamUseDoneEvent</span><span class="p">);</span>

<span class="c1">// it is now safe to launch the freeing graph, which may also access the memory</span>
<span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">freeGraphExec</span><span class="p">,</span><span class="w"> </span><span class="n">stream3</span><span class="p">);</span>
</pre></div>
</div>
<p>Third, ordering established by using graph external event nodes:</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="c1">// Contents of allocating graph</span>
<span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">dptr</span><span class="p">;</span>
<span class="n">cudaEvent_t</span><span class="w"> </span><span class="n">allocEvent</span><span class="p">;</span><span class="w"> </span><span class="c1">// event indicating when the allocation will be ready for use.</span>
<span class="n">cudaEvent_t</span><span class="w"> </span><span class="n">streamUseDoneEvent</span><span class="p">;</span><span class="w"> </span><span class="c1">// event indicating when the stream operations are done with the allocation.</span>

<span class="c1">// Contents of allocating graph with event record node</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">allocNode</span><span class="p">,</span><span class="w"> </span><span class="n">allocGraph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">allocNodeParams</span><span class="p">);</span>
<span class="n">dptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">allocNodeParams</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">dptr</span><span class="p">;</span>
<span class="c1">// note: this event record node depends on the alloc node</span>

<span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">allocEventNodeParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeEventRecord</span><span class="w"> </span><span class="p">};</span>
<span class="n">allocEventParams</span><span class="p">.</span><span class="n">eventRecord</span><span class="p">.</span><span class="n">event</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">allocEvent</span><span class="p">;</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">recordNode</span><span class="p">,</span><span class="w"> </span><span class="n">allocGraph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">allocNode</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">allocEventNodeParams</span><span class="p">);</span>
<span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">allocGraphExec</span><span class="p">,</span><span class="w"> </span><span class="n">allocGraph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="c1">// contents of consuming/freeing graph with event wait nodes</span>
<span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">streamWaitEventNodeParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeEventWait</span><span class="w"> </span><span class="p">};</span>
<span class="n">streamWaitEventNodeParams</span><span class="p">.</span><span class="n">eventWait</span><span class="p">.</span><span class="n">event</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">streamUseDoneEvent</span><span class="p">;</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">streamUseDoneEventNode</span><span class="p">,</span><span class="w"> </span><span class="n">waitAndFreeGraph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">streamWaitEventNodeParams</span><span class="p">);</span>

<span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">allocWaitEventNodeParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeEventWait</span><span class="w"> </span><span class="p">};</span>
<span class="n">allocWaitEventNodeParams</span><span class="p">.</span><span class="n">eventWait</span><span class="p">.</span><span class="n">event</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">allocEvent</span><span class="p">;</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">allocReadyEventNode</span><span class="p">,</span><span class="w"> </span><span class="n">waitAndFreeGraph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">allocWaitEventNodeParams</span><span class="p">);</span>

<span class="n">kernelNodeParams</span><span class="o">-&gt;</span><span class="n">kernelParams</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">allocNodeParams</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">dptr</span><span class="p">;</span>

<span class="c1">// The allocReadyEventNode provides ordering with the alloc node for use in a consuming graph.</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">kernelNode</span><span class="p">,</span><span class="w"> </span><span class="n">waitAndFreeGraph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">allocReadyEventNode</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">kernelNodeParams</span><span class="p">);</span>

<span class="c1">// The free node has to be ordered after both external and internal users.</span>
<span class="c1">// Thus the node must depend on both the kernelNode and the streamUseDoneEventNode.</span>
<span class="n">dependencies</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kernelNode</span><span class="p">;</span>
<span class="n">dependencies</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">streamUseDoneEventNode</span><span class="p">;</span>

<span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">freeNodeParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeMemFree</span><span class="w"> </span><span class="p">};</span>
<span class="n">freeNodeParams</span><span class="p">.</span><span class="n">free</span><span class="p">.</span><span class="n">dptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dptr</span><span class="p">;</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">freeNode</span><span class="p">,</span><span class="w"> </span><span class="n">waitAndFreeGraph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">dependencies</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">freeNodeParams</span><span class="p">);</span>
<span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">waitAndFreeGraphExec</span><span class="p">,</span><span class="w"> </span><span class="n">waitAndFreeGraph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">allocGraphExec</span><span class="p">,</span><span class="w"> </span><span class="n">allocStream</span><span class="p">);</span>

<span class="c1">// establish the dependency of stream2 on the event node satisfies the ordering requirement</span>
<span class="n">cudaStreamWaitEvent</span><span class="p">(</span><span class="n">stream2</span><span class="p">,</span><span class="w"> </span><span class="n">allocEvent</span><span class="p">);</span>
<span class="n">kernel</span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">stream2</span><span class="w"> </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="p">(</span><span class="n">dptr</span><span class="p">,</span><span class="w"> </span><span class="p">...);</span>
<span class="n">cudaStreamRecordEvent</span><span class="p">(</span><span class="n">streamUseDoneEvent</span><span class="p">,</span><span class="w"> </span><span class="n">stream2</span><span class="p">);</span>

<span class="c1">// the event wait node in the waitAndFreeGraphExec establishes the dependency on the &quot;readyForFreeEvent&quot; that is needed to prevent the kernel running in stream two from accessing the allocation after the free node in execution order.</span>
<span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">waitAndFreeGraphExec</span><span class="p">,</span><span class="w"> </span><span class="n">stream3</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="cudagraphinstantiateflagautofreeonlaunch">
<span id="cuda-graphs-graph-memory-nodes-cudagraphinstantiateflagautofreeonlaunch"></span><h4><span class="section-number">4.2.5.2.4. </span>cudaGraphInstantiateFlagAutoFreeOnLaunch<a class="headerlink" href="#cudagraphinstantiateflagautofreeonlaunch" title="Link to this heading">#</a></h4>
<p>Under normal circumstances, CUDA will prevent a graph from being relaunched if it has unfreed memory allocations because multiple allocations at the same address will leak memory. Instantiating a graph with the <code class="docutils literal notranslate"><span class="pre">cudaGraphInstantiateFlagAutoFreeOnLaunch</span></code> flag allows the graph to be relaunched while it still has unfreed allocations. In this case, the launch automatically inserts an asynchronous free of the unfreed allocations.</p>
<p>Auto free on launch is useful for single-producer multiple-consumer algorithms. At each iteration, a producer graph creates several allocations, and, depending on runtime conditions, a varying set of consumers accesses those allocations. This type of variable execution sequence means that consumers cannot free the allocations because a subsequent consumer may require access. Auto free on launch means that the launch loop does not need to track the producer’s allocations - instead, that information remains isolated to the producer’s creation and destruction logic. In general, auto free on launch simplifies an algorithm which would otherwise need to free all the allocations owned by a graph before each relaunch.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">cudaGraphInstantiateFlagAutoFreeOnLaunch</span></code> flag does not change the behavior of graph destruction. The application must explicitly free the unfreed memory in order to avoid memory leaks, even for graphs instantiated with the flag.
The following code shows the use of <code class="docutils literal notranslate"><span class="pre">cudaGraphInstantiateFlagAutoFreeOnLaunch</span></code> to simplify a single-producer / multiple-consumer algorithm:</p>
</div>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="c1">// Create producer graph which allocates memory and populates it with data</span>
<span class="n">cudaStreamBeginCapture</span><span class="p">(</span><span class="n">cudaStreamPerThread</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamCaptureModeGlobal</span><span class="p">);</span>
<span class="n">cudaMallocAsync</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data1</span><span class="p">,</span><span class="w"> </span><span class="n">blocks</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">threads</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamPerThread</span><span class="p">);</span>
<span class="n">cudaMallocAsync</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data2</span><span class="p">,</span><span class="w"> </span><span class="n">blocks</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">threads</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamPerThread</span><span class="p">);</span>
<span class="n">produce</span><span class="o">&lt;&lt;&lt;</span><span class="n">blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threads</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamPerThread</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span><span class="w"> </span><span class="n">data2</span><span class="p">);</span>
<span class="p">...</span>
<span class="n">cudaStreamEndCapture</span><span class="p">(</span><span class="n">cudaStreamPerThread</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graph</span><span class="p">);</span>
<span class="n">cudaGraphInstantiateWithFlags</span><span class="p">(</span><span class="o">&amp;</span><span class="n">producer</span><span class="p">,</span>
<span class="w">                              </span><span class="n">graph</span><span class="p">,</span>
<span class="w">                              </span><span class="n">cudaGraphInstantiateFlagAutoFreeOnLaunch</span><span class="p">);</span>
<span class="n">cudaGraphDestroy</span><span class="p">(</span><span class="n">graph</span><span class="p">);</span>

<span class="c1">// Create first consumer graph by capturing an asynchronous library call</span>
<span class="n">cudaStreamBeginCapture</span><span class="p">(</span><span class="n">cudaStreamPerThread</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamCaptureModeGlobal</span><span class="p">);</span>
<span class="n">consumerFromLibrary</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamPerThread</span><span class="p">);</span>
<span class="n">cudaStreamEndCapture</span><span class="p">(</span><span class="n">cudaStreamPerThread</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graph</span><span class="p">);</span>
<span class="n">cudaGraphInstantiateWithFlags</span><span class="p">(</span><span class="o">&amp;</span><span class="n">consumer1</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w"> </span><span class="c1">//regular instantiation</span>
<span class="n">cudaGraphDestroy</span><span class="p">(</span><span class="n">graph</span><span class="p">);</span>

<span class="c1">// Create second consumer graph</span>
<span class="n">cudaStreamBeginCapture</span><span class="p">(</span><span class="n">cudaStreamPerThread</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamCaptureModeGlobal</span><span class="p">);</span>
<span class="n">consume2</span><span class="o">&lt;&lt;&lt;</span><span class="n">blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threads</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamPerThread</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">data2</span><span class="p">);</span>
<span class="p">...</span>
<span class="n">cudaStreamEndCapture</span><span class="p">(</span><span class="n">cudaStreamPerThread</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graph</span><span class="p">);</span>
<span class="n">cudaGraphInstantiateWithFlags</span><span class="p">(</span><span class="o">&amp;</span><span class="n">consumer2</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="n">cudaGraphDestroy</span><span class="p">(</span><span class="n">graph</span><span class="p">);</span>

<span class="c1">// Launch in a loop</span>
<span class="kt">bool</span><span class="w"> </span><span class="n">launchConsumer2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="k">do</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">producer</span><span class="p">,</span><span class="w"> </span><span class="n">myStream</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">consumer1</span><span class="p">,</span><span class="w"> </span><span class="n">myStream</span><span class="p">);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">launchConsumer2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">consumer2</span><span class="p">,</span><span class="w"> </span><span class="n">myStream</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span><span class="w"> </span><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="n">determineAction</span><span class="p">(</span><span class="o">&amp;</span><span class="n">launchConsumer2</span><span class="p">));</span>

<span class="n">cudaFreeAsync</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span><span class="w"> </span><span class="n">myStream</span><span class="p">);</span>
<span class="n">cudaFreeAsync</span><span class="p">(</span><span class="n">data2</span><span class="p">,</span><span class="w"> </span><span class="n">myStream</span><span class="p">);</span>

<span class="n">cudaGraphExecDestroy</span><span class="p">(</span><span class="n">producer</span><span class="p">);</span>
<span class="n">cudaGraphExecDestroy</span><span class="p">(</span><span class="n">consumer1</span><span class="p">);</span>
<span class="n">cudaGraphExecDestroy</span><span class="p">(</span><span class="n">consumer2</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="memory-nodes-in-child-graphs">
<span id="cuda-graphs-graph-memory-nodes-memory-nodes-in-child-graphs"></span><h4><span class="section-number">4.2.5.2.5. </span>Memory Nodes in Child Graphs<a class="headerlink" href="#memory-nodes-in-child-graphs" title="Link to this heading">#</a></h4>
<p>CUDA 12.9 introduces the ability to move child graph ownership to a parent graph. Child graphs which are moved to the parent are allowed to contain memory allocation and free nodes. This allows a child graph containing allocation or free nodes to be independently constructed prior to its addition in a parent graph.</p>
<p>The following restrictions apply to child graphs after they have been moved:</p>
<ul class="simple">
<li><p>Cannot be independently instantiated or destroyed.</p></li>
<li><p>Cannot be added as a child graph of a separate parent graph.</p></li>
<li><p>Cannot be used as an argument to cuGraphExecUpdate.</p></li>
<li><p>Cannot have additional memory allocation or free nodes added.</p></li>
</ul>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="c1">// Create the child graph</span>
<span class="n">cudaGraphCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">child</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="c1">// parameters for a basic allocation</span>
<span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">allocNodeParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeMemAlloc</span><span class="w"> </span><span class="p">};</span>
<span class="n">allocNodeParams</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">poolProps</span><span class="p">.</span><span class="n">allocType</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemAllocationTypePinned</span><span class="p">;</span>
<span class="n">allocNodeParams</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">poolProps</span><span class="p">.</span><span class="n">location</span><span class="p">.</span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemLocationTypeDevice</span><span class="p">;</span>
<span class="c1">// specify device 0 as the resident device</span>
<span class="n">allocNodeParams</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">poolProps</span><span class="p">.</span><span class="n">location</span><span class="p">.</span><span class="n">id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="n">allocNodeParams</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">bytesize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">size</span><span class="p">;</span>

<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">allocNode</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">allocNodeParams</span><span class="p">);</span>
<span class="c1">// Additional nodes using the allocation could be added here</span>
<span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">freeNodeParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeMemFree</span><span class="w"> </span><span class="p">};</span>
<span class="n">freeNodeParams</span><span class="p">.</span><span class="n">free</span><span class="p">.</span><span class="n">dptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">allocNodeParams</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">dptr</span><span class="p">;</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">freeNode</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">allocNode</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">freeNodeParams</span><span class="p">);</span>

<span class="c1">// Create the parent graph</span>
<span class="n">cudaGraphCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">parent</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="c1">// Move the child graph to the parent graph</span>
<span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">childNodeParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeGraph</span><span class="w"> </span><span class="p">};</span>
<span class="n">childNodeParams</span><span class="p">.</span><span class="n">graph</span><span class="p">.</span><span class="n">graph</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">child</span><span class="p">;</span>
<span class="n">childNodeParams</span><span class="p">.</span><span class="n">graph</span><span class="p">.</span><span class="n">ownership</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaGraphChildGraphOwnershipMove</span><span class="p">;</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">parentNode</span><span class="p">,</span><span class="w"> </span><span class="n">parent</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">childNodeParams</span><span class="p">);</span>
</pre></div>
</div>
</section>
</section>
<section id="optimized-memory-reuse">
<span id="cuda-graphs-graph-memory-nodes-optimized-memory-reuse"></span><h3><span class="section-number">4.2.5.3. </span>Optimized Memory Reuse<a class="headerlink" href="#optimized-memory-reuse" title="Link to this heading">#</a></h3>
<p>CUDA reuses memory in two ways:</p>
<ul class="simple">
<li><p>Virtual and physical memory reuse within a graph is based on virtual address assignment, like in the stream ordered allocator.</p></li>
<li><p>Physical memory reuse between graphs is done with virtual aliasing: different graphs can map the same physical memory to their unique virtual addresses.</p></li>
</ul>
<section id="address-reuse-within-a-graph">
<span id="cuda-graphs-graph-memory-nodes-address-reuse-within-a-graph"></span><h4><span class="section-number">4.2.5.3.1. </span>Address Reuse within a Graph<a class="headerlink" href="#address-reuse-within-a-graph" title="Link to this heading">#</a></h4>
<p>CUDA may reuse memory within a graph by assigning the same virtual address ranges to different allocations whose lifetimes do not overlap. Since virtual addresses may be reused, pointers to different allocations with disjoint lifetimes are not guaranteed to be unique.</p>
<p>The following figure shows adding a new allocation node (2) that can reuse the address freed by a dependent node (1).</p>
<figure class="align-default" id="id9">
<img alt="Adding New Alloc Node 2" src="../_images/new-alloc-node.png" />
<figcaption>
<p><span class="caption-number">Figure 28 </span><span class="caption-text">Adding New Alloc Node 2</span><a class="headerlink" href="#id9" title="Link to this image">#</a></p>
<div class="legend">
<p>The following figure shows adding a new alloc node (4). The new alloc node is not dependent on the free node (2) so cannot reuse the address from the associated alloc node (2). If the alloc node (2) used the address freed by free node (1), the new alloc node 3 would need a new address.</p>
</div>
</figcaption>
</figure>
<figure class="align-default" id="id10">
<img alt="Adding New Alloc Node 3" src="../_images/adding-new-alloc-nodes.png" />
<figcaption>
<p><span class="caption-number">Figure 29 </span><span class="caption-text">Adding New Alloc Node 3</span><a class="headerlink" href="#id10" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="physical-memory-management-and-sharing">
<span id="cuda-graphs-graph-memory-nodes-physical-memory-mgmt"></span><h4><span class="section-number">4.2.5.3.2. </span>Physical Memory Management and Sharing<a class="headerlink" href="#physical-memory-management-and-sharing" title="Link to this heading">#</a></h4>
<p>CUDA is responsible for mapping physical memory to the virtual address before the allocating node is reached in GPU order. As an optimization for memory footprint and mapping overhead, multiple graphs may use the same physical memory for distinct allocations if they will not run simultaneously; however, physical pages cannot be reused if they are bound to more than one executing graph at the same time, or to a graph allocation which remains unfreed.</p>
<p>CUDA may update physical memory mappings at any time during graph instantiation, launch, or execution. CUDA may also introduce synchronization between future graph launches in order to prevent live graph allocations from referring to the same physical memory. As for any allocate-free-allocate pattern, if a program accesses a pointer outside of an allocation’s lifetime, the erroneous access may silently read or write live data owned by another allocation (even if the virtual address of the allocation is unique). Use of compute sanitizer tools can catch this error.</p>
<p>The following figure shows graphs sequentially launched in the same stream. In this example, each graph frees all the memory it allocates. Since the graphs in the same stream never run concurrently, CUDA can and should use the same physical memory to satisfy all the allocations.</p>
<figure class="align-default" id="id11">
<img alt="Sequentially Launched Graphs" src="../_images/sequentially-launched-graphs.png" />
<figcaption>
<p><span class="caption-number">Figure 30 </span><span class="caption-text">Sequentially Launched Graphs</span><a class="headerlink" href="#id11" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="performance-considerations">
<span id="cuda-graphs-graph-memory-nodes-performance-considerations"></span><h3><span class="section-number">4.2.5.4. </span>Performance Considerations<a class="headerlink" href="#performance-considerations" title="Link to this heading">#</a></h3>
<p>When multiple graphs are launched into the same stream, CUDA attempts to allocate the same physical memory to them because the execution of these graphs cannot overlap. Physical mappings for a graph are retained between launches as an optimization to avoid the cost of remapping. If, at a later time, one of the graphs is launched such that its execution may overlap with the others (for example if it is launched into a different stream) then CUDA must perform some remapping because concurrent graphs require distinct memory to avoid data corruption.</p>
<p>In general, remapping of graph memory in CUDA is likely caused by these operations:</p>
<ul class="simple">
<li><p>Changing the stream into which a graph is launched</p></li>
<li><p>A trim operation on the graph memory pool, which explicitly frees unused memory (discussed in <a class="reference internal" href="#cuda-graphs-graph-memory-nodes-physical-memory-footprint"><span class="std std-ref">graph-memory-nodes-physical-memory-footprint</span></a>)</p></li>
<li><p>Relaunching a graph while an unfreed allocation from another graph is mapped to the same memory will cause a remap of memory before relaunch</p></li>
</ul>
<p>Remapping must happen in execution order, but after any previous execution of that graph is complete (otherwise memory that is still in use could be unmapped). Due to this ordering dependency, as well as because mapping operations are OS calls, mapping operations can be relatively expensive. Applications can avoid this cost by launching graphs containing allocation memory nodes consistently into the same stream.</p>
<section id="first-launch-cudagraphupload">
<span id="cuda-graphs-graph-memory-nodes-first-launch"></span><h4><span class="section-number">4.2.5.4.1. </span>First Launch / cudaGraphUpload<a class="headerlink" href="#first-launch-cudagraphupload" title="Link to this heading">#</a></h4>
<p>Physical memory cannot be allocated or mapped during graph instantiation because the stream in which the graph will execute is unknown. Mapping is done instead during graph launch. Calling <code class="docutils literal notranslate"><span class="pre">cudaGraphUpload</span></code> can separate out the cost of allocation from the launch by performing all mappings for that graph immediately and associating the graph with the upload stream. If the graph is then launched into the same stream, it will launch without any additional remapping.</p>
<p>Using different streams for graph upload and graph launch behaves similarly to switching streams, likely resulting in remap operations. In addition, unrelated memory pool management is permitted to pull memory from an idle stream, which could negate the impact of the uploads.</p>
</section>
</section>
<section id="physical-memory-footprint">
<span id="cuda-graphs-graph-memory-nodes-physical-memory-footprint"></span><h3><span class="section-number">4.2.5.5. </span>Physical Memory Footprint<a class="headerlink" href="#physical-memory-footprint" title="Link to this heading">#</a></h3>
<p>The pool-management behavior of asynchronous allocation means that destroying a graph which contains memory nodes (even if their allocations are free) will not immediately return physical memory to the OS for use by other processes. To explicitly release memory back to the OS, an application should use the <code class="docutils literal notranslate"><span class="pre">cudaDeviceGraphMemTrim</span></code> API.</p>
<p><code class="docutils literal notranslate"><span class="pre">cudaDeviceGraphMemTrim</span></code> will unmap and release any physical memory reserved by graph memory nodes that is not actively in use. Allocations that have not been freed and graphs that are scheduled or running are considered to be actively using the physical memory and will not be impacted. Use of the trim API will make physical memory available to other allocation APIs and other applications or processes, but will cause CUDA to reallocate and remap memory when the trimmed graphs are next launched. Note that <code class="docutils literal notranslate"><span class="pre">cudaDeviceGraphMemTrim</span></code> operates on a different pool from <code class="docutils literal notranslate"><span class="pre">cudaMemPoolTrimTo()</span></code>. The graph memory pool is not exposed to the steam ordered memory allocator. CUDA allows applications to query their graph memory footprint through the <code class="docutils literal notranslate"><span class="pre">cudaDeviceGetGraphMemAttribute</span></code> API. Querying the attribute <code class="docutils literal notranslate"><span class="pre">cudaGraphMemAttrReservedMemCurrent</span></code> returns the amount of physical memory reserved by the driver for graph allocations in the current process. Querying <code class="docutils literal notranslate"><span class="pre">cudaGraphMemAttrUsedMemCurrent</span></code> returns the amount of physical memory currently mapped by at least one graph. Either of these attributes can be used to track when new physical memory is acquired by CUDA for the sake of an allocating graph. Both of these attributes are useful for examining how much memory is saved by the sharing mechanism.</p>
</section>
<section id="peer-access">
<span id="cuda-graphs-graph-memory-nodes-peer-access"></span><h3><span class="section-number">4.2.5.6. </span>Peer Access<a class="headerlink" href="#peer-access" title="Link to this heading">#</a></h3>
<p>Graph allocations can be configured for access from multiple GPUs, in which case CUDA will map the allocations onto the peer GPUs as required. CUDA allows graph allocations requiring different mappings to reuse the same virtual address. When this occurs, the address range is mapped onto all GPUs required by the different allocations. This means an allocation may sometimes allow more peer access than was requested during its creation; however, relying on these extra mappings is still an error.</p>
<section id="peer-access-with-graph-node-apis">
<span id="cuda-graphs-graph-memory-nodes-peer-access-with-graph-node-apis"></span><h4><span class="section-number">4.2.5.6.1. </span>Peer Access with Graph Node APIs<a class="headerlink" href="#peer-access-with-graph-node-apis" title="Link to this heading">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">cudaGraphAddNode</span></code> API accepts mapping requests in the <code class="docutils literal notranslate"><span class="pre">accessDescs</span></code> array field of the alloc node parameters structures. The <code class="docutils literal notranslate"><span class="pre">poolProps.location</span></code> embedded structure specifies the resident device for the allocation. Access from the allocating GPU is assumed to be needed, thus the application does not need to specify an entry for the resident device in the <code class="docutils literal notranslate"><span class="pre">accessDescs</span></code> array.</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="n">cudaGraphNodeParams</span><span class="w"> </span><span class="n">allocNodeParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">cudaGraphNodeTypeMemAlloc</span><span class="w"> </span><span class="p">};</span>
<span class="n">allocNodeParams</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">poolProps</span><span class="p">.</span><span class="n">allocType</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemAllocationTypePinned</span><span class="p">;</span>
<span class="n">allocNodeParams</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">poolProps</span><span class="p">.</span><span class="n">location</span><span class="p">.</span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemLocationTypeDevice</span><span class="p">;</span>
<span class="c1">// specify device 1 as the resident device</span>
<span class="n">allocNodeParams</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">poolProps</span><span class="p">.</span><span class="n">location</span><span class="p">.</span><span class="n">id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="n">allocNodeParams</span><span class="p">.</span><span class="n">alloc</span><span class="p">.</span><span class="n">bytesize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">size</span><span class="p">;</span>

<span class="c1">// allocate an allocation resident on device 1 accessible from device 1</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">allocNode</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">allocNodeParams</span><span class="p">);</span>

<span class="n">accessDescs</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="c1">// boilerplate for the access descs (only ReadWrite and Device access supported by the add node api)</span>
<span class="n">accessDescs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">flags</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemAccessFlagsProtReadWrite</span><span class="p">;</span>
<span class="n">accessDescs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">location</span><span class="p">.</span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemLocationTypeDevice</span><span class="p">;</span>
<span class="n">accessDescs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">flags</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemAccessFlagsProtReadWrite</span><span class="p">;</span>
<span class="n">accessDescs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">location</span><span class="p">.</span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemLocationTypeDevice</span><span class="p">;</span>

<span class="c1">// access being requested for device 0 &amp; 2.  Device 1 access requirement left implicit.</span>
<span class="n">accessDescs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">location</span><span class="p">.</span><span class="n">id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="n">accessDescs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">location</span><span class="p">.</span><span class="n">id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>

<span class="c1">// access request array has 2 entries.</span>
<span class="n">allocNodeParams</span><span class="p">.</span><span class="n">accessDescCount</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="n">allocNodeParams</span><span class="p">.</span><span class="n">accessDescs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">accessDescs</span><span class="p">;</span>

<span class="c1">// allocate an allocation resident on device 1 accessible from devices 0, 1 and 2. (0 &amp; 2 from the descriptors, 1 from it being the resident device).</span>
<span class="n">cudaGraphAddNode</span><span class="p">(</span><span class="o">&amp;</span><span class="n">allocNode</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">allocNodeParams</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="peer-access-with-stream-capture">
<span id="cuda-graphs-graph-memory-nodes-peer-access-with-stream-capture"></span><h4><span class="section-number">4.2.5.6.2. </span>Peer Access with Stream Capture<a class="headerlink" href="#peer-access-with-stream-capture" title="Link to this heading">#</a></h4>
<p>For stream capture, the allocation node records the peer accessibility of the allocating pool at the time of the capture. Altering the peer accessibility of the allocating pool after a <code class="docutils literal notranslate"><span class="pre">cudaMallocFromPoolAsync</span></code> call is captured does not affect the mappings that the graph will make for the allocation.</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="c1">// boilerplate for the access descs (only ReadWrite and Device access supported by the add node api)</span>
<span class="n">accessDesc</span><span class="p">.</span><span class="n">flags</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemAccessFlagsProtReadWrite</span><span class="p">;</span>
<span class="n">accessDesc</span><span class="p">.</span><span class="n">location</span><span class="p">.</span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemLocationTypeDevice</span><span class="p">;</span>
<span class="n">accessDesc</span><span class="p">.</span><span class="n">location</span><span class="p">.</span><span class="n">id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>

<span class="c1">// let memPool be resident and accessible on device 0</span>

<span class="n">cudaStreamBeginCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>
<span class="n">cudaMallocAsync</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dptr1</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">memPool</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
<span class="n">cudaStreamEndCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graph1</span><span class="p">);</span>

<span class="n">cudaMemPoolSetAccess</span><span class="p">(</span><span class="n">memPool</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">accessDesc</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>

<span class="n">cudaStreamBeginCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>
<span class="n">cudaMallocAsync</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dptr2</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">memPool</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
<span class="n">cudaStreamEndCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graph2</span><span class="p">);</span>

<span class="c1">//The graph node allocating dptr1 would only have the device 0 accessibility even though memPool now has device 1 accessibility.</span>
<span class="c1">//The graph node allocating dptr2 will have device 0 and device 1 accessibility, since that was the pool accessibility at the time of the cudaMallocAsync call.</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="device-graph-launch">
<span id="cuda-graphs-device-graph-launch"></span><h2><span class="section-number">4.2.6. </span>Device Graph Launch<a class="headerlink" href="#device-graph-launch" title="Link to this heading">#</a></h2>
<p>There are many workflows which need to make data-dependent decisions during runtime and execute different operations depending on those decisions. Rather than offloading this decision-making process to the host, which may require a round-trip from the device, users may prefer to perform it on the device. To that end, CUDA provides a mechanism to launch graphs from the device.</p>
<p>Device graph launch provides a convenient way to perform dynamic control flow from the device, be it something as simple as a loop or as complex as a device-side work scheduler.</p>
<p>Graphs which can be launched from the device will henceforth be referred to as device graphs, and graphs which cannot be launched from the device will be referred to as host graphs.</p>
<p>Device graphs can be launched from both the host and device, whereas host graphs can only be launched from the host. Unlike host launches, launching a device graph from the device while a previous launch of the graph is running will result in an error, returning <code class="docutils literal notranslate"><span class="pre">cudaErrorInvalidValue</span></code>; therefore, a device graph cannot be launched twice from the device at the same time. Launching a device graph from the host and device simultaneously will result in undefined behavior.</p>
<section id="device-graph-creation">
<span id="cuda-graphs-device-graph-creation"></span><h3><span class="section-number">4.2.6.1. </span>Device Graph Creation<a class="headerlink" href="#device-graph-creation" title="Link to this heading">#</a></h3>
<p>In order for a graph to be launched from the device, it must be instantiated explicitly for device launch. This is achieved by passing the <code class="docutils literal notranslate"><span class="pre">cudaGraphInstantiateFlagDeviceLaunch</span></code> flag to the <code class="docutils literal notranslate"><span class="pre">cudaGraphInstantiate()</span></code> call. As is the case for host graphs, device graph structure is fixed at time of instantiation and cannot be updated without re-instantiation, and instantiation can only be performed on the host. In order for a graph to be able to be instantiated for device launch, it must adhere to various requirements.</p>
<section id="device-graph-requirements">
<span id="cuda-graphs-device-graph-requirements"></span><h4><span class="section-number">4.2.6.1.1. </span>Device Graph Requirements<a class="headerlink" href="#device-graph-requirements" title="Link to this heading">#</a></h4>
<p>General requirements:</p>
<ul class="simple">
<li><p>The graph’s nodes must all reside on a single device.</p></li>
<li><p>The graph can only contain kernel nodes, memcpy nodes, memset nodes, and child graph nodes.</p></li>
</ul>
<p>Kernel nodes:</p>
<ul class="simple">
<li><p>Use of CUDA Dynamic Parallelism by kernels in the graph is not permitted.</p></li>
<li><p>Cooperative launches are permitted so long as MPS is not in use.</p></li>
</ul>
<p>Memcpy nodes:</p>
<ul class="simple">
<li><p>Only copies involving device memory and/or pinned device-mapped host memory are permitted.</p></li>
<li><p>Copies involving CUDA arrays are not permitted.</p></li>
<li><p>Both operands must be accessible from the current device at time of instantiation. Note that the copy operation will be performed from the device on which the graph resides, even if it is targeting memory on another device.</p></li>
</ul>
</section>
<section id="device-graph-upload">
<span id="cuda-graphs-device-graph-upload"></span><h4><span class="section-number">4.2.6.1.2. </span>Device Graph Upload<a class="headerlink" href="#device-graph-upload" title="Link to this heading">#</a></h4>
<p>In order to launch a graph on the device, it must first be uploaded to the device to populate the necessary device resources. This can be achieved in one of two ways.</p>
<p>Firstly, the graph can be uploaded explicitly, either via <code class="docutils literal notranslate"><span class="pre">cudaGraphUpload()</span></code> or by requesting an upload as part of instantiation via <code class="docutils literal notranslate"><span class="pre">cudaGraphInstantiateWithParams()</span></code>.</p>
<p>Alternatively, the graph can first be launched from the host, which will perform this upload step implicitly as part of the launch.</p>
<p>Examples of all three methods can be seen below:</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="c1">// Explicit upload after instantiation</span>
<span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">deviceGraphExec1</span><span class="p">,</span><span class="w"> </span><span class="n">deviceGraph1</span><span class="p">,</span><span class="w"> </span><span class="n">cudaGraphInstantiateFlagDeviceLaunch</span><span class="p">);</span>
<span class="n">cudaGraphUpload</span><span class="p">(</span><span class="n">deviceGraphExec1</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>

<span class="c1">// Explicit upload as part of instantiation</span>
<span class="n">cudaGraphInstantiateParams</span><span class="w"> </span><span class="n">instantiateParams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">};</span>
<span class="n">instantiateParams</span><span class="p">.</span><span class="n">flags</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaGraphInstantiateFlagDeviceLaunch</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">cudaGraphInstantiateFlagUpload</span><span class="p">;</span>
<span class="n">instantiateParams</span><span class="p">.</span><span class="n">uploadStream</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stream</span><span class="p">;</span>
<span class="n">cudaGraphInstantiateWithParams</span><span class="p">(</span><span class="o">&amp;</span><span class="n">deviceGraphExec2</span><span class="p">,</span><span class="w"> </span><span class="n">deviceGraph2</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">instantiateParams</span><span class="p">);</span>

<span class="c1">// Implicit upload via host launch</span>
<span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">deviceGraphExec3</span><span class="p">,</span><span class="w"> </span><span class="n">deviceGraph3</span><span class="p">,</span><span class="w"> </span><span class="n">cudaGraphInstantiateFlagDeviceLaunch</span><span class="p">);</span>
<span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">deviceGraphExec3</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="device-graph-update">
<span id="cuda-graphs-device-graph-update"></span><h4><span class="section-number">4.2.6.1.3. </span>Device Graph Update<a class="headerlink" href="#device-graph-update" title="Link to this heading">#</a></h4>
<p>Device graphs can only be updated from the host, and must be re-uploaded to the device upon executable graph update in order for the changes to take effect. This can be achieved using the same methods outlined in Section <a class="reference internal" href="#cuda-graphs-device-graph-upload"><span class="std std-ref">device-graph-upload</span></a>. Unlike host graphs, launching a device graph from the device while an update is being applied will result in undefined behavior.</p>
</section>
</section>
<section id="device-launch">
<span id="cuda-graphs-device-graph-device-launch"></span><h3><span class="section-number">4.2.6.2. </span>Device Launch<a class="headerlink" href="#device-launch" title="Link to this heading">#</a></h3>
<p>Device graphs can be launched from both the host and the device via <code class="docutils literal notranslate"><span class="pre">cudaGraphLaunch()</span></code>, which has the same signature on the device as on the host. Device graphs are launched via the same handle on the host and the device. Device graphs must be launched from another graph when launched from the device.</p>
<p>Device-side graph launch is per-thread and multiple launches may occur from different threads at the same time, so the user will need to select a single thread from which to launch a given graph.</p>
<p>Unlike host launch, device graphs cannot be launched into regular CUDA streams, and can only be launched into distinct named streams, which each denote a specific launch mode. The following table lists the available launch modes.</p>
<div class="pst-scrollable-table-container"><table class="table-no-stripes table" id="id12">
<caption><span class="caption-number">Table 9 </span><span class="caption-text">Device-only Graph Launch Streams</span><a class="headerlink" href="#id12" title="Link to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Stream</p></th>
<th class="head"><p>Launch Mode</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">cudaStreamGraphFireAndForget</span></code></p></td>
<td><p>Fire and forget launch</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">cudaStreamGraphTailLaunch</span></code></p></td>
<td><p>Tail launch</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">cudaStreamGraphFireAndForgetAsSibling</span></code></p></td>
<td><p>Sibling launch</p></td>
</tr>
</tbody>
</table>
</div>
<section id="fire-and-forget-launch">
<span id="cuda-graphs-device-graph-fire-and-forget-launch"></span><h4><span class="section-number">4.2.6.2.1. </span>Fire and Forget Launch<a class="headerlink" href="#fire-and-forget-launch" title="Link to this heading">#</a></h4>
<p>As the name suggests, a fire and forget launch is submitted to the GPU immediately, and it runs independently of the launching graph. In a fire-and-forget scenario, the launching graph is the parent, and the launched graph is the child.</p>
<figure class="align-default" id="id13">
<a class="image reference internal image-reference" href="../_images/fire-and-forget-simple.png"><img alt="../_images/fire-and-forget-simple.png" class="image" src="../_images/fire-and-forget-simple.png" style="width: 400px;" />
</a>
<figcaption>
<p><span class="caption-number">Figure 31 </span><span class="caption-text">Fire and forget launch</span><a class="headerlink" href="#id13" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>The above diagram can be generated by the sample code below:</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">launchFireAndForgetGraph</span><span class="p">(</span><span class="n">cudaGraphExec_t</span><span class="w"> </span><span class="n">graph</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamGraphFireAndForget</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">void</span><span class="w"> </span><span class="n">graphSetup</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cudaGraphExec_t</span><span class="w"> </span><span class="n">gExec1</span><span class="p">,</span><span class="w"> </span><span class="n">gExec2</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraph_t</span><span class="w"> </span><span class="n">g1</span><span class="p">,</span><span class="w"> </span><span class="n">g2</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Create, instantiate, and upload the device graph.</span>
<span class="w">    </span><span class="n">create_graph</span><span class="p">(</span><span class="o">&amp;</span><span class="n">g2</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">gExec2</span><span class="p">,</span><span class="w"> </span><span class="n">g2</span><span class="p">,</span><span class="w"> </span><span class="n">cudaGraphInstantiateFlagDeviceLaunch</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphUpload</span><span class="p">(</span><span class="n">gExec2</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Create and instantiate the launching graph.</span>
<span class="w">    </span><span class="n">cudaStreamBeginCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamCaptureModeGlobal</span><span class="p">);</span>
<span class="w">    </span><span class="n">launchFireAndForgetGraph</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">gExec2</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaStreamEndCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">g1</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">gExec1</span><span class="p">,</span><span class="w"> </span><span class="n">g1</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Launch the host graph, which will in turn launch the device graph.</span>
<span class="w">    </span><span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">gExec1</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>A graph can have up to 120 total fire-and-forget graphs during the course of its execution. This total resets between launches of the same parent graph.</p>
<section id="graph-execution-environments">
<span id="cuda-graphs-device-graph-execution-environments"></span><h5><span class="section-number">4.2.6.2.1.1. </span>Graph Execution Environments<a class="headerlink" href="#graph-execution-environments" title="Link to this heading">#</a></h5>
<p>In order to fully understand the device-side synchronization model, it is first necessary to understand the concept of an execution environment.</p>
<p>When a graph is launched from the device, it is launched into its own execution environment. The execution environment of a given graph encapsulates all work in the graph as well as all generated fire and forget work. The graph can be considered complete when it has completed execution and when all generated child work is complete.</p>
<p>The below diagram shows the environment encapsulation that would be generated by the fire-and-forget sample code in the previous section.</p>
<figure class="align-default" id="id14">
<a class="image reference internal image-reference" href="../_images/fire-and-forget-environments.png"><img alt="../_images/fire-and-forget-environments.png" class="image" src="../_images/fire-and-forget-environments.png" style="width: 400px;" />
</a>
<figcaption>
<p><span class="caption-number">Figure 32 </span><span class="caption-text">Fire and forget launch, with execution environments</span><a class="headerlink" href="#id14" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>These environments are also hierarchical, so a graph environment can include multiple levels of child-environments from fire and forget launches.</p>
<figure class="align-default" id="id15">
<a class="image reference internal image-reference" href="../_images/fire-and-forget-nested-environments.png"><img alt="../_images/fire-and-forget-nested-environments.png" class="image" src="../_images/fire-and-forget-nested-environments.png" style="width: 500px;" />
</a>
<figcaption>
<p><span class="caption-number">Figure 33 </span><span class="caption-text">Nested fire and forget environments</span><a class="headerlink" href="#id15" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>When a graph is launched from the host, there exists a stream environment that parents the execution environment of the launched graph. The stream environment encapsulates all work generated as part of the overall launch. The stream launch is complete (i.e. downstream dependent work may now run) when the overall stream environment is marked as complete.</p>
<figure class="align-default" id="id16">
<a class="image reference internal image-reference" href="../_images/device-graph-stream-environment.png"><img alt="../_images/device-graph-stream-environment.png" class="image" src="../_images/device-graph-stream-environment.png" style="width: 600px;" />
</a>
<figcaption>
<p><span class="caption-number">Figure 34 </span><span class="caption-text">The stream environment, visualized</span><a class="headerlink" href="#id16" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="tail-launch">
<span id="cuda-graphs-device-graph-tail-launch"></span><h4><span class="section-number">4.2.6.2.2. </span>Tail Launch<a class="headerlink" href="#tail-launch" title="Link to this heading">#</a></h4>
<p>Unlike on the host, it is not possible to synchronize with device graphs from the GPU via traditional methods such as <code class="docutils literal notranslate"><span class="pre">cudaDeviceSynchronize()</span></code> or <code class="docutils literal notranslate"><span class="pre">cudaStreamSynchronize()</span></code>. Rather, in order to enable serial work dependencies, a different launch mode - tail launch - is offered, to provide similar functionality.</p>
<p>A tail launch executes when a graph’s environment is considered complete - ie, when the graph and all its children are complete. When a graph completes, the environment of the next graph in the tail launch list will replace the completed environment as a child of the parent environment. Like fire-and-forget launches, a graph can have multiple graphs enqueued for tail launch.</p>
<figure class="align-default" id="id17">
<a class="image reference internal image-reference" href="../_images/tail-launch-simple.png"><img alt="../_images/tail-launch-simple.png" class="image" src="../_images/tail-launch-simple.png" style="width: 600px;" />
</a>
<figcaption>
<p><span class="caption-number">Figure 35 </span><span class="caption-text">A simple tail launch</span><a class="headerlink" href="#id17" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>The above execution flow can be generated by the code below:</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">launchTailGraph</span><span class="p">(</span><span class="n">cudaGraphExec_t</span><span class="w"> </span><span class="n">graph</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamGraphTailLaunch</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">void</span><span class="w"> </span><span class="n">graphSetup</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cudaGraphExec_t</span><span class="w"> </span><span class="n">gExec1</span><span class="p">,</span><span class="w"> </span><span class="n">gExec2</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraph_t</span><span class="w"> </span><span class="n">g1</span><span class="p">,</span><span class="w"> </span><span class="n">g2</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Create, instantiate, and upload the device graph.</span>
<span class="w">    </span><span class="n">create_graph</span><span class="p">(</span><span class="o">&amp;</span><span class="n">g2</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">gExec2</span><span class="p">,</span><span class="w"> </span><span class="n">g2</span><span class="p">,</span><span class="w"> </span><span class="n">cudaGraphInstantiateFlagDeviceLaunch</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphUpload</span><span class="p">(</span><span class="n">gExec2</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Create and instantiate the launching graph.</span>
<span class="w">    </span><span class="n">cudaStreamBeginCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamCaptureModeGlobal</span><span class="p">);</span>
<span class="w">    </span><span class="n">launchTailGraph</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">gExec2</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaStreamEndCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">g1</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">gExec1</span><span class="p">,</span><span class="w"> </span><span class="n">g1</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Launch the host graph, which will in turn launch the device graph.</span>
<span class="w">    </span><span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">gExec1</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Tail launches enqueued by a given graph will execute one at a time, in order of when they were enqueued. So the first enqueued graph will run first, and then the second, and so on.</p>
<figure class="align-default" id="id18">
<img alt="../_images/tail-launch-ordering-simple.png" class="image" src="../_images/tail-launch-ordering-simple.png" />
<figcaption>
<p><span class="caption-number">Figure 36 </span><span class="caption-text">Tail launch ordering</span><a class="headerlink" href="#id18" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Tail launches enqueued by a tail graph will execute before tail launches enqueued by previous graphs in the tail launch list. These new tail launches will execute in the order they are enqueued.</p>
<figure class="align-default" id="id19">
<img alt="../_images/tail-launch-ordering-complex.png" class="image" src="../_images/tail-launch-ordering-complex.png" />
<figcaption>
<p><span class="caption-number">Figure 37 </span><span class="caption-text">Tail launch ordering when enqueued from multiple graphs</span><a class="headerlink" href="#id19" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>A graph can have up to 255 pending tail launches.</p>
<section id="tail-self-launch">
<span id="cuda-graphs-device-graph-tail-self-launch"></span><h5><span class="section-number">4.2.6.2.2.1. </span>Tail Self-launch<a class="headerlink" href="#tail-self-launch" title="Link to this heading">#</a></h5>
<p>It is possible for a device graph to enqueue itself for a tail launch, although a given graph can only have one self-launch enqueued at a time. In order to query the currently running device graph so that it can be relaunched, a new device-side function is added:</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="n">cudaGraphExec_t</span><span class="w"> </span><span class="nf">cudaGetCurrentGraphExec</span><span class="p">();</span>
</pre></div>
</div>
<p>This function returns the handle of the currently running graph if it is a device graph. If the currently executing kernel is not a node within a device graph, this function will return NULL.</p>
<p>Below is sample code showing usage of this function for a relaunch loop:</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="kt">__device__</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">relaunchCount</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">relaunchSelf</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">relaunchMax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">100</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">relaunchCount</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">relaunchMax</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">cudaGetCurrentGraphExec</span><span class="p">(),</span><span class="w"> </span><span class="n">cudaStreamGraphTailLaunch</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="n">relaunchCount</span><span class="o">++</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
<section id="sibling-launch">
<span id="cuda-graphs-sibling-launch"></span><h4><span class="section-number">4.2.6.2.3. </span>Sibling Launch<a class="headerlink" href="#sibling-launch" title="Link to this heading">#</a></h4>
<p>Sibling launch is a variation of fire-and-forget launch in which the graph is launched not as a child of the launching graph’s execution environment, but rather as a child of the launching graph’s parent environment. Sibling launch is equivalent to a fire-and-forget launch from the launching graph’s parent environment.</p>
<figure class="align-default" id="id20">
<img alt="../_images/sibling-launch-simple.png" class="image" src="../_images/sibling-launch-simple.png" />
<figcaption>
<p><span class="caption-number">Figure 38 </span><span class="caption-text">A simple sibling launch</span><a class="headerlink" href="#id20" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>The above diagram can be generated by the sample code below:</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">launchSiblingGraph</span><span class="p">(</span><span class="n">cudaGraphExec_t</span><span class="w"> </span><span class="n">graph</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamGraphFireAndForgetAsSibling</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">void</span><span class="w"> </span><span class="n">graphSetup</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cudaGraphExec_t</span><span class="w"> </span><span class="n">gExec1</span><span class="p">,</span><span class="w"> </span><span class="n">gExec2</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaGraph_t</span><span class="w"> </span><span class="n">g1</span><span class="p">,</span><span class="w"> </span><span class="n">g2</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Create, instantiate, and upload the device graph.</span>
<span class="w">    </span><span class="n">create_graph</span><span class="p">(</span><span class="o">&amp;</span><span class="n">g2</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">gExec2</span><span class="p">,</span><span class="w"> </span><span class="n">g2</span><span class="p">,</span><span class="w"> </span><span class="n">cudaGraphInstantiateFlagDeviceLaunch</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphUpload</span><span class="p">(</span><span class="n">gExec2</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Create and instantiate the launching graph.</span>
<span class="w">    </span><span class="n">cudaStreamBeginCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamCaptureModeGlobal</span><span class="p">);</span>
<span class="w">    </span><span class="n">launchSiblingGraph</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">gExec2</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaStreamEndCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">g1</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">gExec1</span><span class="p">,</span><span class="w"> </span><span class="n">g1</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Launch the host graph, which will in turn launch the device graph.</span>
<span class="w">    </span><span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">gExec1</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Since sibling launches are not launched into the launching graph’s execution environment, they will not gate tail launches enqueued by the launching graph.</p>
</section>
</section>
</section>
<section id="using-graph-apis">
<span id="cuda-graphs-using-graph-apis"></span><h2><span class="section-number">4.2.7. </span>Using Graph APIs<a class="headerlink" href="#using-graph-apis" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">cudaGraph_t</span></code> objects are not thread-safe. It is the responsibility of the user to ensure that multiple threads do not concurrently access the same <code class="docutils literal notranslate"><span class="pre">cudaGraph_t</span></code>.</p>
<p>A <code class="docutils literal notranslate"><span class="pre">cudaGraphExec_t</span></code> cannot run concurrently with itself. A launch of a <code class="docutils literal notranslate"><span class="pre">cudaGraphExec_t</span></code> will be ordered after previous launches of the same executable graph.</p>
<p>Graph execution is done in streams for ordering with other asynchronous work. However, the stream is for ordering only; it does not constrain the internal parallelism of the graph, nor does it affect where graph nodes execute.</p>
<p>See <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__GRAPH.html#group__CUDART__GRAPH">Graph API.</a></p>
</section>
<section id="cuda-user-objects">
<span id="cuda-graphs-cuda-user-objects"></span><h2><span class="section-number">4.2.8. </span>CUDA User Objects<a class="headerlink" href="#cuda-user-objects" title="Link to this heading">#</a></h2>
<p>CUDA User Objects can be used to help manage the lifetime of resources used by asynchronous work in CUDA. In particular, this feature is useful for <a class="reference internal" href="#cuda-graphs"><span class="std std-ref">cuda-graphs</span></a> and <a class="reference internal" href="#cuda-graphs-creating-a-graph-using-stream-capture"><span class="std std-ref">stream capture</span></a>.</p>
<p>Various resource management schemes are not compatible with CUDA graphs. Consider for example an event-based pool or a synchronous-create, asynchronous-destroy scheme.</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="c1">// Library API with pool allocation</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">libraryWork</span><span class="p">(</span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">stream</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">resource</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pool</span><span class="p">.</span><span class="n">claimTemporaryResource</span><span class="p">();</span>
<span class="w">    </span><span class="n">resource</span><span class="p">.</span><span class="n">waitOnReadyEventInStream</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>
<span class="w">    </span><span class="n">launchWork</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="n">resource</span><span class="p">);</span>
<span class="w">    </span><span class="n">resource</span><span class="p">.</span><span class="n">recordReadyEvent</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="c1">// Library API with asynchronous resource deletion</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">libraryWork</span><span class="p">(</span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">stream</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">Resource</span><span class="w"> </span><span class="o">*</span><span class="n">resource</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">new</span><span class="w"> </span><span class="n">Resource</span><span class="p">(...);</span>
<span class="w">    </span><span class="n">launchWork</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="n">resource</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaLaunchHostFunc</span><span class="p">(</span>
<span class="w">        </span><span class="n">stream</span><span class="p">,</span>
<span class="w">        </span><span class="p">[](</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">resource</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">delete</span><span class="w"> </span><span class="n">static_cast</span><span class="o">&lt;</span><span class="n">Resource</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">resource</span><span class="p">);</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="n">resource</span><span class="p">,</span>
<span class="w">        </span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="c1">// Error handling considerations not shown</span>
<span class="p">}</span>
</pre></div>
</div>
<p>These schemes are difficult with CUDA graphs because of the non-fixed pointer or handle for the resource which requires indirection or graph update, and the synchronous CPU code needed each time the work is submitted. They also do not work with stream capture if these considerations are hidden from the caller of the library, and because of use of disallowed APIs during capture. Various solutions exist such as exposing the resource to the caller. CUDA user objects present another approach.</p>
<p>A CUDA user object associates a user-specified destructor callback with an internal refcount, similar to C++ <code class="docutils literal notranslate"><span class="pre">shared_ptr</span></code>. References may be owned by user code on the CPU and by CUDA graphs. Note that for user-owned references, unlike C++ smart pointers, there is no object representing the reference; users must track user-owned references manually. A typical use case would be to immediately move the sole user-owned reference to a CUDA graph after the user object is created.</p>
<p>When a reference is associated to a CUDA graph, CUDA will manage the graph operations automatically. A cloned <code class="docutils literal notranslate"><span class="pre">cudaGraph_t</span></code> retains a copy of every reference owned by the source <code class="docutils literal notranslate"><span class="pre">cudaGraph_t</span></code>, with the same multiplicity. An instantiated <code class="docutils literal notranslate"><span class="pre">cudaGraphExec_t</span></code> retains a copy of every reference in the source <code class="docutils literal notranslate"><span class="pre">cudaGraph_t</span></code>. When a <code class="docutils literal notranslate"><span class="pre">cudaGraphExec_t</span></code> is destroyed without being synchronized, the references are retained until the execution is completed.</p>
<p>Here is an example use.</p>
<div class="highlight-cuda notranslate"><div class="highlight"><pre><span></span><span class="n">cudaGraph_t</span><span class="w"> </span><span class="n">graph</span><span class="p">;</span><span class="w">  </span><span class="c1">// Preexisting graph</span>

<span class="n">Object</span><span class="w"> </span><span class="o">*</span><span class="n">object</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">new</span><span class="w"> </span><span class="n">Object</span><span class="p">;</span><span class="w">  </span><span class="c1">// C++ object with possibly nontrivial destructor</span>
<span class="n">cudaUserObject_t</span><span class="w"> </span><span class="n">cuObject</span><span class="p">;</span>
<span class="n">cudaUserObjectCreate</span><span class="p">(</span>
<span class="w">    </span><span class="o">&amp;</span><span class="n">cuObject</span><span class="p">,</span>
<span class="w">    </span><span class="n">object</span><span class="p">,</span><span class="w">  </span><span class="c1">// Here we use a CUDA-provided template wrapper for this API,</span>
<span class="w">             </span><span class="c1">// which supplies a callback to delete the C++ object pointer</span>
<span class="w">    </span><span class="mi">1</span><span class="p">,</span><span class="w">  </span><span class="c1">// Initial refcount</span>
<span class="w">    </span><span class="n">cudaUserObjectNoDestructorSync</span><span class="w">  </span><span class="c1">// Acknowledge that the callback cannot be</span>
<span class="w">                                    </span><span class="c1">// waited on via CUDA</span>
<span class="p">);</span>
<span class="n">cudaGraphRetainUserObject</span><span class="p">(</span>
<span class="w">    </span><span class="n">graph</span><span class="p">,</span>
<span class="w">    </span><span class="n">cuObject</span><span class="p">,</span>
<span class="w">    </span><span class="mi">1</span><span class="p">,</span><span class="w">  </span><span class="c1">// Number of references</span>
<span class="w">    </span><span class="n">cudaGraphUserObjectMove</span><span class="w">  </span><span class="c1">// Transfer a reference owned by the caller (do</span>
<span class="w">                             </span><span class="c1">// not modify the total reference count)</span>
<span class="p">);</span>
<span class="c1">// No more references owned by this thread; no need to call release API</span>
<span class="n">cudaGraphExec_t</span><span class="w"> </span><span class="n">graphExec</span><span class="p">;</span>
<span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="n">nullptr</span><span class="p">,</span><span class="w"> </span><span class="n">nullptr</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w">  </span><span class="c1">// Will retain a</span>
<span class="w">                                                               </span><span class="c1">// new reference</span>
<span class="n">cudaGraphDestroy</span><span class="p">(</span><span class="n">graph</span><span class="p">);</span><span class="w">  </span><span class="c1">// graphExec still owns a reference</span>
<span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">graphExec</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w">  </span><span class="c1">// Async launch has access to the user objects</span>
<span class="n">cudaGraphExecDestroy</span><span class="p">(</span><span class="n">graphExec</span><span class="p">);</span><span class="w">  </span><span class="c1">// Launch is not synchronized; the release</span>
<span class="w">                                  </span><span class="c1">// will be deferred if needed</span>
<span class="n">cudaStreamSynchronize</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span><span class="w">  </span><span class="c1">// After the launch is synchronized, the remaining</span>
<span class="w">                           </span><span class="c1">// reference is released and the destructor will</span>
<span class="w">                           </span><span class="c1">// execute. Note this happens asynchronously.</span>
<span class="c1">// If the destructor callback had signaled a synchronization object, it would</span>
<span class="c1">// be safe to wait on it at this point.</span>
</pre></div>
</div>
<p>References owned by graphs in child graph nodes are associated to the child graphs, not the parents. If a child graph is updated or deleted, the references change accordingly. If an executable graph or child graph is updated with <code class="docutils literal notranslate"><span class="pre">cudaGraphExecUpdate</span></code> or <code class="docutils literal notranslate"><span class="pre">cudaGraphExecChildGraphNodeSetParams</span></code>, the references in the new source graph are cloned and replace the references in the target graph. In either case, if previous launches are not synchronized, any references which would be released are held until the launches have finished executing.</p>
<p>There is not currently a mechanism to wait on user object destructors via a CUDA API. Users may signal a synchronization object manually from the destructor code. In addition, it is not legal to call CUDA APIs from the destructor, similar to the restriction on <code class="docutils literal notranslate"><span class="pre">cudaLaunchHostFunc</span></code>. This is to avoid blocking a CUDA internal shared thread and preventing forward progress. It is legal to signal another thread to perform an API call, if the dependency is one way and the thread doing the call cannot block forward progress of CUDA work.</p>
<p>User objects are created with <code class="docutils literal notranslate"><span class="pre">cudaUserObjectCreate</span></code>, which is a good starting point to browse related APIs.</p>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="unified-memory.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">4.1. </span>Unified Memory</p>
      </div>
    </a>
    <a class="right-next"
       href="stream-ordered-memory-allocation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">4.3. </span>Stream-Ordered Memory Allocator</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            


              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-structure">4.2.1. Graph Structure</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#node-types">4.2.1.1. Node Types</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#edge-data">4.2.1.2. Edge Data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-and-running-graphs">4.2.2. Building and Running Graphs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-creation">4.2.2.1. Graph Creation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-apis">4.2.2.1.1. Graph APIs</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#stream-capture">4.2.2.1.2. Stream Capture</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-stream-dependencies-and-events">4.2.2.1.2.1. Cross-stream Dependencies and Events</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#prohibited-and-unhandled-operations">4.2.2.1.2.2. Prohibited and Unhandled Operations</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#invalidation">4.2.2.1.2.3. Invalidation</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#capture-introspection">4.2.2.1.2.4. Capture Introspection</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#putting-it-all-together">4.2.2.1.3. Putting It All Together</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-instantiation">4.2.2.2. Graph Instantiation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-execution">4.2.2.3. Graph Execution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#updating-instantiated-graphs">4.2.3. Updating Instantiated Graphs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#whole-graph-update">4.2.3.1. Whole Graph Update</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#individual-node-update">4.2.3.2. Individual Node Update</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#individual-node-enable">4.2.3.3. Individual Node Enable</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-update-limitations">4.2.3.4. Graph Update Limitations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-graph-nodes">4.2.4. Conditional Graph Nodes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-handles">4.2.4.1. Conditional Handles</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-node-body-graph-requirements">4.2.4.2. Conditional Node Body Graph Requirements</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-if-nodes">4.2.4.3. Conditional IF Nodes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-while-nodes">4.2.4.4. Conditional WHILE Nodes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-switch-nodes">4.2.4.5. Conditional SWITCH Nodes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-memory-nodes">4.2.5. Graph Memory Nodes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">4.2.5.1. Introduction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#api-fundamentals">4.2.5.2. API Fundamentals</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-node-apis">4.2.5.2.1. Graph Node APIs</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cuda-graphs-graph-memory-nodes-stream-capture">4.2.5.2.2. Stream Capture</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#accessing-and-freeing-graph-memory-outside-of-the-allocating-graph">4.2.5.2.3. Accessing and Freeing Graph Memory Outside of the Allocating Graph</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cudagraphinstantiateflagautofreeonlaunch">4.2.5.2.4. cudaGraphInstantiateFlagAutoFreeOnLaunch</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-nodes-in-child-graphs">4.2.5.2.5. Memory Nodes in Child Graphs</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimized-memory-reuse">4.2.5.3. Optimized Memory Reuse</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#address-reuse-within-a-graph">4.2.5.3.1. Address Reuse within a Graph</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#physical-memory-management-and-sharing">4.2.5.3.2. Physical Memory Management and Sharing</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-considerations">4.2.5.4. Performance Considerations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#first-launch-cudagraphupload">4.2.5.4.1. First Launch / cudaGraphUpload</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#physical-memory-footprint">4.2.5.5. Physical Memory Footprint</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#peer-access">4.2.5.6. Peer Access</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#peer-access-with-graph-node-apis">4.2.5.6.1. Peer Access with Graph Node APIs</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#peer-access-with-stream-capture">4.2.5.6.2. Peer Access with Stream Capture</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#device-graph-launch">4.2.6. Device Graph Launch</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#device-graph-creation">4.2.6.1. Device Graph Creation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#device-graph-requirements">4.2.6.1.1. Device Graph Requirements</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#device-graph-upload">4.2.6.1.2. Device Graph Upload</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#device-graph-update">4.2.6.1.3. Device Graph Update</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#device-launch">4.2.6.2. Device Launch</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#fire-and-forget-launch">4.2.6.2.1. Fire and Forget Launch</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-execution-environments">4.2.6.2.1.1. Graph Execution Environments</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#tail-launch">4.2.6.2.2. Tail Launch</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#tail-self-launch">4.2.6.2.2.1. Tail Self-launch</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sibling-launch">4.2.6.2.3. Sibling Launch</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-graph-apis">4.2.7. Using Graph APIs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cuda-user-objects">4.2.8. CUDA User Objects</a></li>
</ul>
  </nav></div>

</div></div>
              
            

          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  

  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>


  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
<a class="footer-brand logo" href="https://www.nvidia.com">
  <img src="../_static/nvidia-logo-horiz-rgb-1c-blk-for-screen.svg" class="logo__image only-light" alt="NVIDIA"/>
  <img src="../_static/nvidia-logo-horiz-rgb-1c-wht-for-screen.svg" class="logo__image only-dark" alt="NVIDIA"/>
</a></div>
      
        <div class="footer-item">

<div class="footer-links">
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/">Privacy Policy</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/">Your Privacy Choices</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/">Terms of Service</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/accessibility/">Accessibility</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/company-policies/">Corporate Policies</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/product-security/">Product Security</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/contact/">Contact</a>
  
  
  
</div>
</div>
      
        <div class="footer-item">




  <p class="copyright">
    
      Copyright © 2007-2025, NVIDIA Corporation &amp; affiliates. All rights reserved.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item"><p class="last-updated">
  Last updated on Dec 12, 2025.
  <br/>
</p></div>
      
    </div>
  
  
  
</div>

  </footer>
  </body>
</html>