# Topic 5: CUDA streams â€” execution/dependency model, events, synchronization, NCCL interaction

Streams are the fundamental concurrency primitive for overlapping compute, communication, and memory transfers. NCCL operations execute on their own streams, and understanding how events synchronize across streams is essential for pipeline parallelism.

## Resources

<!-- Resource IDs from manifest belonging to this topic -->
| ID | Title | Priority | Status |
|----|-------|----------|--------|
| pytorch-cuda-semantics | PyTorch CUDA Semantics | high | pending |
| cuda-async-execution | CUDA Programming Guide: Asynchronous Execution | medium | pending |
| leimao-cuda-stream | CUDA Stream | low | pending |

## Synthesis

<!-- To be filled during study -->

### Mental model

### Key concepts

### Cross-resource agreement / disagreement

### Practical checklist

### Gotchas and failure modes

### Experiments to run
